title: "Kappa loss per fold (by noise level and by percent altered)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/Users/chris/github/robustness-under-noise")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(dplyr)
library(purrr)
library(tidyr)
```

```{r helper-functions}
# Helper to coerce names like "noise_10" -> 0.10 and percent names like "25" -> 0.25
parse_noise <- function(nm) {
  # nm expected like "noise_0" or "noise_10" or "0"
  if (is.numeric(nm)) return(as.numeric(nm))
  if (grepl("^noise_", nm)) {
    as.numeric(sub("^noise_", "", nm))/100
  } else {
    as.numeric(nm)
  }
}

parse_percent <- function(pct_nm) {
  # pct_nm likely strings like "0", "25", "50", etc. If they are fractional already, return as-is
  if (is.numeric(pct_nm)) return(as.numeric(pct_nm))
  val <- suppressWarnings(as.numeric(pct_nm))
  if (is.na(val)) return(NA_real_)
  # If the value looks like an integer percentage (0..100) convert to fraction if >1
  if (val > 1) return(val/100)
  val
}

safe_kappa <- function(x) {
  # try to extract Kappa from a confusionMatrix-like object
  if (inherits(x, "confusionMatrix")) {
    as.numeric(x$overall["Kappa"])
  } else if (is.list(x) && !is.null(x$overall) && !is.null(x$overall["Kappa"])) {
    as.numeric(x$overall["Kappa"])
  } else if (is.numeric(x)) {
    # in case the stored value is already numeric
    as.numeric(x)
  } else {
    NA_real_
  }
}
```

```{r load-files}
instances_file_candidates <- c(
  "results/instances/instances_list.rds",
  "results/instances/instancesCM_list.rds"
)
instances_file <- instances_file_candidates[file.exists(instances_file_candidates)][2]
if (is.na(instances_file) || is.null(instances_file)) stop("No instances file found in results/instances; expected instances_list.rds or instancesCM_list.rds")

message("Using instances file: ", instances_file)

instances_all <- readRDS(instances_file)
```

## Extract Kappa values into a tidy table

```{r extract}
# We'll build rows: dataset, fold, method, noise, percent, kappa
rows <- list()
ri <- 1

for (dataset in names(instances_all)) {
  folds <- instances_all[[dataset]]
  for (fold_name in names(folds)) {
    methods <- folds[[fold_name]]
    for (method in names(methods)) {
      noise_list <- methods[[method]]
      for (noise_name in names(noise_list)) {
        percent_list <- noise_list[[noise_name]]
        for (pct_name in names(percent_list)) {
          value <- percent_list[[pct_name]]
          kappa_val <- safe_kappa(value)

          rows[[ri]] <- data.frame(
            dataset = dataset,
            fold = fold_name,
            method = method,
            noise_name = noise_name,
            percent_name = pct_name,
            noise = parse_noise(noise_name),
            percent = parse_percent(pct_name),
            kappa = kappa_val,
            stringsAsFactors = FALSE
          )
          ri <- ri + 1
        }
      }
    }
  }
}

df_kappa <- bind_rows(rows)

if (nrow(df_kappa) == 0) stop("No kappa values could be extracted from the file; check structure")

head(df_kappa)

```

## Compute baseline Kappa and Kappa loss

We define kappa loss as: 1 - kappa.

```{r loss}
# compute kappa loss as 1 - kappa and add to df_kappa
df_kappa2 <- df_kappa %>%
  mutate(kappa_loss = 1 - kappa)

# Quick sanity check: noise==0 rows should have loss approx 0
df_kappa2 %>%
  filter(noise == 0) %>%
  select(dataset, fold, method, percent, kappa, kappa_loss) %>%
  head()
```

## Aggregate: 1) Kappa loss by noise level (mean across instance percentages and across models)

```{r agg_noise}
agg_by_noise <- df_kappa2 %>%
  group_by(dataset, fold, noise) %>%
  summarise(mean_kappa_loss = mean(kappa_loss, na.rm = TRUE),
            sd_kappa_loss = sd(kappa_loss, na.rm = TRUE),
            n = sum(!is.na(kappa_loss)),
            .groups = "drop") %>%
  arrange(dataset, fold, noise)

agg_by_noise %>% head()

# Save
write.csv(agg_by_noise, file = "results/instances/folds/agg_kappa_loss_by_noise_per_fold.csv", row.names = FALSE)
```

## Aggregate: 2) Kappa loss by percentage of altered instances (mean across noise levels and across models)

```{r agg_percent}
agg_by_percent <- df_kappa2 %>%
  group_by(dataset, fold, percent) %>%
  summarise(mean_kappa_loss = mean(kappa_loss, na.rm = TRUE),
            sd_kappa_loss = sd(kappa_loss, na.rm = TRUE),
            n = sum(!is.na(kappa_loss)),
            .groups = "drop") %>%
  arrange(dataset, fold, percent)

agg_by_percent %>% head()

write.csv(agg_by_percent, file = "results/instances/folds/agg_kappa_loss_by_percent_per_fold.csv", row.names = FALSE)
```

## Statistical tests (ANOVA / Friedman / Wilcoxon)

The following section performs statistical comparisons across noise levels (for each dataset & fold) and across percentage levels. For each dataset+fold we:

- compute per-method mean kappa_loss across percentages (so each method provides one observation per noise level), then:
  - if there are > 2 noise levels: run Friedman test (non-parametric repeated measures) and a paired Wilcoxon pairwise test (with BH correction);
  - if there are exactly 2 noise levels: run a paired Wilcoxon signed-rank test.

- similarly for percent-level comparisons (per-method mean across noise levels).

Results (R objects) are saved under `results/instances/folds/tests/` as RDS files.

```{r stats-noise}
library(broom)

tests_by_noise <- list()

# Prepare per-method per-noise means (average across percent)
per_method_noise <- df_kappa2 %>%
  group_by(dataset, fold, method, noise) %>%
  summarise(mean_kappa_loss = mean(kappa_loss, na.rm = TRUE), .groups = "drop")

datasets_folds <- per_method_noise %>% select(dataset, fold) %>% distinct()

for (r in seq_len(nrow(datasets_folds))) {
  ds <- datasets_folds$dataset[r]
  fd <- datasets_folds$fold[r]

  dat_sub <- per_method_noise %>% filter(dataset == ds, fold == fd)
  # ensure noise is factor ordered
  dat_sub <- dat_sub %>% mutate(noise_f = factor(noise))

  res <- list()

  try({
    n_levels <- length(unique(dat_sub$noise_f))
    if (n_levels > 2) {
      # Friedman test: mean_kappa_loss ~ noise | method
      fr <- tryCatch(
        friedman.test(mean_kappa_loss ~ noise_f | method, data = dat_sub),
        error = function(e) e
      )
      res$friedman <- fr

      # Pairwise Wilcoxon (paired across methods)
      pw <- tryCatch(
        pairwise.wilcox.test(dat_sub$mean_kappa_loss, dat_sub$noise_f, paired = TRUE, p.adjust.method = "BH"),
        error = function(e) e
      )
      res$pairwise_wilcox <- pw

      # Try repeated measures ANOVA (may fail if assumptions not met)
      aov_res <- tryCatch({
        aov(mean_kappa_loss ~ noise_f + Error(factor(method)), data = dat_sub)
      }, error = function(e) e)
      res$aov <- aov_res
    } else if (n_levels == 2) {
      # Paired Wilcoxon across methods
      w <- tryCatch({
        # reshape to wide: rows methods, cols two noise levels
        wide <- dat_sub %>% select(method, noise_f, mean_kappa_loss) %>% pivot_wider(names_from = noise_f, values_from = mean_kappa_loss)
        # paired wilcox.test on the two columns
        cols <- names(wide)[-1]
        wilcox.test(wide[[cols[1]]], wide[[cols[2]]], paired = TRUE)
      }, error = function(e) e)
      res$wilcox <- w
    }
  }, silent = TRUE)

  tests_by_noise[[paste(ds, fd, sep = "__")]] <- res
}
```

```{r plot-noise}
library(ggplot2)

# Plot aggregated by noise level
p_noise <- ggplot(agg_by_noise, aes(x = factor(noise), y = mean_kappa_loss, fill = factor(noise))) +
  geom_boxplot() +
  facet_wrap(~ dataset) +
  labs(title = "Kappa Loss by Noise Level",
       x = "Noise Level",
       y = "Mean Kappa Loss",
       fill = "Noise") +
  theme_minimal()

print(p_noise)
```
```{r stats-percent}
# Now do the analogous analysis across percent levels (average across noise)
tests_by_percent <- list()

per_method_percent <- df_kappa2 %>%
  group_by(dataset, fold, method, percent) %>%
  summarise(mean_kappa_loss = mean(kappa_loss, na.rm = TRUE), .groups = "drop")

datasets_folds2 <- per_method_percent %>% select(dataset, fold) %>% distinct()

for (r in seq_len(nrow(datasets_folds2))) {
  ds <- datasets_folds2$dataset[r]
  fd <- datasets_folds2$fold[r]

  dat_sub <- per_method_percent %>% filter(dataset == ds, fold == fd)
  dat_sub <- dat_sub %>% mutate(percent_f = factor(percent))

  res <- list()

  try({
    n_levels <- length(unique(dat_sub$percent_f))
    if (n_levels > 2) {
      fr <- tryCatch(
        friedman.test(mean_kappa_loss ~ percent_f | method, data = dat_sub),
        error = function(e) e
      )
      res$friedman <- fr

      pw <- tryCatch(
        pairwise.wilcox.test(dat_sub$mean_kappa_loss, dat_sub$percent_f, paired = TRUE, p.adjust.method = "BH"),
        error = function(e) e
      )
      res$pairwise_wilcox <- pw

      aov_res <- tryCatch({
        aov(mean_kappa_loss ~ percent_f + Error(factor(method)), data = dat_sub)
      }, error = function(e) e)
      res$aov <- aov_res
    } else if (n_levels == 2) {
      w <- tryCatch({
        wide <- dat_sub %>% select(method, percent_f, mean_kappa_loss) %>% pivot_wider(names_from = percent_f, values_from = mean_kappa_loss)
        cols <- names(wide)[-1]
        wilcox.test(wide[[cols[1]]], wide[[cols[2]]], paired = TRUE)
      }, error = function(e) e)
      res$wilcox <- w
    }
  }, silent = TRUE)

  tests_by_percent[[paste(ds, fd, sep = "__")]] <- res
}
```

```{r plot-percent}
# Plot aggregated by percentage of altered instances
p_percent <- ggplot(agg_by_percent, aes(x = factor(percent), y = mean_kappa_loss, fill = factor(percent))) +
  geom_boxplot() +
  facet_wrap(~ dataset) +
  labs(title = "Kappa Loss by Percentage Altered",
       x = "Percentage",
       y = "Mean Kappa Loss",
       fill = "Percent") +
  theme_minimal()

print(p_percent)
```

```{r summarize-tests}
# Write brief summaries to CSVs for quick inspection
summarize_test <- function(tlist) {
  rows <- list(); ri <- 1
  for (nm in names(tlist)) {
    res <- tlist[[nm]]
    # collect available test names
    if (!is.null(res$friedman) && inherits(res$friedman, "htest")) {
      rows[[ri]] <- data.frame(target = nm, test = "friedman", statistic = res$friedman$statistic, p.value = res$friedman$p.value, stringsAsFactors = FALSE); ri <- ri+1
    }
    if (!is.null(res$wilcox) && inherits(res$wilcox, "htest")) {
      rows[[ri]] <- data.frame(target = nm, test = "wilcox", statistic = res$wilcox$statistic, p.value = res$wilcox$p.value, stringsAsFactors = FALSE); ri <- ri+1
    }
    if (!is.null(res$pairwise_wilcox) && inherits(res$pairwise_wilcox, "list")) {
      # pairwise.wilcox.test returns list with p.value matrix
      pmat <- res$pairwise_wilcox$p.value
      # flatten
      if (!is.null(pmat)) {
        for (i in seq_len(nrow(pmat))) for (j in seq_len(ncol(pmat))) {
          pv <- pmat[i,j]
          if (!is.na(pv)) {
            rows[[ri]] <- data.frame(target = nm, test = "pairwise_wilcox", comparison = paste(rownames(pmat)[i], colnames(pmat)[j], sep = " vs "), p.value = pv, stringsAsFactors = FALSE); ri <- ri+1
          }
        }
      }
    }
  }
  if (length(rows) == 0) return(tibble())
  bind_rows(rows)
}

sum_noise <- summarize_test(tests_by_noise)
sum_percent <- summarize_test(tests_by_percent)
if (nrow(sum_noise)>0) write.csv(sum_noise, file = "results/instances/folds/summary_tests_by_noise.csv", row.names = FALSE)
if (nrow(sum_percent)>0) write.csv(sum_percent, file = "results/instances/folds/summary_tests_by_percent.csv", row.names = FALSE)

print("Statistical tests completed. Results saved to results/instances/folds/")
```
