Top-K Feature Agreement Analysis
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================

Dataset: analcatdata_authorship
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
be              7.979310     8.034483        8.462069           0.2770511
to              2.875862     2.965517        3.131035           0.1022592
our             2.627586     2.689655        2.806897           0.0927467
her             2.331034     2.586207        2.875862           0.0891795
had             1.820690     1.965517        2.082759           0.0677765

=== LIME Rankings ===


Feature    Importance
--------  -----------
be          0.2338872
her         0.1095251
to          0.0928735
had         0.0616971
our         0.0532500

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
be          0.1990598
her         0.1489527
to          0.1220335
had         0.0730571
which       0.0345455

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: be
LIME: be
SHAP: be

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   be          be          TRUE      
FEAT_IMP vs SHAP   be          be          TRUE      
LIME vs SHAP       be          be          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
her             3.101587     3.142857        3.260318           0.4708680
a               1.000000     1.000000        1.000000           0.1498216
all             1.000000     1.000000        1.000000           0.1498216
also            1.000000     1.000000        1.000000           0.1498216
an              1.000000     1.000000        1.000000           0.1498216

=== LIME Rankings ===


Feature    Importance
--------  -----------
her         0.5541534
from        0.0163695
but         0.0148028
even        0.0134563
such        0.0133923

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
her         0.4181877
a           0.0000000
all         0.0000000
also        0.0000000
an          0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: her
LIME: her
SHAP: her

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   her         her         TRUE      
FEAT_IMP vs SHAP   her         her         TRUE      
LIME vs SHAP       her         her         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2270            -nan     0.1000    0.0458
     2        1.1460            -nan     0.1000    0.0369
     3        1.0774            -nan     0.1000    0.0328
     4        1.0223            -nan     0.1000    0.0249
     5        0.9637            -nan     0.1000    0.0301
     6        0.9147            -nan     0.1000    0.0226
     7        0.8644            -nan     0.1000    0.0245
     8        0.8227            -nan     0.1000    0.0204
     9        0.7838            -nan     0.1000    0.0190
    10        0.7452            -nan     0.1000    0.0170
    20        0.4978            -nan     0.1000    0.0078
    40        0.2752            -nan     0.1000    0.0030
    50        0.2146            -nan     0.1000    0.0018



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
be                3.3625       3.7500          3.9125           0.0713436
her               2.8625       3.3750          3.4375           0.0642093
to                1.6500       1.9375          2.1625           0.0368609
any               1.1000       1.3125          1.4875           0.0249703
been              1.1875       1.2500          1.3500           0.0237812

=== LIME Rankings ===


Feature    Importance
--------  -----------
her         0.1774817
be          0.1593537
to          0.0944110
any         0.0835596
been        0.0560643

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
her         0.1587098
be          0.1474567
any         0.0670900
to          0.0518656
been        0.0407824

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: be
LIME: her
SHAP: her

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   be          her         FALSE     
FEAT_IMP vs SHAP   be          her         FALSE     
LIME vs SHAP       her         her         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
be             0.0637337    0.0713436       0.0772889           0.0713436
was            0.0406659    0.0487515       0.0487515           0.0487515
any            0.0190250    0.0237812       0.0282996           0.0237812
not            0.0216409    0.0225922       0.0247325           0.0225922
at             0.0118906    0.0190250       0.0244946           0.0190250
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
at          0.2608252
be          0.2037138
any         0.1500254
was         0.1400285
not         0.1108807

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
be          0.1703533
was         0.1301330
any         0.0862488
such        0.0781357
at          0.0656535

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: be
LIME: at
SHAP: be

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   be          at          FALSE     
FEAT_IMP vs SHAP   be          be          TRUE      
LIME vs SHAP       at          be          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
be              9.400000     9.615385       10.169231           0.1486326
her             6.815385     7.461538        8.076923           0.1153389
to              2.723077     3.307692        3.461539           0.0511296
any             2.415385     2.846154        3.400000           0.0439952
as              1.569231     1.846154        2.092308           0.0285375

=== LIME Rankings ===


Feature    Importance
--------  -----------
be          0.2450456
her         0.1982003
every       0.1153069
any         0.0926260
as          0.0701570

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
be          0.2599958
her         0.1240922
every       0.0775474
any         0.0699456
as          0.0515993

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: be
LIME: be
SHAP: be

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   be          be          TRUE      
FEAT_IMP vs SHAP   be          be          TRUE      
LIME vs SHAP       be          be          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
at              1.733333     2.000000        2.666667           0.0071344
her             2.000000     2.000000        2.266667           0.0071344
such            1.400000     2.000000        2.000000           0.0071344
to              1.666667     2.000000        2.933333           0.0071344
and             1.333333     1.666667        1.933333           0.0059453

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: at
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   at          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
to             0.0011891    0.0023781       0.0066587           0.0023781
any            0.0002378    0.0011891       0.0030916           0.0011891
at             0.0011891    0.0011891       0.0030916           0.0011891
a              0.0000000    0.0000000       0.0000000           0.0000000
all            0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
at          0.1427364
any         0.1280638
be          0.1085612
her         0.0979177
every       0.0958757

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
any         0.0511238
her         0.0443907
at          0.0427814
be          0.0408982
which       0.0388042

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: to
LIME: at
SHAP: any

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   to          at          FALSE     
FEAT_IMP vs SHAP   to          any         FALSE     
LIME vs SHAP       at          any         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=multinom ===
Applying data scaling for method: multinom
# weights:  72 (71 variable)
initial  value 582.936779 
iter  10 value 0.453684
iter  20 value 0.024321
iter  30 value 0.012004
iter  40 value 0.008317
iter  50 value 0.006369
iter  60 value 0.005418
iter  70 value 0.004655
iter  80 value 0.004096
iter  90 value 0.003406
iter 100 value 0.002971
final  value 0.002971 
stopped after 100 iterations


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
not            0.0059453    0.0059453       0.0080856           0.0059453
of             0.0028537    0.0047562       0.0059453           0.0047562
at             0.0002378    0.0035672       0.0045184           0.0035672
to             0.0023781    0.0035672       0.0047562           0.0035672
be             0.0002378    0.0023781       0.0033294           0.0023781
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
at          0.1701607
of          0.1634126
her         0.1138866
any         0.1134601
be          0.0991738

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
her         0.0834759
of          0.0732643
at          0.0591579
any         0.0591429
be          0.0527324

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: not
LIME: at
SHAP: her

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   not         at          FALSE     
FEAT_IMP vs SHAP   not         her         FALSE     
LIME vs SHAP       at          her         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
was                21.35        22.00           23.35           0.1046373
be                 17.25        17.75           20.90           0.0844233
her                10.80        13.00           13.45           0.0618312
to                 10.65        11.50           12.40           0.0546968
the                 8.05         9.50           10.45           0.0451843

=== LIME Rankings ===


Feature    Importance
--------  -----------
be          0.1410376
her         0.1173408
was         0.1047653
then        0.0905298
to          0.0853969

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
was         0.1339935
her         0.1041019
which       0.0862703
to          0.0787171
be          0.0751752

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -0.5                 3
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP            -1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: was
LIME: be
SHAP: was

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   was         be          FALSE     
FEAT_IMP vs SHAP   was         was         TRUE      
LIME vs SHAP       be          was         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
her             2.333333     2.500000        2.833333           0.0178359
any             1.566667     1.833333        2.100000           0.0130797
not             1.533333     1.833333        2.233333           0.0130797
to              1.833333     1.833333        2.000000           0.0130797
as              1.533333     1.666667        1.933333           0.0118906

=== LIME Rankings ===


Feature    Importance
--------  -----------
things      0.4619914
also        0.4163162
its         0.2783998
one         0.2598571
our         0.2299500

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
are         0.9145438
even        0.6452839
some        0.6326428
their       0.5319435
BookID      0.5284562

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: her
LIME: things
SHAP: are

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   her         things      FALSE     
FEAT_IMP vs SHAP   her         are         FALSE     
LIME vs SHAP       things      are         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
our                 18.4           22            25.4           0.0261593
an                  11.0           13            14.6           0.0154578
the                  7.2            8            10.4           0.0095125
my                   4.0            5             7.6           0.0059453
any                  2.0            3             4.0           0.0035672

=== LIME Rankings ===


Feature    Importance
--------  -----------
things      0.0798852
our         0.0673345
be          0.0653568
any         0.0583402
been        0.0570491

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
her         0.0649400
every       0.0490684
our         0.0363467
any         0.0313288
an          0.0278009

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: our
LIME: things
SHAP: her

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   our         things      FALSE     
FEAT_IMP vs SHAP   our         her         FALSE     
LIME vs SHAP       things      her         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
her            0.0014269    0.0035672       0.0054697           0.0035672
a              0.0000000    0.0000000       0.0000000           0.0000000
all            0.0000000    0.0000000       0.0000000           0.0000000
also           0.0000000    0.0000000       0.0000000           0.0000000
an             0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
her         0.0870040
be          0.0719082
any         0.0587000
every       0.0413609
to          0.0353943

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
her          0.104964
be           0.070088
any          0.045752
every        0.035704
to           0.032952

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: her
LIME: her
SHAP: her

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   her         her         TRUE      
FEAT_IMP vs SHAP   her         her         TRUE      
LIME vs SHAP       her         her         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
a                      1            1               1           0.3769322
all                    1            1               1           0.3769322
also                   1            1               1           0.3769322
an                     1            1               1           0.3769322
and                    1            1               1           0.3769322

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
a                   0
all                 0
also                0
an                  0
and                 0

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP           1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: a
SHAP: a

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   a           a           TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
her                 1.12          1.4            1.66           0.0166468
at                  1.02          1.3            1.30           0.0154578
been                1.14          1.3            1.70           0.0154578
to                  1.14          1.3            1.50           0.0154578
as                  1.04          1.2            1.28           0.0142687

=== LIME Rankings ===


Feature    Importance
--------  -----------
every       0.0365654
her         0.0351435
any         0.0296184
would       0.0289844
be          0.0270284

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
every       0.0249877
her         0.0228511
any         0.0164476
been        0.0133346
have        0.0125999

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: her
LIME: every
SHAP: every

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   her         every       FALSE     
FEAT_IMP vs SHAP   her         every       FALSE     
LIME vs SHAP       every       every       TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
any            0.0002378    0.0023781       0.0035672           0.0023781
at             0.0002378    0.0023781       0.0035672           0.0023781
to             0.0002378    0.0023781       0.0023781           0.0023781
her            0.0000000    0.0011891       0.0011891           0.0011891
such           0.0002378    0.0011891       0.0023781           0.0011891
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: any
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   any         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
to                   2.0            4             4.0           0.0047562
at                   2.0            3             3.8           0.0035672
every                2.0            2             2.0           0.0023781
that                 1.2            2             2.8           0.0023781
a                    1.0            1             1.0           0.0011891

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: to
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   to          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
be              9.454546     9.818182       10.390909           0.2568371
to              4.472727     4.590909        4.790909           0.1200951
her             2.690909     2.863636        2.900000           0.0749108
had             1.463636     1.727273        1.772727           0.0451843
was             1.681818     1.727273        2.018182           0.0451843

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: be
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   be          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
not            1.0000000     1.333333        1.600000           0.0047562
what           1.3333333     1.333333        1.333333           0.0047562
a              1.0000000     1.000000        1.000000           0.0035672
also           0.7333333     1.000000        1.000000           0.0035672
an             1.0000000     1.000000        1.266667           0.0035672

=== LIME Rankings ===


Feature    Importance
--------  -----------
things      0.1001517
every       0.0972391
her         0.0938881
at          0.0869929
any         0.0807284

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
her         0.0414667
every       0.0336000
at          0.0281333
be          0.0250667
as          0.0216667

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP          NA                 0
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: not
LIME: things
SHAP: her

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   not         things      FALSE     
FEAT_IMP vs SHAP   not         her         FALSE     
LIME vs SHAP       things      her         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=analcatdata_authorship, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
to             0.0026159    0.0035672       0.0057075           0.0035672
at             0.0014269    0.0023781       0.0033294           0.0023781
any            0.0002378    0.0011891       0.0042806           0.0011891
be             0.0000000    0.0011891       0.0023781           0.0011891
not            0.0000000    0.0011891       0.0011891           0.0011891
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
at          0.1775531
be          0.1284521
any         0.1283138
her         0.1163464
to          0.0905806

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
her         0.0664482
any         0.0591381
be          0.0547379
at          0.0540714
every       0.0470484

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: to
LIME: at
SHAP: her

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   to          at          FALSE     
FEAT_IMP vs SHAP   to          her         FALSE     
LIME vs SHAP       at          her         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


Dataset: badges2
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3918367    0.4217687       0.4353741           0.4217687
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0000000           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.9991261
spaces                    0.0000189
vowel_consonant_ratio     0.0000130
even_odd                  0.0000124
consonants                0.0000124
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature              Importance
------------------  -----------
second_char_vowel         0.676
consonants                0.000
dots                      0.000
even_odd                  0.000
first_char_vowel          0.000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3918367    0.4217687       0.4353741           0.4217687
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0000000           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.9991261
spaces                    0.0000189
vowel_consonant_ratio     0.0000130
even_odd                  0.0000124
consonants                0.0000124
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature              Importance
------------------  -----------
second_char_vowel         0.676
consonants                0.000
dots                      0.000
even_odd                  0.000
first_char_vowel          0.000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0068            -nan     0.1000    0.0949
     2        0.8640            -nan     0.1000    0.0705
     3        0.7502            -nan     0.1000    0.0549
     4        0.6565            -nan     0.1000    0.0479
     5        0.5778            -nan     0.1000    0.0385
     6        0.5108            -nan     0.1000    0.0322
     7        0.4530            -nan     0.1000    0.0300
     8        0.4029            -nan     0.1000    0.0253
     9        0.3592            -nan     0.1000    0.0217
    10        0.3208            -nan     0.1000    0.0195
    20        0.1099            -nan     0.1000    0.0056
    40        0.0144            -nan     0.1000    0.0008
    50        0.0053            -nan     0.1000    0.0003



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3863946     0.414966       0.4272109            0.414966
length                   0.0000000     0.000000       0.0000000            0.000000
even_odd                 0.0000000     0.000000       0.0000000            0.000000
first_char_vowel         0.0000000     0.000000       0.0000000            0.000000
vowels                   0.0000000     0.000000       0.0000000            0.000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature              Importance
------------------  -----------
second_char_vowel     0.9927291
consonants            0.0000132
first_char_vowel      0.0000124
even_odd              0.0000123
vowels                0.0000118
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature              Importance
------------------  -----------
second_char_vowel     0.6359051
consonants            0.0000000
dots                  0.0000000
even_odd              0.0000000
first_char_vowel      0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3918367    0.4217687       0.4353741           0.4217687
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0000000           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.9991261
spaces                    0.0000189
vowel_consonant_ratio     0.0000130
even_odd                  0.0000124
consonants                0.0000124
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature              Importance
------------------  -----------
second_char_vowel         0.676
consonants                0.000
dots                      0.000
even_odd                  0.000
first_char_vowel          0.000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3918367    0.4217687       0.4353741           0.4217687
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0000000           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.9991261
spaces                    0.0000189
vowel_consonant_ratio     0.0000130
even_odd                  0.0000124
consonants                0.0000124
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature              Importance
------------------  -----------
second_char_vowel         0.676
consonants                0.000
dots                      0.000
even_odd                  0.000
first_char_vowel          0.000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        2.7176471     2.764706        2.958823           0.3197279
first_char_vowel         1.1588235     1.235294        1.288235           0.1428571
words                    0.9823529     1.058823        1.105882           0.1224490
even_odd                 1.0058824     1.029412        1.082353           0.1190476
spaces                   1.0294118     1.029412        1.058823           0.1190476

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2   Agreement 
-----------------  ------------------  ----------  ----------
FEAT_IMP vs SHAP   second_char_vowel   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3945578    0.4013605       0.4081633           0.4013605
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0000000           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.9500013
first_char_vowel          0.0051986
vowel_consonant_ratio     0.0006111
length                    0.0002716
even_odd                  0.0002234
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.5976333
first_char_vowel          0.0035725
vowel_consonant_ratio     0.0006963
length                    0.0002083
even_odd                  0.0001288

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=multinom ===
Applying data scaling for method: multinom
# weights:  12 (11 variable)
initial  value 203.785271 
final  value 0.000047 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3918367    0.4217687       0.4353741           0.4217687
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0027211           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.9940673
first_char_vowel          0.0222836
consonants                0.0063195
vowel_consonant_ratio     0.0030785
words                     0.0021066
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.6754117
first_char_vowel          0.0032577
vowel_consonant_ratio     0.0023864
dots                      0.0014146
spaces                    0.0013507

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3918367    0.4217687       0.4353741           0.4217687
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0000000           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.9991261
spaces                    0.0000189
vowel_consonant_ratio     0.0000130
even_odd                  0.0000124
consonants                0.0000124
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature              Importance
------------------  -----------
second_char_vowel         0.676
consonants                0.000
dots                      0.000
even_odd                  0.000
first_char_vowel          0.000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
second_char_vowel                 38.9         45.0            49.5           0.3061224
first_char_vowel                  13.1         14.5            16.1           0.0986395
consonants                         2.7          3.5             4.0           0.0238095
vowel_consonant_ratio              2.6          3.5             4.0           0.0238095
length                             2.0          2.5             3.0           0.0170068

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
first_char_vowel          1.3134369
second_char_vowel         1.1775798
vowel_consonant_ratio     0.4250128
vowels                    0.3887826
dots                      0.3369976
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         1.4908302
vowel_consonant_ratio     0.9996553
first_char_vowel          0.7745460
vowels                    0.4828882
dots                      0.4743421

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: first_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   first_char_vowel    FALSE     
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       first_char_vowel    second_char_vowel   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===
Error in get_featimp: Lapack routine dgesv: system is exactly singular: U[4,4] = 0 

=== LIME Rankings ===
Error in get_lime: Lapack routine dgesv: system is exactly singular: U[4,4] = 0 
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: Lapack routine dgesv: system is exactly singular: U[4,4] = 0 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 0 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3755102    0.3945578       0.4136054           0.3945578
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0000000           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.8557649
first_char_vowel          0.1486997
consonants                0.0159629
length                    0.0128966
vowel_consonant_ratio     0.0108384
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel          0.499600
first_char_vowel           0.098612
vowel_consonant_ratio      0.013500
vowels                     0.010916
length                     0.006772

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
length                           1            1               1           0.2857143
even_odd                         1            1               1           0.2857143
first_char_vowel                 1            1               1           0.2857143
second_char_vowel                1            1               1           0.2857143
vowels                           1            1               1           0.2857143

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature             Importance
-----------------  -----------
consonants                   0
dots                         0
even_odd                     0
first_char_vowel             0
length                       0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: length
SHAP: consonants

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2    Agreement 
-----------------  ----------  -----------  ----------
FEAT_IMP vs SHAP   length      consonants   FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
second_char_vowel                110.2          117           122.8           0.3979592
first_char_vowel                   7.2            9            11.0           0.0306122
vowel_consonant_ratio              1.0            2             2.0           0.0068027
length                             1.0            1             1.8           0.0034014
even_odd                           1.0            1             1.0           0.0034014

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.3222773
first_char_vowel          0.2043118
consonants                0.0542815
length                    0.0320896
vowel_consonant_ratio     0.0154395
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.2109925
first_char_vowel          0.1809905
consonants                0.0228796
length                    0.0158861
vowel_consonant_ratio     0.0123426

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3918367    0.4217687       0.4353741           0.4217687
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0000000           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2   Agreement 
-----------------  ------------------  ----------  ----------
FEAT_IMP vs SHAP   second_char_vowel   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
second_char_vowel            0.3265306    0.3435374       0.3605442           0.3435374
first_char_vowel             0.0326531    0.0408163       0.0523810           0.0408163
vowel_consonant_ratio        0.0034014    0.0068027       0.0095238           0.0068027
length                       0.0000000    0.0000000       0.0000000           0.0000000
even_odd                     0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2   Agreement 
-----------------  ------------------  ----------  ----------
FEAT_IMP vs SHAP   second_char_vowel   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1684 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3659864     0.414966       0.4380952            0.414966
length                   0.0000000     0.000000       0.0000000            0.000000
even_odd                 0.0000000     0.000000       0.0000000            0.000000
first_char_vowel         0.0000000     0.000000       0.0000000            0.000000
vowels                   0.0000000     0.000000       0.0000000            0.000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2   Agreement 
-----------------  ------------------  ----------  ----------
FEAT_IMP vs SHAP   second_char_vowel   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel             48.5         51.0            55.3           0.3469388
first_char_vowel               6.7          9.0             9.9           0.0612245
length                         1.0          1.5             1.5           0.0102041
consonants                     1.0          1.5             2.0           0.0102041
even_odd                       1.0          1.0             1.4           0.0068027

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.8062219
first_char_vowel          0.5864260
vowel_consonant_ratio     0.0666858
vowels                    0.0171739
consonants                0.0132463
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
first_char_vowel          0.3604571
second_char_vowel         0.3558262
vowel_consonant_ratio     0.0653071
vowels                    0.0157262
consonants                0.0121299

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: first_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   first_char_vowel    FALSE     
LIME vs SHAP       second_char_vowel   first_char_vowel    FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=badges2, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
second_char_vowel        0.3918367    0.4217687       0.4353741           0.4217687
length                   0.0000000    0.0000000       0.0000000           0.0000000
even_odd                 0.0000000    0.0000000       0.0000000           0.0000000
first_char_vowel         0.0000000    0.0000000       0.0000000           0.0000000
vowels                   0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.9967942
first_char_vowel          0.0002060
consonants                0.0001038
length                    0.0000488
vowel_consonant_ratio     0.0000367
Warning messages:
1: spaces does not contain enough variance to use quantile binning. Using standard binning instead. 
2: dots does not contain enough variance to use quantile binning. Using standard binning instead. 
3: words does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
second_char_vowel         0.6744465
first_char_vowel          0.0001976
consonants                0.0000512
length                    0.0000311
vowel_consonant_ratio     0.0000301

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: second_char_vowel
LIME: second_char_vowel
SHAP: second_char_vowel

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   second_char_vowel   second_char_vowel   TRUE      
FEAT_IMP vs SHAP   second_char_vowel   second_char_vowel   TRUE      
LIME vs SHAP       second_char_vowel   second_char_vowel   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: banknote
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance        26.481818    26.863636       27.227273           0.4307580
skewness         8.490909     8.681818        9.218182           0.1392128
curtosis         7.418182     7.772727        8.318182           0.1246356
entropy          2.690909     2.772727        3.127273           0.0444606

=== LIME Rankings ===


Feature     Importance
---------  -----------
variance     0.4224288
skewness     0.2341382
curtosis     0.1452945
entropy      0.0154701

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.3181845
skewness     0.1227095
curtosis     0.0502634
entropy      0.0091824

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: variance
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    variance    TRUE      
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       variance    variance    TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance         3.290909     3.334928        3.359809           0.5080175
skewness         1.000000     1.000000        1.000000           0.1523324
curtosis         1.000000     1.000000        1.000000           0.1523324
entropy          1.000000     1.000000        1.000000           0.1523324

=== LIME Rankings ===


Feature     Importance
---------  -----------
variance     0.5280599
entropy      0.0105076
skewness     0.0083832
curtosis     0.0049166

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.3756954
curtosis     0.0000000
entropy      0.0000000
skewness     0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: variance
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    variance    TRUE      
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       variance    variance    TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2792            -nan     0.1000    0.0476
     2        1.2026            -nan     0.1000    0.0388
     3        1.1360            -nan     0.1000    0.0311
     4        1.0792            -nan     0.1000    0.0275
     5        1.0322            -nan     0.1000    0.0227
     6        0.9909            -nan     0.1000    0.0189
     7        0.9539            -nan     0.1000    0.0171
     8        0.9196            -nan     0.1000    0.0171
     9        0.8890            -nan     0.1000    0.0135
    10        0.8606            -nan     0.1000    0.0128
    20        0.6664            -nan     0.1000    0.0068
    40        0.4882            -nan     0.1000    0.0033
    50        0.4313            -nan     0.1000    0.0019



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance         8.663636     9.000000        9.354546           0.4329446
skewness         3.430303     3.621212        3.721212           0.1741983
curtosis         1.733333     1.833333        1.881818           0.0881924
entropy          1.000000     1.000000        1.000000           0.0481050

=== LIME Rankings ===


Feature     Importance
---------  -----------
variance     0.3929721
skewness     0.1933288
curtosis     0.0739150
entropy      0.0072737

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.2502435
skewness     0.1021610
curtosis     0.0330201
entropy      0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: variance
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    variance    TRUE      
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       variance    variance    TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance        0.3753644    0.3819242       0.3880466           0.3819242
skewness        0.3189504    0.3228863       0.3408163           0.3228863
curtosis        0.2295918    0.2441691       0.2523324           0.2441691
entropy         0.0138484    0.0182216       0.0199708           0.0182216
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature     Importance
---------  -----------
skewness     0.3606025
curtosis     0.3542827
variance     0.2828537
entropy      0.0469217

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.3039972
skewness     0.2382726
curtosis     0.2037354
entropy      0.0356883

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: variance
LIME: skewness
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    skewness    FALSE     
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       skewness    variance    FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance           103.96        105.0          106.16           0.3826531
skewness            59.48         62.8           64.48           0.2288630
curtosis            34.08         35.6           36.84           0.1297376
entropy              6.28          6.6            8.00           0.0240525

=== LIME Rankings ===


Feature     Importance
---------  -----------
variance     0.4052412
skewness     0.2804141
curtosis     0.2346763
entropy      0.0379316

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.3055282
skewness     0.1808234
curtosis     0.1031774
entropy      0.0060000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: variance
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    variance    TRUE      
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       variance    variance    TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance        3.1486631     3.229947       3.3090909           0.4402332
skewness        1.3165775     1.390374       1.4032086           0.1895044
entropy         1.0096257     1.026738       1.0406417           0.1399417
curtosis        0.9550802     0.973262       0.9871658           0.1326531

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: variance
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   variance    NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance         34.74667     34.93333       35.280000           0.3819242
skewness         30.70667     31.53333       32.040000           0.3447522
curtosis         17.57333     18.20000       19.040000           0.1989796
entropy           1.08000      1.20000        1.466667           0.0131195

=== LIME Rankings ===


Feature     Importance
---------  -----------
skewness     0.4023561
variance     0.3019748
curtosis     0.2529233
entropy      0.0163748

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
skewness     0.2743119
variance     0.2681865
curtosis     0.1077820
entropy      0.0082145

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: skewness
SHAP: skewness

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    skewness    FALSE     
FEAT_IMP vs SHAP   variance    skewness    FALSE     
LIME vs SHAP       skewness    skewness    TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=multinom ===
Applying data scaling for method: multinom
# weights:  6 (5 variable)
initial  value 950.997932 
iter  10 value 47.750897
iter  20 value 25.619616
iter  30 value 24.945378
final  value 24.945319 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance        47.472727    49.090909       50.490909           0.3935860
skewness        40.909091    41.636364       43.890909           0.3338192
curtosis        24.036364    24.909091       25.290909           0.1997085
entropy          1.145455     1.363636        1.509091           0.0109329

=== LIME Rankings ===


Feature     Importance
---------  -----------
skewness     0.4093093
variance     0.3050105
curtosis     0.2712722
entropy      0.0119576

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.3000392
skewness     0.1858237
curtosis     0.1175782
entropy      0.0094118

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: variance
LIME: skewness
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    skewness    FALSE     
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       skewness    variance    FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance        154.60000   156.000000      162.466667           0.3411079
skewness        112.33333   119.000000      121.866667           0.2602041
curtosis         57.93333    61.000000       66.066667           0.1333819
entropy           6.00000     7.666667        9.533333           0.0167638

=== LIME Rankings ===


Feature     Importance
---------  -----------
variance     0.3668580
skewness     0.2598506
curtosis     0.2252117
entropy      0.0138635

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.2767840
skewness     0.1382375
curtosis     0.0493958
entropy      0.0300546

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: variance
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    variance    TRUE      
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       variance    variance    TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance           61.400       63.000          64.350           0.3673469
skewness           30.825       31.750          34.350           0.1851312
curtosis           19.000       20.000          21.325           0.1166181
entropy             6.100        6.625           7.050           0.0386297

=== LIME Rankings ===


Feature     Importance
---------  -----------
variance     11.692082
skewness      7.627190
entropy       6.127167
curtosis      5.660923

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     18.089834
skewness      9.843150
entropy       6.446067
curtosis      5.004358

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: variance
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    variance    TRUE      
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       variance    variance    TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance            25.79        26.20           26.65           0.3819242
skewness            23.50        23.70           25.11           0.3454810
curtosis            15.71        15.95           16.96           0.2325073
entropy              1.06         1.10            1.15           0.0160350

=== LIME Rankings ===


Feature     Importance
---------  -----------
skewness     0.3585405
variance     0.2926974
curtosis     0.2609351
entropy      0.0171638

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.2775041
skewness     0.2346509
curtosis     0.1447577
entropy      0.0021184

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: variance
LIME: skewness
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    skewness    FALSE     
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       skewness    variance    FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance        0.3212828    0.3440233       0.3537901           0.3440233
skewness        0.2142857    0.2288630       0.2352770           0.2288630
curtosis        0.1023324    0.1086006       0.1141399           0.1086006
entropy         0.0021866    0.0029155       0.0034985           0.0029155
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature     Importance
---------  -----------
variance     0.3341057
skewness     0.3042218
curtosis     0.1612714
entropy      0.0179462

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance      0.227320
skewness      0.200800
curtosis      0.118992
entropy       0.017568

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: variance
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    variance    TRUE      
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       variance    variance    TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance                1            1               1           0.4446064
skewness                1            1               1           0.4446064
curtosis                1            1               1           0.4446064
entropy                 1            1               1           0.4446064

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
curtosis             0
entropy              0
skewness             0
variance             0

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP          -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: variance
SHAP: curtosis

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   variance    curtosis    FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance        2.6144928    2.6908213       2.7710145           0.4059767
skewness        1.5603865    1.5700483       1.6173913           0.2368805
entropy         0.9864734    0.9903382       0.9942029           0.1494169
curtosis        0.8521739    0.8985507       0.9178744           0.1355685

=== LIME Rankings ===


Feature     Importance
---------  -----------
variance     0.1877187
skewness     0.1302612
curtosis     0.0347925
entropy      0.0049987

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.1070738
skewness     0.0601604
curtosis     0.0167538
entropy      0.0013159

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: variance
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    variance    TRUE      
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       variance    variance    TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance       24.6380952    24.904762        25.39048           0.3811953
skewness       22.4476190    22.904762        24.41905           0.3505831
curtosis       13.3428571    13.571429        14.26667           0.2077259
entropy         0.9142857     0.952381         1.00000           0.0145773

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: variance
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   variance    NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance            92.88         93.2           97.20           0.3396501
skewness            79.72         84.0           85.84           0.3061224
curtosis            47.24         48.4           48.56           0.1763848
entropy              5.60          6.8            7.80           0.0247813

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: variance
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   variance    NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1941 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance           12.665       12.975          13.045           0.3782799
skewness            6.735        6.925           7.295           0.2018950
curtosis            2.695        2.825           2.825           0.0823615
entropy             1.000        1.000           1.000           0.0291545

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: variance
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   variance    NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance            220.0        222.5           226.2           0.3243440
skewness            168.7        177.5           178.9           0.2587464
curtosis             89.5         98.5            99.8           0.1435860
entropy              16.6         18.0            21.3           0.0262391

=== LIME Rankings ===


Feature     Importance
---------  -----------
variance     0.3782947
skewness     0.3307731
curtosis     0.2192327
entropy      0.0476573

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.2806397
skewness     0.2052381
curtosis     0.1103683
entropy      0.0465159

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: variance
LIME: variance
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    variance    TRUE      
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       variance    variance    TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=banknote, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
variance          32.8500      33.9375         34.6750           0.3957726
skewness          28.0250      28.4375         30.0625           0.3316327
curtosis          16.3625      17.1875         17.5500           0.2004373
entropy            0.7125       0.8125          0.9375           0.0094752

=== LIME Rankings ===


Feature     Importance
---------  -----------
skewness     0.4102589
variance     0.3046733
curtosis     0.2702280
entropy      0.0110345

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
variance     0.2944062
skewness     0.1929085
curtosis     0.1159677
entropy      0.0052080

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: variance
LIME: skewness
SHAP: variance

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   variance    skewness    FALSE     
FEAT_IMP vs SHAP   variance    variance    TRUE      
LIME vs SHAP       skewness    variance    FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: blood-transfusion-service-center
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V2              1.294040     1.317881        1.394702           0.2660428
V1              1.246358     1.271523        1.321854           0.2566845
V4              1.172185     1.211920        1.217218           0.2446524
V3              1.021192     1.026490        1.070199           0.2072193

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.1860827
V2          0.0788076
V4          0.0452469
V3          0.0184568

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.1624232
V2          0.1106591
V3          0.0740813
V4          0.0578638

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V2
LIME: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V2          V1          FALSE     
FEAT_IMP vs SHAP   V2          V1          FALSE     
LIME vs SHAP       V1          V1          TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.2379679
V2                     1            1               1           0.2379679
V3                     1            1               1           0.2379679
V4                     1            1               1           0.2379679

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.2451767
V2          0.0037501
V4          0.0029881
V3          0.0010337

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.1966287
V2          0.0000000
V3          0.0000000
V4          0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
LIME: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V1          V1          TRUE      
FEAT_IMP vs SHAP   V1          V1          TRUE      
LIME vs SHAP       V1          V1          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0801            -nan     0.1000    0.0092
     2        1.0640            -nan     0.1000    0.0070
     3        1.0514            -nan     0.1000    0.0059
     4        1.0406            -nan     0.1000    0.0046
     5        1.0315            -nan     0.1000    0.0035
     6        1.0242            -nan     0.1000    0.0035
     7        1.0168            -nan     0.1000    0.0022
     8        1.0111            -nan     0.1000    0.0021
     9        1.0047            -nan     0.1000    0.0014
    10        0.9994            -nan     0.1000    0.0017
    20        0.9686            -nan     0.1000   -0.0001
    40        0.9357            -nan     0.1000    0.0002
    50        0.9253            -nan     0.1000   -0.0003



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V2              1.085542     1.144578        1.149398           0.2540107
V1              1.032530     1.048193        1.059036           0.2326203
V4              1.007229     1.024096        1.028916           0.2272727
V3              1.000000     1.000000        1.000000           0.2219251

=== LIME Rankings ===


Feature    Importance
--------  -----------
V2          0.3189307
V1          0.1537266
V4          0.0670505
V3          0.0038035

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2          0.2786631
V1          0.1430158
V4          0.0695767
V3          0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V2
LIME: V2
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V2          V2          TRUE      
FEAT_IMP vs SHAP   V2          V2          TRUE      
LIME vs SHAP       V2          V2          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V2              1.397368     1.414474        1.502632           0.2874332
V4              1.218421     1.236842        1.350000           0.2513369
V1              1.107895     1.138158        1.165790           0.2312834
V3              1.000000     1.000000        1.000000           0.2032086

=== LIME Rankings ===


Feature    Importance
--------  -----------
V2          0.5358789
V1          0.1341520
V4          0.1088290
V3          0.0044785

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2          0.4156199
V1          0.1379582
V4          0.0964548
V3          0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V2
LIME: V2
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V2          V2          TRUE      
FEAT_IMP vs SHAP   V2          V2          TRUE      
LIME vs SHAP       V2          V2          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V2               1.32500     1.335526        1.378947           0.2713904
V1               1.22500     1.243421        1.317105           0.2526738
V4               1.15921     1.197368        1.203947           0.2433155
V3               1.00000     1.000000        1.000000           0.2032086

=== LIME Rankings ===


Feature    Importance
--------  -----------
V2          0.1612683
V1          0.1159735
V4          0.0165866
V3          0.0039356

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2          0.2172316
V1          0.1247311
V4          0.0628056
V3          0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V2
LIME: V2
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V2          V2          TRUE      
FEAT_IMP vs SHAP   V2          V2          TRUE      
LIME vs SHAP       V2          V2          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.2379679
V2                     1            1               1           0.2379679
V3                     1            1               1           0.2379679
V4                     1            1               1           0.2379679

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V3              1.237267     1.285714        1.320497           0.2767380
V4              1.201242     1.217391        1.288199           0.2620321
V2              1.137888     1.161491        1.211180           0.2500000
V1              1.074534     1.130435        1.165217           0.2433155

=== LIME Rankings ===


Feature    Importance
--------  -----------
V3          0.2429069
V2          0.2288704
V1          0.1447837
V4          0.0632679

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V3          0.1559030
V2          0.1373647
V1          0.1081067
V4          0.0404304

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V3
LIME: V3
SHAP: V3

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V3          V3          TRUE      
FEAT_IMP vs SHAP   V3          V3          TRUE      
LIME vs SHAP       V3          V3          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=multinom ===
Applying data scaling for method: multinom
# weights:  6 (5 variable)
initial  value 518.474091 
iter  10 value 353.933407
final  value 353.933398 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4             0.9953216     1.046784        1.086550           0.2393048
V3             0.9988304     1.040936        1.109941           0.2379679
V2             1.0093567     1.023392        1.059649           0.2339572
V1             1.0000000     1.005848        1.021053           0.2299465

=== LIME Rankings ===


Feature    Importance
--------  -----------
V3          0.2758613
V2          0.2754306
V1          0.1811706
V4          0.0909335

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2          0.2184259
V3          0.2112508
V1          0.1407171
V4          0.0754029

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V3
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V3          FALSE     
FEAT_IMP vs SHAP   V4          V2          FALSE     
LIME vs SHAP       V3          V2          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V2              1.262025     1.303797        1.340506           0.2754011
V1              1.224051     1.234177        1.321519           0.2606952
V4              1.132911     1.170886        1.183544           0.2473262
V3              1.000000     1.000000        1.000000           0.2112299

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.1848012
V2          0.1137530
V4          0.0285501
V3          0.0028975

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2          0.1633950
V1          0.1567625
V4          0.0326129
V3          0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V2
LIME: V1
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V2          V1          FALSE     
FEAT_IMP vs SHAP   V2          V2          TRUE      
LIME vs SHAP       V1          V2          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              2.291139     2.316456        2.412658           0.2446524
V1              2.212658     2.278481        2.412658           0.2406417
V2              2.091139     2.126582        2.250633           0.2245989
V3              2.086076     2.126582        2.159494           0.2245989

=== LIME Rankings ===


Feature    Importance
--------  -----------
V3          0.1524091
V2          0.1510990
V4          0.1354757
V1          0.1082556

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.3250327
V3          0.3039343
V4          0.2505115
V2          0.1728757

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V3
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V3          FALSE     
FEAT_IMP vs SHAP   V4          V1          FALSE     
LIME vs SHAP       V3          V1          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===
Error in get_featimp: system is computationally singular: reciprocal condition number = 2.43872e-17 

=== LIME Rankings ===
Error in get_lime: system is computationally singular: reciprocal condition number = 2.43872e-17 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: system is computationally singular: reciprocal condition number = 2.43872e-17 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 0 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              2.618461     2.646154        2.707692           0.2299465
V1              2.341538     2.569231        2.729231           0.2232620
V2              2.163077     2.323077        2.369231           0.2018717
V3              2.123077     2.153846        2.344615           0.1871658

=== LIME Rankings ===


Feature    Importance
--------  -----------
V2          0.1581283
V3          0.1453324
V1          0.0900041
V4          0.0519854

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2           0.208088
V3           0.187448
V1           0.148016
V4           0.078508

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V2
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V2          FALSE     
FEAT_IMP vs SHAP   V4          V2          FALSE     
LIME vs SHAP       V2          V2          TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.2379679
V2                     1            1               1           0.2379679
V3                     1            1               1           0.2379679
V4                     1            1               1           0.2379679

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1                  0
V2                  0
V3                  0
V4                  0

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP           1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          V1          TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V3             1.0245614     1.029240        1.053801           0.2352941
V2             0.9964912     1.023392        1.042105           0.2339572
V1             1.0070175     1.017544        1.022222           0.2326203
V4             1.0011696     1.005848        1.016374           0.2299465

=== LIME Rankings ===


Feature    Importance
--------  -----------
V2          0.1101172
V3          0.1097862
V1          0.0594800
V4          0.0062392

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2          0.0820651
V3          0.0815249
V1          0.0321411
V4          0.0040698

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V3
LIME: V2
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V3          V2          FALSE     
FEAT_IMP vs SHAP   V3          V2          FALSE     
LIME vs SHAP       V2          V2          TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.2379679
V2                     1            1               1           0.2379679
V3                     1            1               1           0.2379679
V4                     1            1               1           0.2379679

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              1.001191     1.083333        1.126191           0.2433155
V1              1.029762     1.059524        1.075000           0.2379679
V2              1.041667     1.041667        1.080952           0.2339572
V3              1.007143     1.035714        1.052381           0.2326203

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V4          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1998 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V3              1.244898     1.292517        1.359184           0.2540107
V4              1.227211     1.278912        1.312925           0.2513369
V1              1.185034     1.204082        1.227211           0.2366310
V2              1.058503     1.081633        1.100680           0.2125668

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V3
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V3          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V3              1.280000     1.400000        1.411429           0.2620321
V2              1.298571     1.378571        1.420000           0.2580214
V4              1.230000     1.235714        1.348571           0.2312834
V1              1.167143     1.214286        1.338571           0.2272727

=== LIME Rankings ===


Feature    Importance
--------  -----------
V2          0.2310963
V3          0.2293206
V1          0.1570022
V4          0.0788315

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V3          0.1552860
V1          0.1495917
V2          0.1348849
V4          0.0794976

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V3
LIME: V2
SHAP: V3

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V3          V2          FALSE     
FEAT_IMP vs SHAP   V3          V3          TRUE      
LIME vs SHAP       V2          V3          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=blood-transfusion-service-center, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V3              1.000000     1.052941        1.102353           0.2393048
V4              1.000000     1.047059        1.087059           0.2379679
V2              1.010588     1.035294        1.060000           0.2352941
V1              1.005882     1.011765        1.027059           0.2299465

=== LIME Rankings ===


Feature    Importance
--------  -----------
V3          0.2728897
V2          0.2724930
V1          0.1802687
V4          0.0893961

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2          0.2162649
V3          0.2091077
V1          0.1396078
V4          0.0744509

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V3
LIME: V3
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V3          V3          TRUE      
FEAT_IMP vs SHAP   V3          V2          FALSE     
LIME vs SHAP       V3          V2          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: breast-w
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Cell_Size_Uniformity          8.444444     8.722222        9.433333           0.2298682
Bare_Nuclei                   3.933333     4.277778        4.477778           0.1127379
Cell_Shape_Uniformity         2.177778     2.277778        2.277778           0.0600293
Clump_Thickness               1.511111     1.555556        1.655556           0.0409956
Marginal_Adhesion             1.000000     1.000000        1.000000           0.0263543

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Shape_Uniformity     0.1106342
Clump_Thickness           0.0754244
Cell_Size_Uniformity      0.0633984
Bare_Nuclei               0.0419151
Bland_Chromatin           0.0289188
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Size_Uniformity      0.2107000
Bare_Nuclei               0.1090606
Cell_Shape_Uniformity     0.0965136
Clump_Thickness           0.0538333
Normal_Nucleoli           0.0146667

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Cell_Size_Uniformity
LIME: Cell_Shape_Uniformity
SHAP: Cell_Size_Uniformity

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1               Feature_2               Agreement 
-----------------  ----------------------  ----------------------  ----------
FEAT_IMP vs LIME   Cell_Size_Uniformity    Cell_Shape_Uniformity   FALSE     
FEAT_IMP vs SHAP   Cell_Size_Uniformity    Cell_Size_Uniformity    TRUE      
LIME vs SHAP       Cell_Shape_Uniformity   Cell_Size_Uniformity    FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Cell_Size_Uniformity              6.15         6.25            6.75           0.4392387
Clump_Thickness                   1.00         1.00            1.00           0.0702782
Cell_Shape_Uniformity             1.00         1.00            1.00           0.0702782
Marginal_Adhesion                 1.00         1.00            1.00           0.0702782
Single_Epi_Cell_Size              1.00         1.00            1.00           0.0702782

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
Cell_Size_Uniformity     0.5079579
Single_Epi_Cell_Size     0.0181585
Mitoses                  0.0152805
Bare_Nuclei              0.0145044
Clump_Thickness          0.0121528
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Size_Uniformity      0.5268547
Bare_Nuclei               0.0000000
Bland_Chromatin           0.0000000
Cell_Shape_Uniformity     0.0000000
Clump_Thickness           0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Cell_Size_Uniformity
LIME: Cell_Size_Uniformity
SHAP: Cell_Size_Uniformity

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   Cell_Size_Uniformity   Cell_Size_Uniformity   TRUE      
FEAT_IMP vs SHAP   Cell_Size_Uniformity   Cell_Size_Uniformity   TRUE      
LIME vs SHAP       Cell_Size_Uniformity   Cell_Size_Uniformity   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.1546            -nan     0.1000    0.0653
     2        1.0459            -nan     0.1000    0.0526
     3        0.9515            -nan     0.1000    0.0464
     4        0.8705            -nan     0.1000    0.0376
     5        0.8029            -nan     0.1000    0.0334
     6        0.7404            -nan     0.1000    0.0298
     7        0.6875            -nan     0.1000    0.0238
     8        0.6419            -nan     0.1000    0.0232
     9        0.5991            -nan     0.1000    0.0206
    10        0.5632            -nan     0.1000    0.0181
    20        0.3475            -nan     0.1000    0.0056
    40        0.2027            -nan     0.1000    0.0009
    50        0.1780            -nan     0.1000   -0.0001



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                  1.3090909     1.454546        1.618182           0.0468521
Cell_Size_Uniformity         1.2090909     1.363636        1.400000           0.0439239
Clump_Thickness              0.9727273     1.272727        1.318182           0.0409956
Cell_Shape_Uniformity        1.1454545     1.272727        1.345454           0.0409956
Bland_Chromatin              1.0545455     1.136364        1.181818           0.0366032

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Size_Uniformity      0.1842686
Bare_Nuclei               0.1647818
Cell_Shape_Uniformity     0.1121866
Marginal_Adhesion         0.0825884
Normal_Nucleoli           0.0746072
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.1191841
Cell_Size_Uniformity      0.1165099
Cell_Shape_Uniformity     0.0746217
Normal_Nucleoli           0.0273312
Bland_Chromatin           0.0265971

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
LIME: Cell_Size_Uniformity
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   Bare_Nuclei            Cell_Size_Uniformity   FALSE     
FEAT_IMP vs SHAP   Bare_Nuclei            Bare_Nuclei            TRUE      
LIME vs SHAP       Cell_Size_Uniformity   Bare_Nuclei            FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                   2.246154     2.461539        2.584615           0.0468521
Clump_Thickness               2.092308     2.384615        2.753846           0.0453880
Normal_Nucleoli               1.861538     1.923077        2.215385           0.0366032
Cell_Shape_Uniformity         1.492308     1.692308        1.692308           0.0322108
Bland_Chromatin               1.538461     1.615385        1.692308           0.0307467

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Marginal_Adhesion         0.2169414
Normal_Nucleoli           0.1510968
Bare_Nuclei               0.1369414
Cell_Shape_Uniformity     0.1247936
Cell_Size_Uniformity      0.0920472
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.1119324
Normal_Nucleoli           0.1038233
Cell_Shape_Uniformity     0.0730856
Clump_Thickness           0.0709422
Cell_Size_Uniformity      0.0585871

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
LIME: Marginal_Adhesion
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   Bare_Nuclei         Marginal_Adhesion   FALSE     
FEAT_IMP vs SHAP   Bare_Nuclei         Bare_Nuclei         TRUE      
LIME vs SHAP       Marginal_Adhesion   Bare_Nuclei         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                   5.470588     5.705882        5.764706           0.1420205
Cell_Shape_Uniformity         2.235294     2.235294        2.482353           0.0556369
Single_Epi_Cell_Size          1.423529     1.529412        1.682353           0.0380673
Clump_Thickness               1.294118     1.411765        1.411765           0.0351391
Cell_Size_Uniformity          1.188235     1.294118        1.352941           0.0322108

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.2479628
Cell_Shape_Uniformity     0.2397809
Cell_Size_Uniformity      0.1368730
Clump_Thickness           0.0831412
Single_Epi_Cell_Size      0.0645432
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.2242746
Cell_Shape_Uniformity     0.1279018
Bland_Chromatin           0.0360339
Single_Epi_Cell_Size      0.0358974
Cell_Size_Uniformity      0.0355828

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
LIME: Bare_Nuclei
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   Bare_Nuclei   Bare_Nuclei   TRUE      
FEAT_IMP vs SHAP   Bare_Nuclei   Bare_Nuclei   TRUE      
LIME vs SHAP       Bare_Nuclei   Bare_Nuclei   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                   1.521739     1.565217        1.695652           0.0527086
Clump_Thickness               1.347826     1.347826        1.469565           0.0453880
Cell_Size_Uniformity          1.191304     1.304348        1.347826           0.0439239
Cell_Shape_Uniformity         1.173913     1.260870        1.260870           0.0424597
Bland_Chromatin               1.139130     1.217391        1.426087           0.0409956

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2   Agreement 
-----------------  ------------  ----------  ----------
FEAT_IMP vs SHAP   Bare_Nuclei   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                   3.276923     3.538461        3.815385           0.0673499
Cell_Size_Uniformity          2.400000     2.692308        2.815385           0.0512445
Cell_Shape_Uniformity         1.969231     2.615385        2.753846           0.0497804
Mitoses                       1.753846     2.076923        2.200000           0.0395315
Clump_Thickness               1.630769     1.692308        1.769231           0.0322108

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Shape_Uniformity     0.2112555
Bare_Nuclei               0.2094388
Cell_Size_Uniformity      0.2027040
Mitoses                   0.1832605
Marginal_Adhesion         0.1108517
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.1725596
Cell_Shape_Uniformity     0.0980346
Cell_Size_Uniformity      0.0910437
Clump_Thickness           0.0400286
Normal_Nucleoli           0.0309508

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
LIME: Cell_Shape_Uniformity
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1               Feature_2               Agreement 
-----------------  ----------------------  ----------------------  ----------
FEAT_IMP vs LIME   Bare_Nuclei             Cell_Shape_Uniformity   FALSE     
FEAT_IMP vs SHAP   Bare_Nuclei             Bare_Nuclei             TRUE      
LIME vs SHAP       Cell_Shape_Uniformity   Bare_Nuclei             FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=multinom ===
Applying data scaling for method: multinom
# weights:  11 (10 variable)
initial  value 473.419524 
iter  10 value 68.739638
iter  20 value 51.447194
final  value 51.444095 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
Clump_Thickness           1.361905     1.571429        1.619048           0.0483163
Bare_Nuclei               1.361905     1.476190        1.571429           0.0453880
Bland_Chromatin           1.114286     1.285714        1.323810           0.0395315
Mitoses                   1.190476     1.190476        1.371429           0.0366032
Marginal_Adhesion         1.057143     1.095238        1.142857           0.0336750

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Mitoses                   0.3053548
Bare_Nuclei               0.2373121
Marginal_Adhesion         0.2017637
Cell_Shape_Uniformity     0.1927237
Normal_Nucleoli           0.1316261
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.1333537
Cell_Shape_Uniformity     0.0909257
Clump_Thickness           0.0787438
Normal_Nucleoli           0.0489629
Marginal_Adhesion         0.0450854

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Clump_Thickness
LIME: Mitoses
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2     Agreement 
-----------------  ----------------  ------------  ----------
FEAT_IMP vs LIME   Clump_Thickness   Mitoses       FALSE     
FEAT_IMP vs SHAP   Clump_Thickness   Bare_Nuclei   FALSE     
LIME vs SHAP       Mitoses           Bare_Nuclei   FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Cell_Shape_Uniformity             9.60         10.8           11.80           0.0790630
Marginal_Adhesion                 6.68          7.6            9.72           0.0556369
Clump_Thickness                   5.80          6.8            7.32           0.0497804
Bare_Nuclei                       5.00          5.0            5.52           0.0366032
Cell_Size_Uniformity              4.04          4.4            6.12           0.0322108

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Size_Uniformity      0.1973860
Cell_Shape_Uniformity     0.1265723
Marginal_Adhesion         0.1230453
Bare_Nuclei               0.0766155
Clump_Thickness           0.0485343
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Shape_Uniformity     0.1089559
Clump_Thickness           0.0941031
Cell_Size_Uniformity      0.0865575
Marginal_Adhesion         0.0746076
Bare_Nuclei               0.0691789

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Cell_Shape_Uniformity
LIME: Cell_Size_Uniformity
SHAP: Cell_Shape_Uniformity

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1               Feature_2               Agreement 
-----------------  ----------------------  ----------------------  ----------
FEAT_IMP vs LIME   Cell_Shape_Uniformity   Cell_Size_Uniformity    FALSE     
FEAT_IMP vs SHAP   Cell_Shape_Uniformity   Cell_Shape_Uniformity   TRUE      
LIME vs SHAP       Cell_Size_Uniformity    Cell_Shape_Uniformity   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Cell_Size_Uniformity          3.126316     3.315790        3.357895           0.0922401
Normal_Nucleoli               3.084211     3.263158        3.568421           0.0907760
Cell_Shape_Uniformity         2.894737     3.000000        3.484211           0.0834553
Bare_Nuclei                   2.547368     2.736842        2.957895           0.0761347
Mitoses                       1.378947     1.684211        1.810526           0.0468521

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei                2.727394
Cell_Size_Uniformity       2.616163
Cell_Shape_Uniformity      2.613401
Mitoses                    2.573918
Marginal_Adhesion          2.546373
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Clump_Thickness           11.886075
Bland_Chromatin           11.573643
Marginal_Adhesion          7.238285
Cell_Shape_Uniformity      5.527744
Normal_Nucleoli            3.961604

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 0
LIME vs SHAP              NA                 0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Cell_Size_Uniformity
LIME: Bare_Nuclei
SHAP: Clump_Thickness

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2         Agreement 
-----------------  ---------------------  ----------------  ----------
FEAT_IMP vs LIME   Cell_Size_Uniformity   Bare_Nuclei       FALSE     
FEAT_IMP vs SHAP   Cell_Size_Uniformity   Clump_Thickness   FALSE     
LIME vs SHAP       Bare_Nuclei            Clump_Thickness   FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Cell_Size_Uniformity          4.471429     4.928571        5.100000           0.2020498
Bare_Nuclei                   4.228571     4.750000        4.778571           0.1947291
Cell_Shape_Uniformity         4.250000     4.464286        4.814286           0.1830161
Normal_Nucleoli               3.928571     4.000000        4.221429           0.1639824
Marginal_Adhesion             3.185714     3.392857        3.485714           0.1390922

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Size_Uniformity      0.1503854
Bare_Nuclei               0.1489349
Cell_Shape_Uniformity     0.1416847
Normal_Nucleoli           0.1369116
Marginal_Adhesion         0.1322501
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.1006535
Cell_Shape_Uniformity     0.0918153
Cell_Size_Uniformity      0.0895755
Normal_Nucleoli           0.0867703
Single_Epi_Cell_Size      0.0782211

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 3
FEAT_IMP vs SHAP        -0.5                 3
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Cell_Size_Uniformity
LIME: Cell_Size_Uniformity
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   Cell_Size_Uniformity   Cell_Size_Uniformity   TRUE      
FEAT_IMP vs SHAP   Cell_Size_Uniformity   Bare_Nuclei            FALSE     
LIME vs SHAP       Cell_Size_Uniformity   Bare_Nuclei            FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                  0.0240117    0.0263543       0.0363104           0.0263543
Cell_Shape_Uniformity        0.0108346    0.0146413       0.0172767           0.0146413
Cell_Size_Uniformity         0.0117130    0.0131772       0.0146413           0.0131772
Clump_Thickness              0.0064422    0.0117130       0.0143485           0.0117130
Marginal_Adhesion            0.0046852    0.0058565       0.0105417           0.0058565
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.1571123
Cell_Size_Uniformity      0.1449732
Cell_Shape_Uniformity     0.1180305
Normal_Nucleoli           0.0644874
Marginal_Adhesion         0.0635592
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei                0.088520
Cell_Size_Uniformity       0.067040
Cell_Shape_Uniformity      0.039924
Clump_Thickness            0.029700
Bland_Chromatin            0.029384

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
LIME: Bare_Nuclei
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   Bare_Nuclei   Bare_Nuclei   TRUE      
FEAT_IMP vs SHAP   Bare_Nuclei   Bare_Nuclei   TRUE      
LIME vs SHAP       Bare_Nuclei   Bare_Nuclei   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Clump_Thickness                      1            1               1           0.3499268
Cell_Size_Uniformity                 1            1               1           0.3499268
Cell_Shape_Uniformity                1            1               1           0.3499268
Marginal_Adhesion                    1            1               1           0.3499268
Single_Epi_Cell_Size                 1            1               1           0.3499268

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei                       0
Bland_Chromatin                   0
Cell_Shape_Uniformity             0
Cell_Size_Uniformity              0
Clump_Thickness                   0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Clump_Thickness
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2     Agreement 
-----------------  ----------------  ------------  ----------
FEAT_IMP vs SHAP   Clump_Thickness   Bare_Nuclei   FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                  1.2933333     1.400000        1.466667           0.0614934
Clump_Thickness              1.2333333     1.266667        1.300000           0.0556369
Bland_Chromatin              0.9800000     1.100000        1.126667           0.0483163
Cell_Shape_Uniformity        1.0000000     1.066667        1.093333           0.0468521
Marginal_Adhesion            0.9533333     1.066667        1.206667           0.0468521

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Size_Uniformity      0.0474556
Cell_Shape_Uniformity     0.0473788
Mitoses                   0.0440122
Marginal_Adhesion         0.0428008
Normal_Nucleoli           0.0417172
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Cell_Shape_Uniformity     0.0286742
Cell_Size_Uniformity      0.0285920
Bare_Nuclei               0.0248941
Normal_Nucleoli           0.0205328
Single_Epi_Cell_Size      0.0197886

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
LIME: Cell_Size_Uniformity
SHAP: Cell_Shape_Uniformity

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2               Agreement 
-----------------  ---------------------  ----------------------  ----------
FEAT_IMP vs LIME   Bare_Nuclei            Cell_Size_Uniformity    FALSE     
FEAT_IMP vs SHAP   Bare_Nuclei            Cell_Shape_Uniformity   FALSE     
LIME vs SHAP       Cell_Size_Uniformity   Cell_Shape_Uniformity   FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                   1.568421     1.842105        1.947368           0.0512445
Clump_Thickness               1.400000     1.578947        1.673684           0.0439239
Bland_Chromatin               1.010526     1.315789        1.357895           0.0366032
Cell_Shape_Uniformity         1.063158     1.105263        1.157895           0.0307467
Marginal_Adhesion             1.010526     1.105263        1.157895           0.0307467

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2   Agreement 
-----------------  ------------  ----------  ----------
FEAT_IMP vs SHAP   Bare_Nuclei   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                   4.846154     5.038462        5.107692           0.1918009
Cell_Size_Uniformity          4.507692     4.615385        4.846154           0.1756955
Cell_Shape_Uniformity         4.076923     4.230769        4.500000           0.1610542
Normal_Nucleoli               3.823077     4.115385        4.330769           0.1566618
Marginal_Adhesion             3.338462     3.807692        3.961539           0.1449488

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2   Agreement 
-----------------  ------------  ----------  ----------
FEAT_IMP vs SHAP   Bare_Nuclei   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
Clump_Thickness               5.000000     5.307692        5.784615           0.1010249
Bare_Nuclei                   4.123077     5.076923        5.738461           0.0966325
Cell_Size_Uniformity          1.984615     2.307692        2.553846           0.0439239
Cell_Shape_Uniformity         2.123077     2.307692        2.661538           0.0439239
Single_Epi_Cell_Size          1.584615     1.923077        1.923077           0.0366032

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Clump_Thickness
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2   Agreement 
-----------------  ----------------  ----------  ----------
FEAT_IMP vs SHAP   Clump_Thickness   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                 1.9000000     2.000000        2.433333           0.0527086
Clump_Thickness             1.5555556     1.611111        1.666667           0.0424597
Single_Epi_Cell_Size        0.9555556     1.111111        1.166667           0.0292826
Mitoses                     0.9222222     1.111111        1.155556           0.0292826
Cell_Size_Uniformity        0.9111111     1.055556        1.100000           0.0278184

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.2866941
Normal_Nucleoli           0.1883587
Marginal_Adhesion         0.1838039
Mitoses                   0.1606850
Cell_Shape_Uniformity     0.1430547
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.1016667
Normal_Nucleoli           0.0672286
Cell_Shape_Uniformity     0.0506667
Cell_Size_Uniformity      0.0454381
Marginal_Adhesion         0.0297556

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
LIME: Bare_Nuclei
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   Bare_Nuclei   Bare_Nuclei   TRUE      
FEAT_IMP vs SHAP   Bare_Nuclei   Bare_Nuclei   TRUE      
LIME vs SHAP       Bare_Nuclei   Bare_Nuclei   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=breast-w, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
Bare_Nuclei                      1.48         1.65            1.69           0.0483163
Clump_Thickness                  1.47         1.60            1.78           0.0468521
Bland_Chromatin                  1.15         1.25            1.38           0.0366032
Cell_Size_Uniformity             1.05         1.05            1.10           0.0307467
Marginal_Adhesion                1.05         1.05            1.09           0.0307467

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
Mitoses                   0.2662438
Bare_Nuclei               0.2433729
Marginal_Adhesion         0.1875501
Cell_Shape_Uniformity     0.1722463
Normal_Nucleoli           0.1296781
Warning message:
Mitoses does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
Bare_Nuclei               0.1345060
Cell_Shape_Uniformity     0.0793137
Clump_Thickness           0.0763421
Normal_Nucleoli           0.0463495
Marginal_Adhesion         0.0413015

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Bare_Nuclei
LIME: Mitoses
SHAP: Bare_Nuclei

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   Bare_Nuclei   Mitoses       FALSE     
FEAT_IMP vs SHAP   Bare_Nuclei   Bare_Nuclei   TRUE      
LIME vs SHAP       Mitoses       Bare_Nuclei   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: cardiotocography
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V27            0.3273754    0.3367827       0.3516463           0.3367827
V35            0.1629351    0.1655691       0.1680151           0.1655691
V31            0.1570085    0.1613358       0.1669802           0.1613358
V32            0.1464722    0.1509878       0.1537159           0.1509878
V29            0.0667921    0.0682032       0.0701787           0.0682032
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V31         0.5855810
V34         0.1952645
V27         0.1952184
V1          0.0000284
V24         0.0000262
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31             0.276
V27             0.216
V34             0.180
V35             0.064
V32             0.048

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V27
LIME: V31
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V27         V31         FALSE     
FEAT_IMP vs SHAP   V27         V31         FALSE     
LIME vs SHAP       V31         V31         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=fda ===
No scaling applied for method: fda
Error in get(ctr, mode = "function", envir = parent.frame()) : 
  object 'contr.earth.response' of mode 'function' was not found
Calls: train_model ... model.matrix -> model.matrix.default -> contrasts -> get
Execution halted
FAILED - See error above


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        2.3026            -nan     0.1000    1.5560
     2        1.3769            -nan     0.1000    0.6200
     3        1.0251            -nan     0.1000    0.4055
     4        0.7950            -nan     0.1000    0.2936
     5        0.6286            -nan     0.1000    0.2221
     6        0.5024            -nan     0.1000    0.1728
     7        0.4044            -nan     0.1000    0.1360
     8        0.3269            -nan     0.1000    0.1084
     9        0.2652            -nan     0.1000    0.0868
    10        0.2155            -nan     0.1000    0.0702
    20        0.0285            -nan     0.1000    0.0090
    40        0.0005            -nan     0.1000    0.0002
    50        0.0001            -nan     0.1000    0.0000



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V27            0.2379116    0.2474130       0.2519285           0.2474130
V26            0.2141110    0.2253057       0.2287865           0.2253057
V32            0.2000000    0.2013170       0.2078081           0.2013170
V35            0.1467545    0.1514581       0.1556914           0.1514581
V33            0.0942615    0.0950141       0.0974600           0.0950141
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V31         0.5255905
V34         0.1752625
V27         0.1752244
V1          0.0000276
V18         0.0000265
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31         0.3439809
V27         0.1833877
V34         0.1429919
V26         0.0433963
V32         0.0407965

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V27
LIME: V31
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V27         V31         FALSE     
FEAT_IMP vs SHAP   V27         V31         FALSE     
LIME vs SHAP       V31         V31         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning messages:
1: glm.fit: fitted probabilities numerically 0 or 1 occurred 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
3: glm.fit: fitted probabilities numerically 0 or 1 occurred 
4: glm.fit: fitted probabilities numerically 0 or 1 occurred 
5: glm.fit: fitted probabilities numerically 0 or 1 occurred 
6: glm.fit: fitted probabilities numerically 0 or 1 occurred 
7: glm.fit: fitted probabilities numerically 0 or 1 occurred 
8: glm.fit: fitted probabilities numerically 0 or 1 occurred 
9: glm.fit: fitted probabilities numerically 0 or 1 occurred 
10: glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V27            0.3400753    0.3428975       0.3649106           0.3428975
V26            0.2921919    0.2953904       0.2961430           0.2953904
V31            0.1756350    0.1792098       0.1848542           0.1792098
V32            0.1279398    0.1288805       0.1297272           0.1288805
V35            0.0842897    0.0865475       0.0869238           0.0865475
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V31         0.4978614
V27         0.2092602
V34         0.2042162
V30         0.0919878
V26         0.0919808
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31             0.402
V27             0.187
V26             0.096
V32             0.067
V35             0.041

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP        -0.5                 3
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V27
LIME: V31
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V27         V31         FALSE     
FEAT_IMP vs SHAP   V27         V31         FALSE     
LIME vs SHAP       V31         V31         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V31            0.2039511    0.2064911       0.2099718           0.2064911
V26            0.1921919    0.1966134       0.1973659           0.1966134
V32            0.1743180    0.1773283       0.1812794           0.1773283
V35            0.1431797    0.1467545       0.1500470           0.1467545
V33            0.0854186    0.0874882       0.0906867           0.0874882
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31             0.436
V34             0.200
V32             0.066
V35             0.050
V26             0.046

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP           1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: V31
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V31         V31         TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V26                 86.8         91.0            96.2           0.0856068
V35                 81.5         82.5            86.1           0.0776105
V32                 77.2         78.5            80.1           0.0738476
V31                 68.0         69.5            71.3           0.0653810
V30                 55.1         58.5            59.3           0.0550329

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
There were 13 warnings (use warnings() to see them)

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V26
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V26         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V27             2.001890     2.056693        2.085984           0.6142992
V26             1.799685     1.815748        1.831496           0.5423330
V35             1.277480     1.280315        1.284094           0.3824083
V16             1.162205     1.171653        1.184882           0.3499530
V32             1.081890     1.091339        1.105512           0.3259643

=== LIME Rankings ===


Feature    Importance
--------  -----------
V27         0.2246018
V14         0.0590320
V26         0.0512128
V31         0.0155515
V34         0.0143756
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V27         0.1367567
V31         0.0335966
V26         0.0312684
V32         0.0050428
V16         0.0043915

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V27
LIME: V27
SHAP: V27

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V27         V27         TRUE      
FEAT_IMP vs SHAP   V27         V27         TRUE      
LIME vs SHAP       V27         V27         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=multinom ===
Applying data scaling for method: multinom
# weights:  370 (324 variable)
initial  value 4895.295908 
iter  10 value 0.155356
iter  20 value 0.051713
iter  30 value 0.026005
iter  40 value 0.010958
iter  50 value 0.003979
iter  60 value 0.002912
iter  70 value 0.001218
iter  80 value 0.000932
iter  90 value 0.000349
iter 100 value 0.000318
final  value 0.000318 
stopped after 100 iterations


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V27            0.1547507    0.1674506       0.1719661           0.1674506
V32            0.1233302    0.1265287       0.1285042           0.1265287
V26            0.1181562    0.1190028       0.1249294           0.1190028
V35            0.0958608    0.0992474       0.1027281           0.0992474
V31            0.0913452    0.0978363       0.1021637           0.0978363
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V31         0.4050342
V34         0.2194361
V27         0.1798141
V14         0.1021698
V7          0.0958986
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31         0.3352077
V27         0.1801584
V34         0.1531197
V32         0.0414023
V35         0.0320390

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V27
LIME: V31
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V27         V31         FALSE     
FEAT_IMP vs SHAP   V27         V31         FALSE     
LIME vs SHAP       V31         V31         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V27            0.3400753    0.3428975       0.3649106           0.3428975
V26            0.2921919    0.2953904       0.2961430           0.2953904
V31            0.1900282    0.1937912       0.2001881           0.1937912
V32            0.1279398    0.1288805       0.1297272           0.1288805
V33            0.0509878    0.0526811       0.0585136           0.0526811
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V31         0.5855810
V34         0.1952645
V27         0.1952184
V1          0.0000284
V24         0.0000262
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31             0.368
V27             0.226
V34             0.104
V26             0.104
V32             0.020

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V27
LIME: V31
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V27         V31         FALSE     
FEAT_IMP vs SHAP   V27         V31         FALSE     
LIME vs SHAP       V31         V31         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V26                51.60        52.00           53.75           0.0978363
V30                30.45        31.50           34.15           0.0592662
V29                31.00        31.25           32.10           0.0587959
V32                28.25        29.50           30.15           0.0555033
V34                26.15        27.50           28.80           0.0517404

=== LIME Rankings ===


Feature    Importance
--------  -----------
V31        13.8526076
V34         4.4207476
V27         4.3154728
V14         0.3183470
V7          0.2985612
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31          3.162182
V34          2.199553
V12          1.782820
V27          1.627963
V26          1.106095

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP          NA                 0
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V26
LIME: V31
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V26         V31         FALSE     
FEAT_IMP vs SHAP   V26         V31         FALSE     
LIME vs SHAP       V31         V31         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===
Error in get_featimp: Lapack routine dgesv: system is exactly singular: U[14,14] = 0 

=== LIME Rankings ===
Error in get_lime: Lapack routine dgesv: system is exactly singular: U[14,14] = 0 
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: Lapack routine dgesv: system is exactly singular: U[14,14] = 0 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 0 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V27            0.1440263    0.1491063       0.1568203           0.1491063
V26            0.1417686    0.1453434       0.1476952           0.1453434
V35            0.0514581    0.0526811       0.0535278           0.0526811
V32            0.0132643    0.0141110       0.0154280           0.0141110
V31            0.0039511    0.0051740       0.0056444           0.0051740
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V31         0.4641711
V27         0.1678228
V34         0.1433258
V6          0.0373186
V10         0.0169797
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31          0.275896
V27          0.143348
V6           0.057212
V13          0.048752
V34          0.037872

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V27
LIME: V31
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V27         V31         FALSE     
FEAT_IMP vs SHAP   V27         V31         FALSE     
LIME vs SHAP       V31         V31         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.7276576
V2                     1            1               1           0.7276576
V3                     1            1               1           0.7276576
V4                     1            1               1           0.7276576
V5                     1            1               1           0.7276576

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1                  0
V10                 0
V11                 0
V12                 0
V13                 0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          V1          TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V31             1.048757     1.056135        1.060465           0.6194732
V13             1.023897     1.028067        1.029992           0.6030103
V26             1.015397     1.022454        1.026143           0.5997178
V27             1.009142     1.011227        1.012510           0.5931326
V11             1.005613     1.009623        1.011869           0.5921919

=== LIME Rankings ===


Feature    Importance
--------  -----------
V13         0.0072712
V10         0.0062575
V16         0.0039085
V7          0.0036205
V20         0.0028239
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31         0.0043291
V16         0.0020880
V17         0.0017658
V10         0.0015593
V19         0.0014445

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V31
LIME: V13
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V31         V13         FALSE     
FEAT_IMP vs SHAP   V31         V31         TRUE      
LIME vs SHAP       V13         V31         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V31            0.2039511    0.2064911       0.2099718           0.2064911
V26            0.1921919    0.1966134       0.1973659           0.1966134
V32            0.1743180    0.1773283       0.1812794           0.1773283
V35            0.1326435    0.1373471       0.1404516           0.1373471
V33            0.0794920    0.0823142       0.0851364           0.0823142
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
There were 14 warnings (use warnings() to see them)
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V31
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V31         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V26                134.3        139.0           142.4           0.1307620
V35                112.1        115.5           125.2           0.1086548
V32                111.1        114.0           117.9           0.1072437
V31                 94.5        102.5           108.6           0.0964252
V29                 62.5         63.5            65.8           0.0597366

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
There were 14 warnings (use warnings() to see them)
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V26
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V26         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1731 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V27            15.969811    16.716981       17.079245           0.4167451
V31             9.562264     9.754717        9.932075           0.2431797
V32             6.920755     7.283019        7.456604           0.1815616
V35             5.498113     5.660377        5.826415           0.1411101
V33             3.286792     3.490566        3.630189           0.0870179

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
There were 13 warnings (use warnings() to see them)

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V27
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V27         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V35                32.48         34.4           34.92           0.0809031
V29                25.00         25.2           25.60           0.0592662
V26                21.96         23.4           24.24           0.0550329
V30                22.24         22.8           23.88           0.0536218
V34                19.80         20.8           22.00           0.0489182

=== LIME Rankings ===


Feature    Importance
--------  -----------
V31         0.3775864
V7          0.2459025
V34         0.2074568
V13         0.1649817
V27         0.1217514
There were 13 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V31         0.2662667
V34         0.1872000
V27         0.0786667
V32         0.0452000
V26         0.0406857

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP          NA                 0
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V35
LIME: V31
SHAP: V31

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V35         V31         FALSE     
FEAT_IMP vs SHAP   V35         V31         FALSE     
LIME vs SHAP       V31         V31         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cardiotocography, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V26             1.351333     1.359415        1.360791           0.7436500
V1              1.000000     1.000000        1.000000           0.5470367
V2              1.000000     1.000000        1.000000           0.5470367
V3              1.000000     1.000000        1.000000           0.5470367
V4              1.000000     1.000000        1.000000           0.5470367

=== LIME Rankings ===
Error in get_lime: length of 'dimnames' [2] not equal to array extent 
There were 13 warnings (use warnings() to see them)

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V26
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V26         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


Dataset: climate-model-simulation-crashes
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature         importance.05   importance   importance.95   permutation.error
-------------  --------------  -----------  --------------  ------------------
vconst_2             2.011111     2.194444        2.444444           0.1462963
vconst_corr          1.872222     2.111111        2.277778           0.1407407
convect_corr         1.400000     1.500000        1.577778           0.1000000
vconst_3             1.000000     1.000000        1.000000           0.0666667
vconst_4             1.000000     1.000000        1.000000           0.0666667

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
vconst_corr              0.1210084
vconst_2                 0.0971092
convect_corr             0.0409455
vconst_4                 0.0067171
vertical_decay_scale     0.0066897

=== SHAP (IML Shapley) Rankings ===


Feature         Importance
-------------  -----------
vconst_2         0.1392563
vconst_corr      0.0804607
convect_corr     0.0348874
ah_bolus         0.0000000
ah_corr          0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_2
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_2      vconst_corr   FALSE     
FEAT_IMP vs SHAP   vconst_2      vconst_2      TRUE      
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
vconst_corr                1            1               1           0.0851852
vconst_2                   1            1               1           0.0851852
vconst_3                   1            1               1           0.0851852
vconst_4                   1            1               1           0.0851852
vconst_5                   1            1               1           0.0851852

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
vconst_corr              0.1655540
vconst_7                 0.0033194
convect_corr             0.0032865
bckgrnd_vdc_ban          0.0029579
vertical_decay_scale     0.0026824

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
vconst_corr         0.1255263
ah_bolus            0.0000000
ah_corr             0.0000000
bckgrnd_vdc_ban     0.0000000
bckgrnd_vdc_eq      0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_corr

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_corr   TRUE      
LIME vs SHAP       vconst_corr   vconst_corr   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.5595            -nan     0.1000    0.0063
     2        0.5506            -nan     0.1000   -0.0008
     3        0.5355            -nan     0.1000    0.0078
     4        0.5177            -nan     0.1000    0.0077
     5        0.5041            -nan     0.1000    0.0033
     6        0.4968            -nan     0.1000    0.0036
     7        0.4881            -nan     0.1000    0.0011
     8        0.4836            -nan     0.1000    0.0001
     9        0.4726            -nan     0.1000    0.0057
    10        0.4629            -nan     0.1000    0.0019
    20        0.3873            -nan     0.1000    0.0029
    40        0.2995            -nan     0.1000    0.0015
    50        0.2780            -nan     0.1000    0.0002



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
vconst_corr             1.571429     1.714286        1.842857           0.0888889
vconst_2                1.614286     1.678571        1.821429           0.0870370
convect_corr            1.214286     1.285714        1.350000           0.0666667
bckgrnd_vdc1            1.178571     1.214286        1.250000           0.0629630
bckgrnd_vdc_ban         1.035714     1.071429        1.071429           0.0555556

=== LIME Rankings ===


Feature         Importance
-------------  -----------
vconst_corr      0.0920027
vconst_2         0.0710620
convect_corr     0.0286377
bckgrnd_vdc1     0.0219695
vconst_3         0.0087429

=== SHAP (IML Shapley) Rankings ===


Feature         Importance
-------------  -----------
vconst_2         0.0986982
vconst_corr      0.0877176
convect_corr     0.0486693
bckgrnd_vdc1     0.0151649
vconst_4         0.0057294

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_2      FALSE     
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature           importance.05   importance   importance.95   permutation.error
---------------  --------------  -----------  --------------  ------------------
vconst_corr            2.823529     3.235294        3.529412           0.1018519
vconst_2               2.882353     3.000000        3.235294           0.0944444
convect_corr           2.141176     2.294118        2.588235           0.0722222
bckgrnd_vdc1           1.564706     1.764706        2.035294           0.0555556
bckgrnd_vdc_eq         1.411765     1.470588        1.576471           0.0462963

=== LIME Rankings ===


Feature           Importance
---------------  -----------
vconst_corr        0.1362411
vconst_2           0.0981744
bckgrnd_vdc1       0.0581365
convect_corr       0.0565494
bckgrnd_vdc_eq     0.0169232

=== SHAP (IML Shapley) Rankings ===


Feature           Importance
---------------  -----------
vconst_2           0.1217725
convect_corr       0.1189852
vconst_corr        0.0896266
bckgrnd_vdc1       0.0514419
bckgrnd_vdc_eq     0.0156827

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -0.5                 3
LIME vs SHAP            -1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_2      FALSE     
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature         importance.05   importance   importance.95   permutation.error
-------------  --------------  -----------  --------------  ------------------
vconst_2             2.545454     2.590909        2.800000           0.1055556
vconst_corr          2.154545     2.409091        2.836364           0.0981481
convect_corr         1.463636     1.681818        1.763636           0.0685185
bckgrnd_vdc1         1.409091     1.500000        1.545454           0.0611111
vconst_3             1.000000     1.000000        1.000000           0.0407407

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
vconst_corr              0.0863803
vconst_2                 0.0690373
bckgrnd_vdc1             0.0359103
convect_corr             0.0343937
vertical_decay_scale     0.0060071

=== SHAP (IML Shapley) Rankings ===


Feature         Importance
-------------  -----------
vconst_2         0.1272133
vconst_corr      0.0961888
bckgrnd_vdc1     0.0426481
convect_corr     0.0388954
ah_bolus         0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_2
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_2      vconst_corr   FALSE     
FEAT_IMP vs SHAP   vconst_2      vconst_2      TRUE      
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature         importance.05   importance   importance.95   permutation.error
-------------  --------------  -----------  --------------  ------------------
vconst_2             1.100000     1.166667        1.190476           0.0907407
vconst_corr          1.100000     1.119048        1.119048           0.0870370
bckgrnd_vdc1         1.076191     1.095238        1.161905           0.0851852
vconst_5             1.004762     1.071429        1.114286           0.0833333
ah_corr              1.028571     1.071429        1.071429           0.0833333

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_2
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   vconst_2    NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature         importance.05   importance   importance.95   permutation.error
-------------  --------------  -----------  --------------  ------------------
vconst_corr          4.818182     4.818182        5.381818           0.0981481
vconst_2             4.472727     4.727273        5.490909           0.0962963
convect_corr         3.000000     3.272727        3.545454           0.0666667
bckgrnd_vdc1         2.418182     3.000000        3.163636           0.0611111
vconst_5             1.563636     2.090909        2.345455           0.0425926

=== LIME Rankings ===


Feature         Importance
-------------  -----------
vconst_corr      0.1212722
vconst_2         0.0839436
bckgrnd_vdc1     0.0527718
convect_corr     0.0493204
vconst_5         0.0246435

=== SHAP (IML Shapley) Rankings ===


Feature         Importance
-------------  -----------
vconst_2         0.1362066
vconst_corr      0.0876803
convect_corr     0.0645643
bckgrnd_vdc1     0.0436382
vconst_5         0.0331018

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP            -1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_2      FALSE     
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=multinom ===
Applying data scaling for method: multinom
# weights:  20 (19 variable)
initial  value 374.299478 
iter  10 value 48.788320
iter  20 value 48.365998
final  value 48.344147 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature           importance.05   importance   importance.95   permutation.error
---------------  --------------  -----------  --------------  ------------------
vconst_corr              3.4625       3.6875          3.7875           0.1092593
vconst_2                 3.2750       3.3750          3.4375           0.1000000
bckgrnd_vdc1             1.7375       2.4375          2.5500           0.0722222
convect_corr             1.9125       2.1875          2.3750           0.0648148
bckgrnd_vdc_eq           1.3750       1.4375          1.4875           0.0425926

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
vconst_corr              0.1341542
vconst_2                 0.0944565
bckgrnd_vdc1             0.0578881
convect_corr             0.0525440
vertical_decay_scale     0.0260119

=== SHAP (IML Shapley) Rankings ===


Feature         Importance
-------------  -----------
vconst_2         0.1428507
vconst_corr      0.1127610
convect_corr     0.0647863
bckgrnd_vdc1     0.0577577
vconst_5         0.0320122

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_2      FALSE     
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature         importance.05   importance   importance.95   permutation.error
-------------  --------------  -----------  --------------  ------------------
vconst_corr          5.422222     5.888889        6.466667           0.0981481
vconst_2             5.244444     5.888889        6.266667           0.0981481
bckgrnd_vdc1         2.400000     3.333333        3.711111           0.0555556
convect_corr         2.688889     3.111111        3.377778           0.0518519
ah_corr              1.377778     1.666667        1.888889           0.0277778

=== LIME Rankings ===


Feature         Importance
-------------  -----------
vconst_corr      0.1203467
vconst_2         0.1064434
convect_corr     0.0447751
bckgrnd_vdc1     0.0447034
ah_corr          0.0153176

=== SHAP (IML Shapley) Rankings ===


Feature         Importance
-------------  -----------
vconst_2         0.1530073
vconst_corr      0.1073077
convect_corr     0.0454522
bckgrnd_vdc1     0.0445152
ah_corr          0.0203333

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_2      FALSE     
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
vconst_corr                1            1               1           0.0851852
vconst_2                   1            1               1           0.0851852
vconst_3                   1            1               1           0.0851852
vconst_4                   1            1               1           0.0851852
vconst_5                   1            1               1           0.0851852

=== LIME Rankings ===


Feature            Importance
----------------  -----------
vconst_corr          1.624894
convect_corr         1.371739
ah_corr              1.347059
bckgrnd_vdc_ban      1.334698
vconst_2             1.208063

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
vconst_corr          1.695134
convect_corr         1.490973
bckgrnd_vdc_ban      1.409966
vconst_2             1.363624
ah_corr              1.279466

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_corr

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_corr   TRUE      
LIME vs SHAP       vconst_corr   vconst_corr   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature         importance.05   importance   importance.95   permutation.error
-------------  --------------  -----------  --------------  ------------------
vconst_2             2.446154     2.769231        3.338462           0.0666667
vconst_corr          2.123077     2.461539        2.876923           0.0592593
bckgrnd_vdc1         2.092308     2.153846        2.400000           0.0518519
slm_corr             1.246154     1.692308        1.692308           0.0407407
convect_corr         1.415385     1.538461        1.861538           0.0370370

=== LIME Rankings ===


Feature         Importance
-------------  -----------
vconst_corr      0.0593688
vconst_2         0.0530713
bckgrnd_vdc1     0.0358803
convect_corr     0.0211178
vconst_5         0.0119581

=== SHAP (IML Shapley) Rankings ===


Feature         Importance
-------------  -----------
vconst_2         0.0813244
vconst_corr      0.0539830
bckgrnd_vdc1     0.0482553
convect_corr     0.0330291
vconst_5         0.0294923

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_2
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_2      vconst_corr   FALSE     
FEAT_IMP vs SHAP   vconst_2      vconst_2      TRUE      
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature         importance.05   importance   importance.95   permutation.error
-------------  --------------  -----------  --------------  ------------------
vconst_corr         0.0522222    0.0574074       0.0655556           0.0574074
vconst_2            0.0488889    0.0555556       0.0592593           0.0555556
convect_corr        0.0122222    0.0185185       0.0251852           0.0185185
bckgrnd_vdc1        0.0151852    0.0185185       0.0270370           0.0185185
vconst_4            0.0037037    0.0037037       0.0037037           0.0037037
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature          Importance
--------------  -----------
vconst_corr       0.0805083
vconst_2          0.0577742
convect_corr      0.0243557
bckgrnd_vdc1      0.0234137
tidal_mix_max     0.0074879

=== SHAP (IML Shapley) Rankings ===


Feature         Importance
-------------  -----------
vconst_2          0.073904
vconst_corr       0.066680
convect_corr      0.043232
bckgrnd_vdc1      0.024528
vconst_5          0.008924

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_2      FALSE     
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
vconst_corr                1            1               1           0.0851852
vconst_2                   1            1               1           0.0851852
vconst_3                   1            1               1           0.0851852
vconst_4                   1            1               1           0.0851852
vconst_5                   1            1               1           0.0851852

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature             Importance
-----------------  -----------
ah_bolus                     0
ah_corr                      0
bckgrnd_vdc_ban              0
bckgrnd_vdc_eq               0
bckgrnd_vdc_psim             0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
SHAP: ah_bolus

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2   Agreement 
-----------------  ------------  ----------  ----------
FEAT_IMP vs SHAP   vconst_corr   ah_bolus    FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
vconst_corr        1.0000000            1               1           0.0851852
vconst_3           1.0000000            1               1           0.0851852
vconst_4           0.9782609            1               1           0.0851852
vconst_5           1.0000000            1               1           0.0851852
vconst_7           0.9782609            1               1           0.0851852

=== LIME Rankings ===


Feature           Importance
---------------  -----------
vconst_corr        0.0440273
vconst_2           0.0364341
bckgrnd_vdc1       0.0262597
convect_corr       0.0231242
bckgrnd_vdc_eq     0.0074050

=== SHAP (IML Shapley) Rankings ===


Feature           Importance
---------------  -----------
vconst_corr        0.0324188
vconst_2           0.0300589
convect_corr       0.0203689
bckgrnd_vdc1       0.0190795
bckgrnd_vdc_eq     0.0071929

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_corr

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_corr   TRUE      
LIME vs SHAP       vconst_corr   vconst_corr   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature           importance.05   importance   importance.95   permutation.error
---------------  --------------  -----------  --------------  ------------------
vconst_corr            2.952941     3.294118        3.517647           0.1037037
vconst_2               2.847059     3.058823        3.164706           0.0962963
bckgrnd_vdc1           1.670588     2.058823        2.200000           0.0648148
convect_corr           1.717647     1.823529        2.282353           0.0574074
bckgrnd_vdc_eq         1.176471     1.176471        1.364706           0.0370370

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2   Agreement 
-----------------  ------------  ----------  ----------
FEAT_IMP vs SHAP   vconst_corr   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
vconst_corr                1            1               1           0.0851852
vconst_2                   1            1               1           0.0851852
vconst_3                   1            1               1           0.0851852
vconst_4                   1            1               1           0.0851852
vconst_5                   1            1               1           0.0851852

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2   Agreement 
-----------------  ------------  ----------  ----------
FEAT_IMP vs SHAP   vconst_corr   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1959 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature         importance.05   importance   importance.95   permutation.error
-------------  --------------  -----------  --------------  ------------------
vconst_2             1.947826     2.173913        2.208696           0.0925926
vconst_corr          1.834783     1.913043        2.017391           0.0814815
convect_corr         1.347826     1.391304        1.608696           0.0592593
bckgrnd_vdc1         1.260870     1.304348        1.382609           0.0555556
vconst_7             1.060870     1.130435        1.130435           0.0481481

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_2
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   vconst_2    NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
vconst_corr            1.1818182     1.333333        1.490909           0.0814815
vconst_2               1.1878788     1.272727        1.296970           0.0777778
bckgrnd_vdc1           1.1272727     1.212121        1.212121           0.0740741
convect_corr           1.0666667     1.090909        1.139394           0.0666667
bckgrnd_vdc_ban        0.9757576     1.060606        1.084849           0.0648148

=== LIME Rankings ===


Feature         Importance
-------------  -----------
vconst_corr      0.0614001
vconst_2         0.0523363
bckgrnd_vdc1     0.0411798
convect_corr     0.0257327
slm_corr         0.0165151

=== SHAP (IML Shapley) Rankings ===


Feature           Importance
---------------  -----------
vconst_corr        0.0464000
vconst_2           0.0419333
bckgrnd_vdc1       0.0404000
convect_corr       0.0242667
bckgrnd_vdc_eq     0.0200000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_corr

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_corr   TRUE      
LIME vs SHAP       vconst_corr   vconst_corr   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=climate-model-simulation-crashes, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature           importance.05   importance   importance.95   permutation.error
---------------  --------------  -----------  --------------  ------------------
vconst_corr            3.023529     3.235294        3.517647           0.1018519
vconst_2               2.882353     2.941177        3.270588           0.0925926
bckgrnd_vdc1           1.529412     2.058823        2.223529           0.0648148
convect_corr           1.729412     1.941177        2.317647           0.0611111
bckgrnd_vdc_eq         1.176471     1.235294        1.341176           0.0388889

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
vconst_corr              0.1298206
vconst_2                 0.0918609
bckgrnd_vdc1             0.0550728
convect_corr             0.0502712
vertical_decay_scale     0.0236688

=== SHAP (IML Shapley) Rankings ===


Feature         Importance
-------------  -----------
vconst_2         0.1385103
vconst_corr      0.1098666
convect_corr     0.0626251
bckgrnd_vdc1     0.0540585
vconst_5         0.0277664

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: vconst_corr
LIME: vconst_corr
SHAP: vconst_2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   vconst_corr   vconst_corr   TRUE      
FEAT_IMP vs SHAP   vconst_corr   vconst_2      FALSE     
LIME vs SHAP       vconst_corr   vconst_2      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: cmc
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         1.466019     1.487864        1.513592           0.4161575
Wifes_education                      1.312621     1.354369        1.396602           0.3788187
Wifes_age                            1.280097     1.283981        1.300000           0.3591310
Husbands_education                   1.000000     1.000000        1.000000           0.2797013
Wifes_religion                       1.000000     1.000000        1.000000           0.2797013

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_age                        0.1508458
Number_of_children_ever_born     0.0924346
Wifes_education                  0.0853258
Media_exposure                   0.0399835
Wifes_now_working                0.0084697

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_age                        0.1526752
Wifes_education                  0.0981817
Number_of_children_ever_born     0.0897280
Media_exposure                   0.0138382
Husbands_education               0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -0.5                 3
FEAT_IMP vs SHAP        -1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Wifes_age
SHAP: Wifes_age

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2   Agreement 
-----------------  -----------------------------  ----------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Wifes_age   FALSE     
FEAT_IMP vs SHAP   Number_of_children_ever_born   Wifes_age   FALSE     
LIME vs SHAP       Wifes_age                      Wifes_age   TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         1.297338     1.304183        1.339924           0.4657162
Wifes_age                            1.000000     1.000000        1.000000           0.3570944
Wifes_education                      1.000000     1.000000        1.000000           0.3570944
Husbands_education                   1.000000     1.000000        1.000000           0.3570944
Wifes_religion                       1.000000     1.000000        1.000000           0.3570944

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.1650203
Media_exposure                   0.0061936
Wifes_religion                   0.0058875
Standard_of_living_index         0.0049562
Husbands_education               0.0048982

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.1190901
Husbands_education               0.0000000
Husbands_occupation              0.0000000
Media_exposure                   0.0000000
Standard_of_living_index         0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Number_of_children_ever_born
SHAP: Number_of_children_ever_born

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2                      Agreement 
-----------------  -----------------------------  -----------------------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
FEAT_IMP vs SHAP   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
LIME vs SHAP       Number_of_children_ever_born   Number_of_children_ever_born   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3489            -nan     0.1000    0.0075
     2        1.3357            -nan     0.1000    0.0071
     3        1.3268            -nan     0.1000    0.0036
     4        1.3155            -nan     0.1000    0.0055
     5        1.3066            -nan     0.1000    0.0040
     6        1.2982            -nan     0.1000    0.0038
     7        1.2918            -nan     0.1000    0.0023
     8        1.2851            -nan     0.1000    0.0027
     9        1.2783            -nan     0.1000    0.0023
    10        1.2714            -nan     0.1000    0.0025
    20        1.2200            -nan     0.1000    0.0016
    40        1.1606            -nan     0.1000    0.0007
    50        1.1439            -nan     0.1000    0.0003



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born        1.3606635     1.407583        1.432701           0.4032587
Wifes_age                           1.2047393     1.229858        1.258768           0.3523422
Wifes_education                     1.0928910     1.118483        1.140758           0.3204345
Media_exposure                      1.0364929     1.049763        1.058768           0.3007468
Standard_of_living_index            0.9966825     1.002370        1.004739           0.2871690

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.1332116
Wifes_age                        0.1226187
Media_exposure                   0.0852349
Wifes_education                  0.0640611
Standard_of_living_index         0.0125695

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_age                        0.0994449
Number_of_children_ever_born     0.0907521
Wifes_education                  0.0551397
Standard_of_living_index         0.0093794
Media_exposure                   0.0047377

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP            -1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Number_of_children_ever_born
SHAP: Wifes_age

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2                      Agreement 
-----------------  -----------------------------  -----------------------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
FEAT_IMP vs SHAP   Number_of_children_ever_born   Wifes_age                      FALSE     
LIME vs SHAP       Number_of_children_ever_born   Wifes_age                      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born           1.4310       1.4700          1.5105           0.3991853
Wifes_age                              1.2555       1.2700          1.3250           0.3448744
Wifes_education                        1.1350       1.1675          1.1925           0.3170401
Media_exposure                         1.0080       1.0225          1.0265           0.2776646
Husbands_education                     1.0000       1.0000          1.0000           0.2715547

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.2671899
Wifes_age                        0.1963108
Media_exposure                   0.0976814
Wifes_education                  0.0889250
Standard_of_living_index         0.0358503

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.1703431
Wifes_age                        0.1534146
Wifes_education                  0.0807486
Standard_of_living_index         0.0293088
Media_exposure                   0.0121050

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Number_of_children_ever_born
SHAP: Number_of_children_ever_born

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2                      Agreement 
-----------------  -----------------------------  -----------------------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
FEAT_IMP vs SHAP   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
LIME vs SHAP       Number_of_children_ever_born   Number_of_children_ever_born   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         1.470886     1.478481        1.496203           0.3964698
Wifes_age                            1.333165     1.359494        1.372658           0.3645621
Wifes_education                      1.313924     1.349367        1.370633           0.3618466
Husbands_education                   1.000000     1.000000        1.000000           0.2681602
Wifes_religion                       1.000000     1.000000        1.000000           0.2681602

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_age                        0.1751604
Number_of_children_ever_born     0.0750134
Wifes_education                  0.0596510
Media_exposure                   0.0105809
Wifes_religion                   0.0068974

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_age                        0.1607877
Wifes_education                  0.0841510
Number_of_children_ever_born     0.0806445
Husbands_education               0.0000000
Husbands_occupation              0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP        -0.5                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Wifes_age
SHAP: Wifes_age

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2   Agreement 
-----------------  -----------------------------  ----------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Wifes_age   FALSE     
FEAT_IMP vs SHAP   Number_of_children_ever_born   Wifes_age   FALSE     
LIME vs SHAP       Wifes_age                      Wifes_age   TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Wifes_education                     1.1118761     1.127367        1.159725           0.4446707
Husbands_education                  1.0165232     1.043029        1.047504           0.4114053
Wifes_age                           1.0220310     1.027539        1.039931           0.4052953
Number_of_children_ever_born        0.9982788     1.013769        1.023408           0.3998642
Media_exposure                      1.0092943     1.013769        1.018933           0.3998642

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Wifes_education
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2   Agreement 
-----------------  ----------------  ----------  ----------
FEAT_IMP vs SHAP   Wifes_education   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         1.421749     1.486998        1.513002           0.4270197
Wifes_age                            1.203782     1.215130        1.233097           0.3489477
Wifes_education                      1.101655     1.127660        1.162175           0.3238289
Media_exposure                       1.087943     1.111111        1.117258           0.3190767
Wifes_religion                       1.009456     1.014184        1.023641           0.2912424

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Media_exposure                   0.2858300
Number_of_children_ever_born     0.2149365
Wifes_age                        0.1408778
Wifes_education                  0.0420188
Wifes_religion                   0.0417224

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.1511511
Wifes_age                        0.0636546
Media_exposure                   0.0333234
Wifes_education                  0.0262368
Standard_of_living_index         0.0098610

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Media_exposure
SHAP: Number_of_children_ever_born

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2                      Agreement 
-----------------  -----------------------------  -----------------------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Media_exposure                 FALSE     
FEAT_IMP vs SHAP   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
LIME vs SHAP       Media_exposure                 Number_of_children_ever_born   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=multinom ===
Applying data scaling for method: multinom
# weights:  19 (18 variable)
initial  value 1021.005797 
iter  10 value 897.803392
iter  20 value 882.180669
final  value 881.308989 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born        1.2430704     1.268657        1.274200           0.4039375
Wifes_age                           1.1582090     1.196162        1.212793           0.3808554
Wifes_education                     1.1650320     1.183369        1.246055           0.3767821
Wifes_religion                      1.0046908     1.019190        1.029851           0.3245078
Husbands_education                  0.9957356     1.014925        1.018763           0.3231500

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.3481412
Wifes_age                        0.1975894
Wifes_education                  0.0972434
Media_exposure                   0.0833645
Wifes_religion                   0.0795551

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.2695552
Wifes_age                        0.1340839
Wifes_education                  0.0722719
Standard_of_living_index         0.0264781
Husbands_education               0.0203417

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Number_of_children_ever_born
SHAP: Number_of_children_ever_born

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2                      Agreement 
-----------------  -----------------------------  -----------------------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
FEAT_IMP vs SHAP   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
LIME vs SHAP       Number_of_children_ever_born   Number_of_children_ever_born   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         2.268493     2.305936        2.349772           0.3428377
Wifes_education                      2.087671     2.132420        2.165297           0.3170401
Wifes_age                            1.937900     1.972603        2.019178           0.2932790
Standard_of_living_index             1.780822     1.835616        1.849315           0.2729124
Husbands_occupation                  1.496804     1.525114        1.563470           0.2267481

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_age                        0.1566770
Wifes_education                  0.1146513
Number_of_children_ever_born     0.0963559
Standard_of_living_index         0.0501179
Husbands_education               0.0427262

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.1541017
Wifes_education                  0.1446799
Wifes_age                        0.1010511
Husbands_education               0.0943676
Standard_of_living_index         0.0845363

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP              -1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Wifes_age
SHAP: Number_of_children_ever_born

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2                      Agreement 
-----------------  -----------------------------  -----------------------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Wifes_age                      FALSE     
FEAT_IMP vs SHAP   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
LIME vs SHAP       Wifes_age                      Number_of_children_ever_born   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Wifes_education                      5.782051     5.820513        6.182051           0.3082145
Standard_of_living_index             5.271795     5.397436        5.648718           0.2858113
Number_of_children_ever_born         5.225641     5.358974        5.700000           0.2837746
Wifes_age                            4.858974     4.910256        5.112820           0.2600136
Husbands_education                   4.123077     4.551282        4.628205           0.2410048

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_religion                   0.3164109
Number_of_children_ever_born     0.2345433
Media_exposure                   0.1591274
Wifes_age                        0.1219775
Wifes_education                  0.0965724

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_age                        0.1993478
Standard_of_living_index         0.1028907
Number_of_children_ever_born     0.1016274
Wifes_education                  0.0853342
Husbands_education               0.0766771

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Wifes_education
LIME: Wifes_religion
SHAP: Wifes_age

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2        Agreement 
-----------------  ----------------  ---------------  ----------
FEAT_IMP vs LIME   Wifes_education   Wifes_religion   FALSE     
FEAT_IMP vs SHAP   Wifes_education   Wifes_age        FALSE     
LIME vs SHAP       Wifes_religion    Wifes_age        FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         1.069323     1.093625        1.108765           0.3727088
Standard_of_living_index             1.050996     1.083665        1.091235           0.3693143
Wifes_education                      1.054183     1.067729        1.093625           0.3638832
Wifes_age                            1.043825     1.053785        1.070518           0.3591310
Husbands_education                   1.034263     1.041833        1.083665           0.3550577

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Media_exposure                   0.4876846
Number_of_children_ever_born     0.1819113
Wifes_education                  0.1528857
Wifes_age                        0.1399598
Wifes_religion                   0.1210261

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_education                  0.1578404
Husbands_education               0.0926294
Wifes_age                        0.0761818
Number_of_children_ever_born     0.0687169
Standard_of_living_index         0.0413986

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Media_exposure
SHAP: Wifes_education

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2         Agreement 
-----------------  -----------------------------  ----------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Media_exposure    FALSE     
FEAT_IMP vs SHAP   Number_of_children_ever_born   Wifes_education   FALSE     
LIME vs SHAP       Media_exposure                 Wifes_education   FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         2.463095     2.541667        2.617857           0.2898846
Wifes_age                            2.442857     2.511905        2.572619           0.2864902
Wifes_education                      2.211905     2.238095        2.332143           0.2552614
Standard_of_living_index             1.678571     1.755952        1.805952           0.2002716
Husbands_education                   1.671429     1.744048        1.785714           0.1989138

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_age                        0.1262896
Number_of_children_ever_born     0.1240425
Wifes_education                  0.1007871
Media_exposure                   0.0955094
Wifes_now_working                0.0346629

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_education                   0.127996
Wifes_age                         0.123848
Husbands_education                0.055872
Number_of_children_ever_born      0.045380
Standard_of_living_index          0.040812

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP            -1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Wifes_age
SHAP: Wifes_education

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2         Agreement 
-----------------  -----------------------------  ----------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Wifes_age         FALSE     
FEAT_IMP vs SHAP   Number_of_children_ever_born   Wifes_education   FALSE     
LIME vs SHAP       Wifes_age                      Wifes_education   FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Wifes_age                                   1            1               1           0.4270197
Wifes_education                             1            1               1           0.4270197
Husbands_education                          1            1               1           0.4270197
Number_of_children_ever_born                1            1               1           0.4270197
Wifes_religion                              1            1               1           0.4270197

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Husbands_education                       0
Husbands_occupation                      0
Media_exposure                           0
Number_of_children_ever_born             0
Standard_of_living_index                 0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Wifes_age
SHAP: Husbands_education

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2            Agreement 
-----------------  ----------  -------------------  ----------
FEAT_IMP vs SHAP   Wifes_age   Husbands_education   FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born        1.0010657     1.024867        1.028419           0.3917176
Wifes_education                     1.0010657     1.015986        1.039787           0.3883232
Media_exposure                      1.0042629     1.015986        1.024512           0.3883232
Wifes_age                           1.0042629     1.014210        1.028419           0.3876443
Wifes_now_working                   0.9889876     1.007105        1.012789           0.3849287

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Media_exposure                   0.0612350
Number_of_children_ever_born     0.0401696
Husbands_education               0.0329253
Wifes_education                  0.0303201
Standard_of_living_index         0.0262799

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Husbands_education               0.0257175
Number_of_children_ever_born     0.0248863
Wifes_education                  0.0230436
Standard_of_living_index         0.0170012
Wifes_age                        0.0118654

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Media_exposure
SHAP: Husbands_education

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2            Agreement 
-----------------  -----------------------------  -------------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Media_exposure       FALSE     
FEAT_IMP vs SHAP   Number_of_children_ever_born   Husbands_education   FALSE     
LIME vs SHAP       Media_exposure                 Husbands_education   FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         1.261674     1.277533        1.314097           0.3937542
Wifes_age                            1.188106     1.226872        1.233480           0.3781399
Wifes_education                      1.147137     1.189427        1.217181           0.3665988
Standard_of_living_index             1.002203     1.022026        1.029956           0.3150034
Husbands_education                   1.003084     1.008811        1.014537           0.3109301

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2   Agreement 
-----------------  -----------------------------  ----------  ----------
FEAT_IMP vs SHAP   Number_of_children_ever_born   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         1.163801     1.185520        1.223982           0.3557366
Wifes_education                      1.104525     1.117647        1.127149           0.3353700
Wifes_age                            1.097285     1.115385        1.177828           0.3346911
Husbands_occupation                  1.030769     1.049774        1.065158           0.3150034
Media_exposure                       1.037104     1.042986        1.064253           0.3129667

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2   Agreement 
-----------------  -----------------------------  ----------  ----------
FEAT_IMP vs SHAP   Number_of_children_ever_born   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1986 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Wifes_age                            1.257757     1.295943        1.353699           0.3686354
Number_of_children_ever_born         1.277327     1.291170        1.355609           0.3672777
Wifes_education                      1.102625     1.105012        1.152267           0.3143245
Standard_of_living_index             1.040573     1.057279        1.065871           0.3007468
Wifes_religion                       1.000477     1.004773        1.013365           0.2858113

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Wifes_age
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Wifes_age   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Wifes_education                      1.350700     1.378151        1.436975           0.3340122
Standard_of_living_index             1.300280     1.333333        1.394398           0.3231500
Number_of_children_ever_born         1.291316     1.305322        1.338936           0.3163612
Wifes_age                            1.268908     1.285714        1.342857           0.3116090
Husbands_education                   1.254902     1.263305        1.288515           0.3061779

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Media_exposure                   0.2016276
Wifes_age                        0.0731889
Number_of_children_ever_born     0.0636833
Wifes_education                  0.0610931
Wifes_now_working                0.0603075

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Wifes_education                  0.0814429
Wifes_age                        0.0663873
Number_of_children_ever_born     0.0536008
Husbands_education               0.0419595
Husbands_occupation              0.0367437

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Wifes_education
LIME: Media_exposure
SHAP: Wifes_education

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   Wifes_education   Media_exposure    FALSE     
FEAT_IMP vs SHAP   Wifes_education   Wifes_education   TRUE      
LIME vs SHAP       Media_exposure    Wifes_education   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=cmc, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                         importance.05   importance   importance.95   permutation.error
-----------------------------  --------------  -----------  --------------  ------------------
Number_of_children_ever_born         1.243497     1.264392        1.278891           0.4025798
Wifes_age                            1.160768     1.198294        1.214073           0.3815343
Wifes_education                      1.166738     1.187633        1.246482           0.3781399
Wifes_religion                       1.007249     1.019190        1.031556           0.3245078
Husbands_education                   1.000000     1.017058        1.019190           0.3238289

=== LIME Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.3462940
Wifes_age                        0.1966011
Wifes_education                  0.0964227
Media_exposure                   0.0842643
Wifes_religion                   0.0792371

=== SHAP (IML Shapley) Rankings ===


Feature                         Importance
-----------------------------  -----------
Number_of_children_ever_born     0.2677873
Wifes_age                        0.1334861
Wifes_education                  0.0713840
Standard_of_living_index         0.0265559
Husbands_education               0.0196520

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Number_of_children_ever_born
LIME: Number_of_children_ever_born
SHAP: Number_of_children_ever_born

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                      Feature_2                      Agreement 
-----------------  -----------------------------  -----------------------------  ----------
FEAT_IMP vs LIME   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
FEAT_IMP vs SHAP   Number_of_children_ever_born   Number_of_children_ever_born   TRUE      
LIME vs SHAP       Number_of_children_ever_born   Number_of_children_ever_born   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: credit-g
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status         1.268382     1.312500        1.340441               0.357
duration                1.171323     1.250000        1.306618               0.340
credit_history          1.041912     1.058823        1.062500               0.288
purpose                 1.000000     1.000000        1.000000               0.272
credit_amount           1.000000     1.000000        1.000000               0.272

=== LIME Rankings ===


Feature                Importance
--------------------  -----------
checking_status         0.1797602
other_payment_plans     0.0791656
duration                0.0725589
num_dependents          0.0530935
credit_history          0.0137082
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                Importance
--------------------  -----------
checking_status         0.1573941
duration                0.0767337
other_payment_plans     0.0159142
credit_history          0.0034220
age                     0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: checking_status
SHAP: checking_status

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   checking_status   checking_status   TRUE      
FEAT_IMP vs SHAP   checking_status   checking_status   TRUE      
LIME vs SHAP       checking_status   checking_status   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status                1            1               1                 0.3
duration                       1            1               1                 0.3
credit_history                 1            1               1                 0.3
purpose                        1            1               1                 0.3
credit_amount                  1            1               1                 0.3

=== LIME Rankings ===


Feature                Importance
--------------------  -----------
checking_status         0.1856907
num_dependents          0.0082281
other_payment_plans     0.0056077
credit_amount           0.0050236
existing_credits        0.0044118
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.1394588
age                 0.0000000
credit_amount       0.0000000
credit_history      0.0000000
duration            0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: checking_status
SHAP: checking_status

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   checking_status   checking_status   TRUE      
FEAT_IMP vs SHAP   checking_status   checking_status   TRUE      
LIME vs SHAP       checking_status   checking_status   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2000            -nan     0.1000    0.0096
     2        1.1852            -nan     0.1000    0.0078
     3        1.1716            -nan     0.1000    0.0066
     4        1.1585            -nan     0.1000    0.0050
     5        1.1508            -nan     0.1000    0.0040
     6        1.1430            -nan     0.1000    0.0034
     7        1.1355            -nan     0.1000    0.0025
     8        1.1294            -nan     0.1000    0.0016
     9        1.1259            -nan     0.1000    0.0005
    10        1.1195            -nan     0.1000    0.0028
    20        1.0803            -nan     0.1000   -0.0000
    40        1.0327            -nan     0.1000    0.0013
    50        1.0154            -nan     0.1000    0.0004



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning messages:
1: In (function (x, y, offset = NULL, misc = NULL, distribution = "bernoulli",  :
  variable 15: purposevacation has no variation.
2: In (function (x, y, offset = NULL, misc = NULL, distribution = "bernoulli",  :
  variable 32: personal_statusfemale single has no variation.

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status        1.0209738     1.037453        1.078652               0.277
credit_history         1.0052434     1.033708        1.048689               0.276
duration               0.9962547     1.029962        1.062172               0.275
housing                0.9910112     1.018727        1.025468               0.272
age                    1.0119850     1.014981        1.018727               0.271

=== LIME Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.1293119
duration            0.0909166
credit_amount       0.0707768
housing             0.0434344
num_dependents      0.0415726
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.0810059
duration            0.0594168
housing             0.0229086
age                 0.0197851
credit_history      0.0186046

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: checking_status
SHAP: checking_status

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   checking_status   checking_status   TRUE      
FEAT_IMP vs SHAP   checking_status   checking_status   TRUE      
LIME vs SHAP       checking_status   checking_status   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status         1.180556     1.245370        1.256482               0.269
duration                1.120370     1.125000        1.150000               0.243
credit_history          1.025000     1.092593        1.125000               0.236
purpose                 1.020370     1.092593        1.127778               0.236
credit_amount           1.064815     1.069444        1.089815               0.231

=== LIME Rankings ===


Feature                Importance
--------------------  -----------
checking_status         0.1746819
foreign_worker          0.1617364
credit_amount           0.1527169
duration                0.1102598
other_payment_plans     0.0902731
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.1359039
duration            0.0891921
purpose             0.0527749
employment          0.0485521
credit_history      0.0440738

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: checking_status
SHAP: checking_status

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   checking_status   checking_status   TRUE      
FEAT_IMP vs SHAP   checking_status   checking_status   TRUE      
LIME vs SHAP       checking_status   checking_status   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status         1.227046     1.277580        1.306762               0.359
duration                1.159431     1.231317        1.291815               0.346
credit_history          1.000000     1.000000        1.000000               0.281
purpose                 1.000000     1.000000        1.000000               0.281
credit_amount           1.000000     1.000000        1.000000               0.281

=== LIME Rankings ===


Feature            Importance
----------------  -----------
duration            0.1163476
num_dependents      0.0829322
checking_status     0.0485987
foreign_worker      0.0069761
own_telephone       0.0034263
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
duration            0.1109876
checking_status     0.0797325
age                 0.0000000
credit_amount       0.0000000
credit_history      0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: duration
SHAP: duration

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2   Agreement 
-----------------  ----------------  ----------  ----------
FEAT_IMP vs LIME   checking_status   duration    FALSE     
FEAT_IMP vs SHAP   checking_status   duration    FALSE     
LIME vs SHAP       duration          duration    TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=lvq ===
Applying data scaling for method: lvq
Warning in preProcess.default(method = c("center", "scale"), x = c(0, 1,  :
  These variables have zero variances: purposevacation, personal_statusfemale single
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature               importance.05   importance   importance.95   permutation.error
-------------------  --------------  -----------  --------------  ------------------
property_magnitude        1.0126761     1.024648        1.027465               0.291
num_dependents            1.0147887     1.021127        1.033099               0.290
purpose                   0.9943662     1.014085        1.039437               0.288
housing                   1.0049296     1.014085        1.020423               0.288
checking_status           0.9950704     1.010563        1.026056               0.287

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: property_magnitude
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1            Feature_2   Agreement 
-----------------  -------------------  ----------  ----------
FEAT_IMP vs SHAP   property_magnitude   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=mlpML ===
Applying data scaling for method: mlpML
Warning in preProcess.default(method = c("center", "scale"), x = c(0, 1,  :
  These variables have zero variances: purposevacation, personal_statusfemale single
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
There were 19 warnings (use warnings() to see them)

=== IML Rankings ===


feature                   importance.05   importance   importance.95   permutation.error
-----------------------  --------------  -----------  --------------  ------------------
checking_status                1.554762     1.607143        1.697619               0.270
duration                       1.383333     1.434524        1.457143               0.241
credit_history                 1.310714     1.386905        1.420238               0.233
savings_status                 1.257143     1.369048        1.384524               0.230
installment_commitment         1.270238     1.333333        1.380952               0.224

=== LIME Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.1435715
num_dependents      0.1433615
duration            0.1322285
savings_status      0.1168788
age                 0.0923019
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature               Importance
-------------------  -----------
checking_status        0.0751250
duration               0.0695498
age                    0.0525411
property_magnitude     0.0506312
other_parties          0.0458064

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: checking_status
SHAP: checking_status

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   checking_status   checking_status   TRUE      
FEAT_IMP vs SHAP   checking_status   checking_status   TRUE      
LIME vs SHAP       checking_status   checking_status   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=multinom ===
Applying data scaling for method: multinom
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single
# weights:  52 (51 variable)
initial  value 693.147181 
iter  10 value 523.904491
iter  20 value 486.860546
iter  30 value 457.058985
iter  40 value 449.379783
iter  50 value 447.984419
iter  60 value 447.908893
iter  60 value 447.908893
iter  60 value 447.908893
final  value 447.908893 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status         1.142991     1.196262        1.207477               0.256
credit_history          1.056075     1.121495        1.137383               0.240
purpose                 1.035514     1.116822        1.144860               0.239
duration                1.077570     1.093458        1.130841               0.234
credit_amount           1.060748     1.079439        1.086916               0.231

=== LIME Rankings ===


Feature            Importance
----------------  -----------
foreign_worker      0.1670244
checking_status     0.1632090
credit_amount       0.1459288
savings_status      0.1097584
duration            0.0969588
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.1163027
duration            0.0712072
purpose             0.0609795
credit_history      0.0514050
credit_amount       0.0512015

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: foreign_worker
SHAP: checking_status

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   checking_status   foreign_worker    FALSE     
FEAT_IMP vs SHAP   checking_status   checking_status   TRUE      
LIME vs SHAP       foreign_worker    checking_status   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status         3.958333     4.125000          4.2250               0.198
purpose                 3.312500     3.500000          3.6000               0.168
duration                2.841667     2.979167          3.4250               0.143
credit_history          2.720833     2.854167          2.9500               0.137
savings_status          2.812500     2.854167          2.9125               0.137

=== LIME Rankings ===


Feature                Importance
--------------------  -----------
foreign_worker          0.2181165
duration                0.1980447
num_dependents          0.1683767
other_payment_plans     0.1664152
checking_status         0.1353539
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
duration            0.1707056
checking_status     0.1460971
credit_history      0.0837793
housing             0.0576088
savings_status      0.0498703

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: foreign_worker
SHAP: duration

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2        Agreement 
-----------------  ----------------  ---------------  ----------
FEAT_IMP vs LIME   checking_status   foreign_worker   FALSE     
FEAT_IMP vs SHAP   checking_status   duration         FALSE     
LIME vs SHAP       foreign_worker    duration         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=rbfDDA ===
Applying data scaling for method: rbfDDA
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature               importance.05   importance   importance.95   permutation.error
-------------------  --------------  -----------  --------------  ------------------
purpose                    1.146835     1.168776        1.172152               0.277
credit_history             1.112236     1.122363        1.134177               0.266
property_magnitude         1.087764     1.101266        1.115612               0.261
checking_status            1.076793     1.080169        1.100422               0.256
employment                 1.056540     1.080169        1.084388               0.256

=== LIME Rankings ===


Feature                Importance
--------------------  -----------
other_parties            2.840087
foreign_worker           2.679683
housing                  1.779549
other_payment_plans      1.699857
credit_amount            1.433476
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature               Importance
-------------------  -----------
purpose                1.4245650
housing                1.0032339
credit_history         0.7113741
num_dependents         0.5950598
property_magnitude     0.5868442

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: purpose
LIME: other_parties
SHAP: purpose

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1       Feature_2       Agreement 
-----------------  --------------  --------------  ----------
FEAT_IMP vs LIME   purpose         other_parties   FALSE     
FEAT_IMP vs SHAP   purpose         purpose         TRUE      
LIME vs SHAP       other_parties   purpose         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=rda ===
Applying data scaling for method: rda
Warning in preProcess.default(method = c("center", "scale"), x = c(0, 1,  :
  These variables have zero variances: purposevacation, personal_statusfemale single
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===
Error in get_featimp: Lapack routine dgesv: system is exactly singular: U[15,15] = 0 

=== LIME Rankings ===
Error in get_lime: Lapack routine dgesv: system is exactly singular: U[15,15] = 0 
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: Lapack routine dgesv: system is exactly singular: U[15,15] = 0 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 0 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status           0.1046        0.108          0.1166               0.108
credit_history            0.0366        0.047          0.0480               0.047
duration                  0.0314        0.037          0.0388               0.037
credit_amount             0.0292        0.032          0.0338               0.032
age                       0.0274        0.029          0.0370               0.029
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                Importance
--------------------  -----------
num_dependents          0.1298848
checking_status         0.1100952
credit_amount           0.0876206
duration                0.0737111
other_payment_plans     0.0535588
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
checking_status      0.081276
duration             0.062640
age                  0.038160
credit_history       0.038120
credit_amount        0.029460

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: num_dependents
SHAP: checking_status

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   checking_status   num_dependents    FALSE     
FEAT_IMP vs SHAP   checking_status   checking_status   TRUE      
LIME vs SHAP       num_dependents    checking_status   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status                1            1               1                 0.3
duration                       1            1               1                 0.3
credit_history                 1            1               1                 0.3
purpose                        1            1               1                 0.3
credit_amount                  1            1               1                 0.3

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
age                         0
checking_status             0
credit_amount               0
credit_history              0
duration                    0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: checking_status
SHAP: age

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2   Agreement 
-----------------  ----------------  ----------  ----------
FEAT_IMP vs SHAP   checking_status   age         FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=simpls ===
Applying data scaling for method: simpls
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                   importance.05   importance   importance.95   permutation.error
-----------------------  --------------  -----------  --------------  ------------------
checking_status                1.043825     1.087649        1.098008               0.273
duration                       1.046215     1.059761        1.063745               0.266
savings_status                 1.035857     1.051793        1.068526               0.264
installment_commitment         1.033466     1.043825        1.050996               0.262
employment                     1.036653     1.039841        1.062151               0.261

=== LIME Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.0452522
housing             0.0451337
foreign_worker      0.0428986
duration            0.0410576
credit_amount       0.0407365
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.0348805
duration            0.0303868
housing             0.0266247
credit_history      0.0231064
purpose             0.0188410

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: checking_status
SHAP: checking_status

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   checking_status   checking_status   TRUE      
FEAT_IMP vs SHAP   checking_status   checking_status   TRUE      
LIME vs SHAP       checking_status   checking_status   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=svmLinear ===
Applying data scaling for method: svmLinear
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
In .local(x, ...) : Variable(s) `' constant. Cannot scale data.

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status        1.1398148     1.166667        1.207407               0.252
duration               1.0666667     1.101852        1.113889               0.238
purpose                1.0527778     1.069444        1.094444               0.231
credit_history         1.0296296     1.037037        1.102778               0.224
employment             0.9916667     1.037037        1.045370               0.224

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: checking_status
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2   Agreement 
-----------------  ----------------  ----------  ----------
FEAT_IMP vs SHAP   checking_status   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=svmRadial ===
Applying data scaling for method: svmRadial
Warning in preProcess.default(method = c("center", "scale"), x = c(0, 1,  :
  These variables have zero variances: purposevacation, personal_statusfemale single
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning messages:
1: In .local(x, ...) : Variable(s) `' constant. Cannot scale data.
2: In .local(x, ...) : Variable(s) `' constant. Cannot scale data.

=== IML Rankings ===


feature               importance.05   importance   importance.95   permutation.error
-------------------  --------------  -----------  --------------  ------------------
checking_status           1.0075085     1.013652        1.019113               0.297
credit_history            1.0047782     1.013652        1.017065               0.297
purpose                   1.0040956     1.010239        1.012969               0.296
property_magnitude        1.0102389     1.010239        1.019795               0.296
savings_status            0.9959044     1.006826        1.010239               0.295

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: checking_status
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2   Agreement 
-----------------  ----------------  ----------  ----------
FEAT_IMP vs SHAP   checking_status   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1997 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature               importance.05   importance   importance.95   permutation.error
-------------------  --------------  -----------  --------------  ------------------
checking_status            1.210442     1.257028        1.302811               0.313
duration                   1.222490     1.248996        1.273896               0.311
purpose                    1.065864     1.084337        1.090763               0.270
savings_status             1.014458     1.044177        1.053815               0.260
property_magnitude         1.024096     1.044177        1.053815               0.260

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: checking_status
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2   Agreement 
-----------------  ----------------  ----------  ----------
FEAT_IMP vs SHAP   checking_status   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=knn ===
Applying data scaling for method: knn
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
purpose                 1.114917     1.160221        1.177901               0.210
checking_status         1.100553     1.138122        1.191160               0.206
credit_history          1.059668     1.110497        1.142541               0.201
duration                1.009945     1.077348        1.103867               0.195
personal_status         1.004420     1.077348        1.108287               0.195

=== LIME Rankings ===


Feature            Importance
----------------  -----------
num_dependents      0.1303815
foreign_worker      0.1047119
checking_status     0.0780845
credit_history      0.0714129
savings_status      0.0648091
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature           Importance
---------------  -----------
housing            0.0575333
other_parties      0.0448667
duration           0.0442667
purpose            0.0416667
credit_history     0.0412667

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: purpose
LIME: num_dependents
SHAP: housing

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1        Feature_2        Agreement 
-----------------  ---------------  ---------------  ----------
FEAT_IMP vs LIME   purpose          num_dependents   FALSE     
FEAT_IMP vs SHAP   purpose          housing          FALSE     
LIME vs SHAP       num_dependents   housing          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=credit-g, Method=bayesglm ===
Applying data scaling for method: bayesglm
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: purposevacation, personal_statusfemale single


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature            importance.05   importance   importance.95   permutation.error
----------------  --------------  -----------  --------------  ------------------
checking_status         1.163207     1.202830        1.206604               0.255
purpose                 1.038679     1.113207        1.151887               0.236
duration                1.073585     1.103774        1.136793               0.234
credit_history          1.055660     1.103774        1.139623               0.234
credit_amount           1.057547     1.084906        1.101887               0.230

=== LIME Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.1632853
foreign_worker      0.1542543
credit_amount       0.1437876
savings_status      0.1070803
duration            0.0973729
Warning message:
num_dependents does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature            Importance
----------------  -----------
checking_status     0.1165702
duration            0.0716156
purpose             0.0580552
credit_amount       0.0505006
credit_history      0.0502409

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: checking_status
LIME: checking_status
SHAP: checking_status

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2         Agreement 
-----------------  ----------------  ----------------  ----------
FEAT_IMP vs LIME   checking_status   checking_status   TRUE      
FEAT_IMP vs SHAP   checking_status   checking_status   TRUE      
LIME vs SHAP       checking_status   checking_status   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: diabetes
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.744186     1.825581        1.918605           0.4088542
mass            1.090698     1.145349        1.183721           0.2565104
preg            1.000000     1.000000        1.000000           0.2239583
pres            1.000000     1.000000        1.000000           0.2239583
skin            1.000000     1.000000        1.000000           0.2239583

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.2704681
age         0.0866180
mass        0.0646323
preg        0.0113283
pres        0.0085861

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.1704621
mass        0.0699377
age         0.0606565
preg        0.0059802
insu        0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.612245     1.663265        1.726531           0.4244792
preg            1.000000     1.000000        1.000000           0.2552083
pres            1.000000     1.000000        1.000000           0.2552083
skin            1.000000     1.000000        1.000000           0.2552083
insu            1.000000     1.000000        1.000000           0.2552083

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.3773215
mass        0.0098284
pres        0.0071245
age         0.0067168
insu        0.0061016

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.2706972
age         0.0000000
insu        0.0000000
mass        0.0000000
pedi        0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2603            -nan     0.1000    0.0162
     2        1.2317            -nan     0.1000    0.0137
     3        1.2106            -nan     0.1000    0.0099
     4        1.1868            -nan     0.1000    0.0091
     5        1.1697            -nan     0.1000    0.0079
     6        1.1531            -nan     0.1000    0.0071
     7        1.1342            -nan     0.1000    0.0074
     8        1.1184            -nan     0.1000    0.0059
     9        1.1042            -nan     0.1000    0.0049
    10        1.0934            -nan     0.1000    0.0045
    20        1.0082            -nan     0.1000    0.0015
    40        0.9243            -nan     0.1000   -0.0004
    50        0.9002            -nan     0.1000   -0.0011



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas           1.5903614     1.632530        1.742169           0.3528646
mass           1.0963855     1.102410        1.126506           0.2382812
age            1.0204819     1.036145        1.078313           0.2239583
pres           1.0072289     1.018072        1.022892           0.2200521
pedi           0.9975904     1.018072        1.030120           0.2200521

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.2363647
mass        0.1250706
age         0.0664718
pedi        0.0527925
preg        0.0263341

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.1704086
mass        0.1016986
age         0.0501174
pedi        0.0216772
preg        0.0206101

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.625641     1.705128        1.723077           0.3463542
age             1.152564     1.185897        1.223077           0.2408854
mass            1.121795     1.166667        1.173077           0.2369792
pres            1.051282     1.057692        1.080769           0.2148438
pedi            1.020513     1.057692        1.094872           0.2148438

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.2259953
mass        0.1890134
age         0.1025695
pedi        0.0310703
pres        0.0301286

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.1949765
mass        0.1124732
pedi        0.0806397
age         0.0802216
pres        0.0262911

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.722424     1.745454        1.786667           0.3750000
age             1.129697     1.157576        1.207273           0.2486979
mass            1.115152     1.133333        1.150303           0.2434896
preg            1.000000     1.000000        1.000000           0.2148438
pres            1.000000     1.000000        1.000000           0.2148438

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.2646950
age         0.0576966
mass        0.0346225
pres        0.0080502
skin        0.0060115

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.1499643
age         0.0793165
mass        0.0498034
insu        0.0000000
pedi        0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.165258     1.187793        1.215024           0.3294271
insu            1.033803     1.056338        1.069484           0.2929688
mass            1.015024     1.042253        1.046948           0.2890625
pedi            1.024413     1.032864        1.061972           0.2864583
skin            1.004695     1.014085        1.066667           0.2812500

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: plas
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   plas        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.677457     1.687861        1.716763           0.3802083
mass            1.164162     1.225434        1.248555           0.2760417
preg            1.026590     1.104046        1.136416           0.2486979
pedi            1.018497     1.052023        1.052023           0.2369792
pres            1.009249     1.046243        1.084393           0.2356771

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.2532096
mass        0.1547879
pedi        0.1040125
preg        0.0898950
skin        0.0512121

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.1860184
mass        0.0656942
pedi        0.0493675
preg        0.0468338
skin        0.0179773

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=multinom ===
Applying data scaling for method: multinom
# weights:  10 (9 variable)
initial  value 532.337035 
iter  10 value 369.653338
final  value 361.722689 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas           1.5928144     1.688623        1.724551           0.3671875
mass           1.1005988     1.149701        1.216767           0.2500000
preg           0.9964072     1.095808        1.135329           0.2382812
pedi           1.0479042     1.053892        1.105389           0.2291667
insu           1.0203593     1.035928        1.045509           0.2252604

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.3021436
mass        0.1909504
pedi        0.1190626
preg        0.0866278
insu        0.0394844

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.2078496
mass        0.0863646
pedi        0.0820407
preg        0.0522890
pres        0.0191624

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.891667     1.944444        2.031944           0.3645833
age             1.454167     1.486111        1.529167           0.2786458
mass            1.216667     1.256944        1.304167           0.2356771
preg            1.115278     1.159722        1.191667           0.2174479
pres            1.098611     1.125000        1.159722           0.2109375

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.3067462
age         0.1331982
mass        0.1302790
pres        0.0317419
pedi        0.0160239

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.2211734
mass        0.0684644
age         0.0667913
pres        0.0622338
pedi        0.0116375

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            4.195238     4.404762        4.676190           0.2408854
preg            2.971429     3.047619        3.152381           0.1666667
mass            2.895238     3.047619        3.228571           0.1666667
age             2.733333     2.833333        2.928571           0.1549479
pedi            2.595238     2.785714        2.900000           0.1523438

=== LIME Rankings ===


Feature    Importance
--------  -----------
mass        0.1512090
pres        0.1346135
age         0.1169106
pedi        0.1102357
skin        0.1025655

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.6551184
preg        0.4839885
mass        0.4387105
age         0.3640713
pres        0.3487228

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: plas
LIME: mass
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        mass        FALSE     
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       mass        plas        FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.446409     1.469613        1.509392           0.3463542
preg            1.113812     1.132597        1.160221           0.2669271
mass            1.080663     1.104972        1.135912           0.2604167
pedi            1.038674     1.071823        1.076243           0.2526042
pres            1.030939     1.055249        1.091713           0.2486979

=== LIME Rankings ===


Feature    Importance
--------  -----------
pedi        0.1844751
insu        0.1655620
plas        0.1459787
mass        0.1160468
preg        0.1064163

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.1933812
pedi        0.1321188
mass        0.0528182
preg        0.0428515
pres        0.0268080

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: plas
LIME: pedi
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        pedi        FALSE     
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       pedi        plas        FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas           0.1822917    0.1992188       0.2111979           0.1992188
mass           0.0851562    0.0950521       0.0994792           0.0950521
age            0.0760417    0.0820312       0.0934896           0.0820312
pedi           0.0552083    0.0677083       0.0713542           0.0677083
preg           0.0270833    0.0312500       0.0453125           0.0312500
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.1729826
mass        0.1137977
age         0.0640701
pedi        0.0634150
preg        0.0385464

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas         0.195568
mass         0.087432
age          0.075564
pedi         0.048308
preg         0.033856

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
preg                   1            1               1           0.3489583
plas                   1            1               1           0.3489583
pres                   1            1               1           0.3489583
skin                   1            1               1           0.3489583
insu                   1            1               1           0.3489583

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
age                 0
insu                0
mass                0
pedi                0
plas                0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: preg
SHAP: age

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   preg        age         FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas           1.2482051    1.2717949       1.2851282           0.3229167
pedi           0.9682051    1.0102564       1.0328205           0.2565104
preg           0.9753846    1.0051282       1.0420513           0.2552083
mass           0.9907692    1.0000000       1.0789744           0.2539062
pres           0.9620513    0.9846154       0.9887179           0.2500000

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.1197859
mass        0.0730346
pedi        0.0588838
preg        0.0429030
insu        0.0359661

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.0632152
pedi        0.0346398
mass        0.0314570
preg        0.0235575
age         0.0156678

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas           1.5528736    1.6436782       1.6689655           0.3723958
mass           1.0494253    1.0804598       1.1781609           0.2447917
preg           0.9724138    1.0459770       1.0632184           0.2369792
pedi           1.0011494    1.0172414       1.0264368           0.2304688
insu           0.9827586    0.9885057       0.9977011           0.2239583

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: plas
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   plas        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.619048     1.687075        1.794558           0.3229167
mass            1.050340     1.156463        1.214966           0.2213542
pedi            1.117007     1.122449        1.161905           0.2148438
age             1.072109     1.122449        1.134694           0.2148438
insu            1.081633     1.095238        1.107483           0.2096354

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: plas
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   plas        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.359006     1.453416        1.493168           0.3046875
mass            1.203727     1.254658        1.326708           0.2630208
age             1.111801     1.136646        1.212422           0.2382812
preg            1.057143     1.093168        1.109317           0.2291667
pedi            1.026087     1.093168        1.114286           0.2291667

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: plas
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   plas        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.539535     1.666667        1.744186           0.2799479
mass            1.234109     1.325581        1.358140           0.2226562
preg            1.246512     1.317829        1.382946           0.2213542
age             1.217054     1.271318        1.310078           0.2135417
skin            1.144186     1.217054        1.237209           0.2044271

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.1971152
mass        0.1185871
preg        0.0745583
pedi        0.0700059
insu        0.0575682

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.1437333
pedi        0.0676667
age         0.0513333
mass        0.0492000
preg        0.0372000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=diabetes, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
plas            1.602410     1.692771        1.732530           0.3658854
mass            1.106024     1.156627        1.226506           0.2500000
preg            1.003615     1.102410        1.142169           0.2382812
pedi            1.055422     1.066265        1.113253           0.2304688
insu            1.026506     1.036145        1.051807           0.2239583

=== LIME Rankings ===


Feature    Importance
--------  -----------
plas        0.3013503
mass        0.1896582
pedi        0.1182758
preg        0.0860640
insu        0.0382474

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
plas        0.2066139
mass        0.0859728
pedi        0.0814308
preg        0.0519076
pres        0.0188681

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: plas
LIME: plas
SHAP: plas

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   plas        plas        TRUE      
FEAT_IMP vs SHAP   plas        plas        TRUE      
LIME vs SHAP       plas        plas        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: eucalyptus
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Abbrev                  1            1               1           0.3166927
Rep                     1            1               1           0.3166927
Locality                1            1               1           0.3166927
Map_Ref                 1            1               1           0.3166927
Latitude                1            1               1           0.3166927

=== LIME Rankings ===


Feature     Importance
---------  -----------
Vig          0.2327345
Frosts       0.0152877
Sp           0.0105594
Abbrev       0.0091842
Latitude     0.0071781
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Vig          0.1626114
Abbrev       0.0000000
Altitude     0.0000000
Brnch_Fm     0.0000000
Crown_Fm     0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Abbrev
LIME: Vig
SHAP: Vig

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Abbrev      Vig         FALSE     
FEAT_IMP vs SHAP   Abbrev      Vig         FALSE     
LIME vs SHAP       Vig         Vig         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Vig              1.031628     1.074419        1.096744           0.3603744
Abbrev           1.000000     1.000000        1.000000           0.3354134
Rep              1.000000     1.000000        1.000000           0.3354134
Locality         1.000000     1.000000        1.000000           0.3354134
Map_Ref          1.000000     1.000000        1.000000           0.3354134

=== LIME Rankings ===


Feature     Importance
---------  -----------
Vig          0.1456086
Frosts       0.0601574
Sp           0.0085766
Locality     0.0066511
Abbrev       0.0066107
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Vig          0.1703784
Abbrev       0.0000000
Altitude     0.0000000
Brnch_Fm     0.0000000
Crown_Fm     0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Vig
LIME: Vig
SHAP: Vig

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Vig         Vig         TRUE      
FEAT_IMP vs SHAP   Vig         Vig         TRUE      
LIME vs SHAP       Vig         Vig         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2173            -nan     0.1000    0.0163
     2        1.1868            -nan     0.1000    0.0131
     3        1.1656            -nan     0.1000    0.0086
     4        1.1442            -nan     0.1000    0.0088
     5        1.1216            -nan     0.1000    0.0100
     6        1.1053            -nan     0.1000    0.0082
     7        1.0925            -nan     0.1000    0.0060
     8        1.0829            -nan     0.1000    0.0021
     9        1.0694            -nan     0.1000    0.0068
    10        1.0580            -nan     0.1000    0.0051
    20        0.9988            -nan     0.1000    0.0014
    40        0.9355            -nan     0.1000    0.0005
    50        0.9095            -nan     0.1000   -0.0003



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
There were 13 warnings (use warnings() to see them)

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
Vig             1.094118     1.202614        1.240523           0.2870515
DBH             1.052288     1.091503        1.115033           0.2605304
Ht              1.013072     1.078431        1.122876           0.2574103
Sp              1.039216     1.045752        1.045752           0.2496100
Surv            1.033987     1.045752        1.092810           0.2496100

=== LIME Rankings ===


Feature    Importance
--------  -----------
Vig         0.1898530
Frosts      0.0765402
Ht          0.0511034
Sp          0.0304670
Surv        0.0214746
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
Vig         0.1439586
Ht          0.0507063
DBH         0.0275061
Sp          0.0235606
Surv        0.0207918

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Vig
LIME: Vig
SHAP: Vig

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Vig         Vig         TRUE      
FEAT_IMP vs SHAP   Vig         Vig         TRUE      
LIME vs SHAP       Vig         Vig         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
Vig             1.264463     1.314050        1.322314           0.2480499
Year            1.244628     1.297521        1.312397           0.2449298
Ht              1.117355     1.181818        1.249587           0.2230889
Sp              1.125620     1.165289        1.180165           0.2199688
PMCno           1.052893     1.115703        1.143802           0.2106084

=== LIME Rankings ===


Feature     Importance
---------  -----------
Frosts       0.2687388
Vig          0.1521195
Rainfall     0.1084579
DBH          0.0808759
Year         0.0605180
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Year         0.2642124
Rainfall     0.2426863
Vig          0.1444013
Ht           0.1137412
Stem_Fm      0.0664814

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Vig
LIME: Frosts
SHAP: Year

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Vig         Frosts      FALSE     
FEAT_IMP vs SHAP   Vig         Year        FALSE     
LIME vs SHAP       Frosts      Year        FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Vig              1.529730     1.587838        1.666216           0.3666147
Crown_Fm         1.091892     1.155405        1.214865           0.2667707
Ht               1.054054     1.067568        1.100000           0.2464899
Stem_Fm          1.024324     1.060811        1.083784           0.2449298
DBH              1.000000     1.020270        1.048649           0.2355694

=== LIME Rankings ===


Feature     Importance
---------  -----------
Frosts       0.2464805
Vig          0.0886265
Ht           0.0405448
Stem_Fm      0.0186898
Crown_Fm     0.0169192
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Vig          0.1980683
Ht           0.0645887
Crown_Fm     0.0436633
Stem_Fm      0.0332646
DBH          0.0219785

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Vig
LIME: Frosts
SHAP: Vig

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Vig         Frosts      FALSE     
FEAT_IMP vs SHAP   Vig         Vig         TRUE      
LIME vs SHAP       Frosts      Vig         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=lvq ===
Applying data scaling for method: lvq
Warning in preProcess.default(method = c("center", "scale"), x = c(0, 0,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Sp               1.112048     1.150602        1.177108           0.2979719
Abbrev           1.018072     1.024096        1.030120           0.2652106
Latitude         1.013253     1.024096        1.030120           0.2652106
Vig              1.012048     1.018072        1.024096           0.2636505
Rep              1.006024     1.012048        1.018072           0.2620905

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Sp
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Sp          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=mlpML ===
Applying data scaling for method: mlpML
Warning in preProcess.default(method = c("center", "scale"), x = c(0, 0,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Vig              1.595238     1.619048        1.619048           0.3182527
Ht               1.384127     1.444444        1.512698           0.2839314
Surv             1.330159     1.349206        1.452381           0.2652106
Crown_Fm         1.255556     1.349206        1.403175           0.2652106
Sp               1.269841     1.317460        1.369841           0.2589704

=== LIME Rankings ===


Feature     Importance
---------  -----------
Crown_Fm     0.1532422
Vig          0.1331180
Frosts       0.1314518
Sp           0.0575188
Surv         0.0460073
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Vig          0.1316982
Sp           0.0441464
Surv         0.0382276
Ht           0.0341711
Crown_Fm     0.0284707

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Vig
LIME: Crown_Fm
SHAP: Vig

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Vig         Crown_Fm    FALSE     
FEAT_IMP vs SHAP   Vig         Vig         TRUE      
LIME vs SHAP       Crown_Fm    Vig         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=multinom ===
Applying data scaling for method: multinom
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte
# weights:  88 (87 variable)
initial  value 444.307343 
iter  10 value 305.440834
iter  20 value 282.252245
iter  30 value 273.415253
iter  40 value 271.399630
iter  50 value 270.358776
iter  60 value 270.038791
final  value 268.593092 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
Sp              1.130201     1.167785        1.253691           0.2714509
Surv            1.060403     1.120805        1.131544           0.2605304
Ht              1.041611     1.073826        1.153020           0.2496100
Vig             1.033557     1.067114        1.106040           0.2480499
DBH             0.957047     1.040269        1.085906           0.2418097

=== LIME Rankings ===


Feature     Importance
---------  -----------
Frosts       0.1955936
Sp           0.1052596
Vig          0.0868524
Crown_Fm     0.0744754
Surv         0.0483640
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Sp           0.1588994
Vig          0.1033408
Surv         0.0647648
Crown_Fm     0.0318740
DBH          0.0207887

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Sp
LIME: Frosts
SHAP: Sp

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Sp          Frosts      FALSE     
FEAT_IMP vs SHAP   Sp          Sp          TRUE      
LIME vs SHAP       Frosts      Sp          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
Sp              4.310345     4.689655        5.172414           0.2121685
Vig             4.627586     4.689655        5.082759           0.2121685
Abbrev          4.041379     4.172414        4.400000           0.1887676
PMCno           2.455172     2.482759        2.655172           0.1123245
Stem_Fm         2.103448     2.137931        2.331034           0.0967239

=== LIME Rankings ===


Feature    Importance
--------  -----------
Frosts      0.4110708
Vig         0.1709538
PMCno       0.0821516
Sp          0.0760251
Stem_Fm     0.0662125
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
Vig         0.2711593
Stem_Fm     0.1103104
Sp          0.0741815
PMCno       0.0568778
Abbrev      0.0562750

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Sp
LIME: Frosts
SHAP: Vig

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Sp          Frosts      FALSE     
FEAT_IMP vs SHAP   Sp          Vig         FALSE     
LIME vs SHAP       Frosts      Vig         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=rbfDDA ===
Applying data scaling for method: rbfDDA
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Sp               1.618803     1.658120        1.716239           0.3026521
Abbrev           1.629060     1.649573        1.664957           0.3010920
Map_Ref          1.598291     1.615385        1.654701           0.2948518
Latitude         1.586325     1.615385        1.630769           0.2948518
Locality         1.447863     1.504274        1.547009           0.2745710

=== LIME Rankings ===


Feature     Importance
---------  -----------
Frosts       0.7849649
Abbrev       0.3467082
Map_Ref      0.2844616
DBH          0.2837642
Latitude     0.1973732
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Sp           0.7383978
Abbrev       0.2329148
Rainfall     0.2285001
Frosts       0.1975559
Vig          0.1351001

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Sp
LIME: Frosts
SHAP: Sp

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Sp          Frosts      FALSE     
FEAT_IMP vs SHAP   Sp          Sp          TRUE      
LIME vs SHAP       Frosts      Sp          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=rda ===
Applying data scaling for method: rda
Warning in preProcess.default(method = c("center", "scale"), x = c(0, 0,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===
Error in get_featimp: Lapack routine dgesv: system is exactly singular: U[1,1] = 0 

=== LIME Rankings ===
Error in get_lime: Lapack routine dgesv: system is exactly singular: U[1,1] = 0 
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: Lapack routine dgesv: system is exactly singular: U[1,1] = 0 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 0 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
Vig                 26.1         27.0            31.7           0.0842434
Ht                  15.7         16.5            21.0           0.0514821
DBH                  9.0         11.0            12.3           0.0343214
Sp                   8.5         10.0            12.3           0.0312012
Surv                10.0         10.0            13.3           0.0312012

=== LIME Rankings ===


Feature     Importance
---------  -----------
Frosts       0.2850023
Vig          0.1089574
Ht           0.0510404
PMCno        0.0338684
Crown_Fm     0.0274619
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
Vig          0.099972
Ht           0.067420
DBH          0.034780
Stem_Fm      0.028664
PMCno        0.024620

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Vig
LIME: Frosts
SHAP: Vig

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Vig         Frosts      FALSE     
FEAT_IMP vs SHAP   Vig         Vig         TRUE      
LIME vs SHAP       Frosts      Vig         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Abbrev                  1            1               1           0.3166927
Rep                     1            1               1           0.3166927
Locality                1            1               1           0.3166927
Map_Ref                 1            1               1           0.3166927
Latitude                1            1               1           0.3166927

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Abbrev               0
Altitude             0
Brnch_Fm             0
Crown_Fm             0
DBH                  0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: Abbrev
SHAP: Abbrev

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Abbrev      Abbrev      TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=simpls ===
Applying data scaling for method: simpls
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Vig              1.013415     1.024390        1.047561           0.2620905
Sp               1.007317     1.018293        1.035366           0.2605304
Altitude         1.000000     1.006098        1.006098           0.2574103
Rainfall         0.995122     1.006098        1.018293           0.2574103
PMCno            1.001219     1.006098        1.010976           0.2574103

=== LIME Rankings ===


Feature     Importance
---------  -----------
Frosts       0.0263969
Sp           0.0244467
Vig          0.0221175
Crown_Fm     0.0164252
PMCno        0.0098973
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Sp           0.0228402
Vig          0.0175320
Rainfall     0.0118346
Year         0.0116874
Frosts       0.0082577

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Vig
LIME: Frosts
SHAP: Sp

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Vig         Frosts      FALSE     
FEAT_IMP vs SHAP   Vig         Sp          FALSE     
LIME vs SHAP       Frosts      Sp          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=svmLinear ===
Applying data scaling for method: svmLinear
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
In .local(x, ...) : Variable(s) `' constant. Cannot scale data.

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
Sp              1.168345     1.194245        1.237410           0.2589704
Surv            1.096403     1.165468        1.184173           0.2527301
Vig             1.046043     1.100719        1.158273           0.2386895
Ht              1.073381     1.079137        1.136691           0.2340094
Map_Ref         1.011511     1.064748        1.077698           0.2308892

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Sp
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Sp          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=svmRadial ===
Applying data scaling for method: svmRadial
Warning in preProcess.default(method = c("center", "scale"), x = c(0, 0,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning messages:
1: In .local(x, ...) : Variable(s) `' constant. Cannot scale data.
2: In .local(x, ...) : Variable(s) `' constant. Cannot scale data.

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Sp               1.083544     1.177215        1.212658           0.2901716
Abbrev           1.065823     1.107595        1.118987           0.2730109
Map_Ref          1.089873     1.094937        1.120253           0.2698908
Latitude         1.069620     1.075949        1.097468           0.2652106
Vig              1.031646     1.044304        1.050633           0.2574103

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Sp
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Sp          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1984 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Vig              1.192647     1.213235        1.289706           0.2574103
Ht               1.129412     1.205882        1.277941           0.2558502
Altitude         1.108823     1.169118        1.202941           0.2480499
Stem_Fm          1.104412     1.139706        1.147059           0.2418097
Frosts           1.083824     1.110294        1.138235           0.2355694

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Vig
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Vig         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=knn ===
Applying data scaling for method: knn
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
Sp              1.637931     1.655172        1.760345           0.2995320
Abbrev          1.046552     1.060345        1.091379           0.1918877
PMCno           1.037931     1.060345        1.120690           0.1918877
Rep             1.027586     1.051724        1.079310           0.1903276
Ht              1.027586     1.043103        1.065517           0.1887676

=== LIME Rankings ===


Feature     Importance
---------  -----------
Sp           0.1582783
Frosts       0.1257554
Vig          0.0411165
Crown_Fm     0.0349933
Locality     0.0161622
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
Sp          0.1463333
Vig         0.0208000
Rep         0.0159333
Abbrev      0.0151333
Map_Ref     0.0149333

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Sp
LIME: Sp
SHAP: Sp

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Sp          Sp          TRUE      
FEAT_IMP vs SHAP   Sp          Sp          TRUE      
LIME vs SHAP       Sp          Sp          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=eucalyptus, Method=bayesglm ===
Applying data scaling for method: bayesglm
Warning in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10,  :
  These variables have zero variances: AbbrevCly, AbbrevMor, AbbrevWen, LocalityNorthern_Hawkes_Bay, LocalityCentral_Poverty_Bay, Map_RefN116_848/985, Map_RefN141_295/063, Map_RefN98_539/567, Latitude39__00, Latitude39__43, Latitude82__32, Spra, Spte


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Sp              1.1245033     1.172185        1.184106           0.2761310
Surv            1.0503311     1.119205        1.132450           0.2636505
Vig             1.0198675     1.039735        1.094040           0.2449298
Abbrev          0.9933775     1.026490        1.054305           0.2418097
Locality        0.9907285     1.019867        1.052980           0.2402496

=== LIME Rankings ===


Feature     Importance
---------  -----------
Frosts       0.1838951
Vig          0.0826389
Sp           0.0797107
Crown_Fm     0.0730947
Surv         0.0581588
Warning message:
Frosts does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Sp           0.1279010
Vig          0.0986639
Surv         0.0729004
Crown_Fm     0.0313300
Rep          0.0144858

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP            -1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Sp
LIME: Frosts
SHAP: Sp

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Sp          Frosts      FALSE     
FEAT_IMP vs SHAP   Sp          Sp          TRUE      
LIME vs SHAP       Frosts      Sp          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: iris
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petallength         10.33333         11.5       12.500000                0.46
petalwidth           7.30000          8.5        9.733333                0.34
sepallength          1.00000          1.0        1.000000                0.04
sepalwidth           1.00000          1.0        1.000000                0.04

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength     0.9626735
sepalwidth      0.0051538
sepallength     0.0036259
petalwidth      0.0032583

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength          0.71
petalwidth           0.00
sepallength          0.00
sepalwidth           0.00

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petallength
LIME: petallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petallength   petallength   TRUE      
FEAT_IMP vs SHAP   petallength   petallength   TRUE      
LIME vs SHAP       petallength   petallength   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=fda ===
No scaling applied for method: fda
Error in get(ctr, mode = "function", envir = parent.frame()) : 
  object 'contr.earth.response' of mode 'function' was not found
Calls: train_model ... model.matrix -> model.matrix.default -> contrasts -> get
Execution halted
FAILED - See error above


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986            -nan     0.1000    0.2420
     2        0.9138            -nan     0.1000    0.1986
     3        0.7598            -nan     0.1000    0.1462
     4        0.6482            -nan     0.1000    0.1313
     5        0.5614            -nan     0.1000    0.1070
     6        0.4848            -nan     0.1000    0.0910
     7        0.4229            -nan     0.1000    0.0730
     8        0.3713            -nan     0.1000    0.0633
     9        0.3272            -nan     0.1000    0.0388
    10        0.2945            -nan     0.1000    0.0423
    20        0.1243            -nan     0.1000    0.0073
    40        0.0630            -nan     0.1000   -0.0067
    50        0.0542            -nan     0.1000   -0.0033



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petallength        26.466667    28.333333       31.400000           0.5666667
petalwidth         10.533333    12.000000       12.866667           0.2400000
sepalwidth          2.000000     2.000000        2.266667           0.0400000
sepallength         1.333333     1.666667        1.666667           0.0333333

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength     0.8842904
sepalwidth      0.0077070
sepallength     0.0073315
petalwidth      0.0034300

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength     0.6675944
sepallength     0.0019256
petalwidth      0.0006535
sepalwidth      0.0002545

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petallength
LIME: petallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petallength   petallength   TRUE      
FEAT_IMP vs SHAP   petallength   petallength   TRUE      
LIME vs SHAP       petallength   petallength   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning messages:
1: glm.fit: fitted probabilities numerically 0 or 1 occurred 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
3: glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petallength             39.0         41.5            43.2           0.5533333
petalwidth              11.5         12.5            15.0           0.1666667
sepalwidth               2.6          3.0             3.4           0.0400000
sepallength              1.2          2.0             3.4           0.0266667

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength     0.8393551
petalwidth      0.0384537
sepalwidth      0.0075168
sepallength     0.0028265

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength     0.6644657
petalwidth      0.0457179
sepallength     0.0002194
sepalwidth      0.0000358

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petallength
LIME: petallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petallength   petallength   TRUE      
FEAT_IMP vs SHAP   petallength   petallength   TRUE      
LIME vs SHAP       petallength   petallength   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petallength            19.80        21.00            22.6           0.5600000
petalwidth              4.15         5.25             6.6           0.1400000
sepallength             1.00         1.00             1.0           0.0266667
sepalwidth              1.00         1.00             1.0           0.0266667

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength     0.9626735
sepalwidth      0.0051538
sepallength     0.0036259
petalwidth      0.0032583

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength          0.71
petalwidth           0.00
sepallength          0.00
sepalwidth           0.00

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petallength
LIME: petallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petallength   petallength   TRUE      
FEAT_IMP vs SHAP   petallength   petallength   TRUE      
LIME vs SHAP       petallength   petallength   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petalwidth              7.96          9.2            9.72           0.3066667
petallength             6.56          7.6            8.84           0.2533333
sepallength             2.48          3.4            3.56           0.1133333
sepalwidth              1.28          1.6            1.80           0.0533333

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: petalwidth
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1    Feature_2   Agreement 
-----------------  -----------  ----------  ----------
FEAT_IMP vs SHAP   petalwidth   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petalwidth          5.383333     5.750000        6.000000           0.4600000
petallength         4.766667     4.916667        5.266667           0.3933333
sepalwidth          1.666667     1.833333        2.166667           0.1466667
sepallength         1.166667     1.250000        1.783333           0.1000000

=== LIME Rankings ===


Feature        Importance
------------  -----------
petalwidth      0.4225119
petallength     0.3576037
sepalwidth      0.0739987
sepallength     0.0675541

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petalwidth      0.3347396
petallength     0.2341963
sepallength     0.0332276
sepalwidth      0.0267666

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petalwidth
LIME: petalwidth
SHAP: petalwidth

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1    Feature_2    Agreement 
-----------------  -----------  -----------  ----------
FEAT_IMP vs LIME   petalwidth   petalwidth   TRUE      
FEAT_IMP vs SHAP   petalwidth   petalwidth   TRUE      
LIME vs SHAP       petalwidth   petalwidth   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=multinom ===
Applying data scaling for method: multinom
# weights:  18 (10 variable)
initial  value 164.791843 
iter  10 value 16.326750
iter  20 value 6.016313
iter  30 value 5.967080
iter  40 value 5.954635
iter  50 value 5.952867
iter  60 value 5.952088
iter  70 value 5.951629
iter  80 value 5.951337
iter  90 value 5.950851
iter 100 value 5.950641
final  value 5.950641 
stopped after 100 iterations


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petallength             40.0         41.5            44.0           0.5533333
petalwidth              26.1         26.5            29.9           0.3533333
sepalwidth               2.6          3.5             3.9           0.0466667
sepallength              1.6          2.0             2.5           0.0266667

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength     0.6426900
petalwidth      0.2493810
sepallength     0.0886968
sepalwidth      0.0745254

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength     0.5073539
petalwidth      0.1580997
sepallength     0.0412277
sepalwidth      0.0297702

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petallength
LIME: petallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petallength   petallength   TRUE      
FEAT_IMP vs SHAP   petallength   petallength   TRUE      
LIME vs SHAP       petallength   petallength   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petalwidth             20.25         22.5           22.95           0.6000000
petallength             4.35          5.5            6.00           0.1466667
sepallength             1.00          1.0            1.00           0.0266667
sepalwidth              1.00          1.0            1.00           0.0266667

=== LIME Rankings ===


Feature        Importance
------------  -----------
petalwidth      0.8829455
sepalwidth      0.0097198
petallength     0.0078983
sepallength     0.0054382

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petalwidth           0.71
petallength          0.00
sepallength          0.00
sepalwidth           0.00

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petalwidth
LIME: petalwidth
SHAP: petalwidth

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1    Feature_2    Agreement 
-----------------  -----------  -----------  ----------
FEAT_IMP vs LIME   petalwidth   petalwidth   TRUE      
FEAT_IMP vs SHAP   petalwidth   petalwidth   TRUE      
LIME vs SHAP       petalwidth   petalwidth   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petalwidth             13.05        13.75           14.80           0.3666667
petallength            10.10        10.75           11.85           0.2866667
sepallength             6.60         7.25            8.10           0.1933333
sepalwidth              6.20         7.00            7.45           0.1866667

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength      4.539304
petalwidth       4.244890
sepallength      3.522490
sepalwidth       2.518889

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength      5.371540
petalwidth       5.053104
sepallength      4.773371
sepalwidth       2.203025

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petalwidth
LIME: petallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petalwidth    petallength   FALSE     
FEAT_IMP vs SHAP   petalwidth    petallength   FALSE     
LIME vs SHAP       petallength   petallength   TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petallength        20.066667    20.666667       22.466667           0.4133333
petalwidth         20.000000    20.666667       21.800000           0.4133333
sepallength         1.733333     2.666667        3.533333           0.0533333
sepalwidth          2.333333     2.333333        2.666667           0.0466667

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength     0.5242389
petalwidth      0.2503067
sepalwidth      0.0416603
sepallength     0.0065042

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength     0.4508113
petalwidth      0.2506467
sepalwidth      0.0251361
sepallength     0.0165941

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petallength
LIME: petallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petallength   petallength   TRUE      
FEAT_IMP vs SHAP   petallength   petallength   TRUE      
LIME vs SHAP       petallength   petallength   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petallength        0.2133333    0.2533333       0.2586667           0.2533333
petalwidth         0.1613333    0.2000000       0.2160000           0.2000000
sepalwidth         0.0133333    0.0133333       0.0200000           0.0133333
sepallength        0.0013333    0.0066667       0.0240000           0.0066667
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength     0.4143929
petalwidth      0.3864733
sepallength     0.0309873
sepalwidth      0.0094447

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petalwidth       0.327644
petallength      0.325612
sepallength      0.026604
sepalwidth       0.004712

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: petallength
LIME: petallength
SHAP: petalwidth

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petallength   petallength   TRUE      
FEAT_IMP vs SHAP   petallength   petalwidth    FALSE     
LIME vs SHAP       petallength   petalwidth    FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
sepallength                1            1               1           0.6666667
sepalwidth                 1            1               1           0.6666667
petallength                1            1               1           0.6666667
petalwidth                 1            1               1           0.6666667

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength             0
petalwidth              0
sepallength             0
sepalwidth              0

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP          -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: sepallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs SHAP   sepallength   petallength   FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petalwidth             1.084         1.10           1.152           0.3666667
petallength            1.048         1.08           1.080           0.3600000
sepallength            1.000         1.00           1.000           0.3333333
sepalwidth             1.000         1.00           1.020           0.3333333

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength     0.0929775
petalwidth      0.0804505
sepallength     0.0712219
sepalwidth      0.0311545

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength     0.0733556
petalwidth      0.0711620
sepallength     0.0508243
sepalwidth      0.0170825

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petalwidth
LIME: petallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petalwidth    petallength   FALSE     
FEAT_IMP vs SHAP   petalwidth    petallength   FALSE     
LIME vs SHAP       petallength   petallength   TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petalwidth             10.76         12.4           13.76           0.4133333
petallength             9.48         10.8           11.84           0.3600000
sepalwidth              1.64          1.8            1.96           0.0600000
sepallength             0.60          1.2            1.56           0.0400000

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: petalwidth
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1    Feature_2   Agreement 
-----------------  -----------  ----------  ----------
FEAT_IMP vs SHAP   petalwidth   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petalwidth             10.28         11.0           13.52           0.3666667
petallength             8.00          9.2            9.52           0.3066667
sepallength             2.24          2.8            2.80           0.0933333
sepalwidth              1.56          2.2            2.84           0.0733333

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: petalwidth
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1    Feature_2   Agreement 
-----------------  -----------  ----------  ----------
FEAT_IMP vs SHAP   petalwidth   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1616 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petalwidth          15.83333     16.83333        17.13333           0.6733333
sepallength          1.00000      1.00000         1.00000           0.0400000
sepalwidth           1.00000      1.00000         1.00000           0.0400000
petallength          1.00000      1.00000         1.00000           0.0400000

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: petalwidth
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1    Feature_2   Agreement 
-----------------  -----------  ----------  ----------
FEAT_IMP vs SHAP   petalwidth   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petalwidth          6.314286     7.000000        7.800000           0.3266667
petallength         4.057143     4.857143        5.514286           0.2266667
sepalwidth          1.571429     1.857143        1.971429           0.0866667
sepallength         1.571429     1.571429        1.857143           0.0733333

=== LIME Rankings ===


Feature        Importance
------------  -----------
petallength     0.3761717
petalwidth      0.2844327
sepalwidth      0.1787436
sepallength     0.1780780

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
petallength     0.2548000
petalwidth      0.2048000
sepalwidth      0.0906667
sepallength     0.0797333

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: petalwidth
LIME: petallength
SHAP: petallength

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2     Agreement 
-----------------  ------------  ------------  ----------
FEAT_IMP vs LIME   petalwidth    petallength   FALSE     
FEAT_IMP vs SHAP   petalwidth    petallength   FALSE     
LIME vs SHAP       petallength   petallength   TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=iris, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
petallength            1.884         1.98           2.096           0.6600000
sepallength            1.000         1.00           1.000           0.3333333
sepalwidth             1.000         1.00           1.016           0.3333333
petalwidth             1.000         1.00           1.000           0.3333333

=== LIME Rankings ===
Error in get_lime: length of 'dimnames' [2] not equal to array extent 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: petallength
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1     Feature_2   Agreement 
-----------------  ------------  ----------  ----------
FEAT_IMP vs SHAP   petallength   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


Dataset: kc1
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
uniq_Op         1.075497     1.089404        1.101325           0.1559981
d               1.060927     1.079470        1.082119           0.1545756
loc             1.000000     1.000000        1.000000           0.1431958
v_g             1.000000     1.000000        1.000000           0.1431958
ev_g            1.000000     1.000000        1.000000           0.1431958

=== LIME Rankings ===


Feature      Importance
----------  -----------
d             0.1740230
uniq_Opnd     0.0297218
uniq_Op       0.0257045
ev_g          0.0067488
l             0.0066276
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
d             0.0936370
uniq_Opnd     0.0294837
lOBlank       0.0275801
lOCode        0.0085234
loc           0.0043204

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: uniq_Op
LIME: d
SHAP: d

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   uniq_Op     d           FALSE     
FEAT_IMP vs SHAP   uniq_Op     d           FALSE     
LIME vs SHAP       d           d           TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature       importance.05   importance   importance.95   permutation.error
-----------  --------------  -----------  --------------  ------------------
total_Opnd         1.408669     1.433437         1.46935           0.2195353
loc                1.000000     1.000000         1.00000           0.1531532
v_g                1.000000     1.000000         1.00000           0.1531532
ev_g               1.000000     1.000000         1.00000           0.1531532
iv_g               1.000000     1.000000         1.00000           0.1531532

=== LIME Rankings ===


Feature              Importance
------------------  -----------
total_Opnd            0.4394237
lOComment             0.0369208
locCodeAndComment     0.0311112
ev_g                  0.0140117
uniq_Op               0.0085048
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
total_Opnd      0.2032772
b               0.0000000
branchCount     0.0000000
d               0.0000000
e               0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: total_Opnd
LIME: total_Opnd
SHAP: total_Opnd

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1    Feature_2    Agreement 
-----------------  -----------  -----------  ----------
FEAT_IMP vs LIME   total_Opnd   total_Opnd   TRUE      
FEAT_IMP vs SHAP   total_Opnd   total_Opnd   TRUE      
LIME vs SHAP       total_Opnd   total_Opnd   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.8352            -nan     0.1000    0.0111
     2        0.8165            -nan     0.1000    0.0085
     3        0.8006            -nan     0.1000    0.0080
     4        0.7880            -nan     0.1000    0.0066
     5        0.7784            -nan     0.1000    0.0048
     6        0.7675            -nan     0.1000    0.0052
     7        0.7603            -nan     0.1000    0.0028
     8        0.7559            -nan     0.1000    0.0015
     9        0.7464            -nan     0.1000    0.0043
    10        0.7415            -nan     0.1000    0.0020
    20        0.7065            -nan     0.1000   -0.0000
    40        0.6861            -nan     0.1000    0.0000
    50        0.6785            -nan     0.1000   -0.0001



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
total_Opnd               1.0503448     1.058621        1.081379           0.1455666
d                        1.0255172     1.034483        1.040000           0.1422475
locCodeAndComment        1.0275862     1.027586        1.033793           0.1412992
i                        0.9882759     1.017241        1.031035           0.1398767
v_g                      1.0103448     1.013793        1.013793           0.1394026

=== LIME Rankings ===


Feature              Importance
------------------  -----------
locCodeAndComment     0.0550464
lOComment             0.0539817
total_Opnd            0.0464847
d                     0.0396502
i                     0.0390550
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature       Importance
-----------  -----------
i              0.0261907
total_Opnd     0.0245718
lOComment      0.0202941
v              0.0194826
lOCode         0.0194561

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: total_Opnd
LIME: locCodeAndComment
SHAP: i

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   total_Opnd          locCodeAndComment   FALSE     
FEAT_IMP vs SHAP   total_Opnd          i                   FALSE     
LIME vs SHAP       locCodeAndComment   i                   FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature       importance.05   importance   importance.95   permutation.error
-----------  --------------  -----------  --------------  ------------------
total_Opnd         2.412782     2.432331        2.486466           0.3067805
b                  2.366165     2.390977        2.460902           0.3015647
v                  2.064662     2.097744        2.155639           0.2645804
total_Op           1.936842     1.962406        2.014286           0.2475107
v_g                1.537594     1.567669        1.592481           0.1977240

=== LIME Rankings ===


Feature       Importance
-----------  -----------
v              0.3371186
total_Op       0.2742123
total_Opnd     0.2281739
v_g            0.1039523
iv_g           0.0957253
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
v               0.3822701
b               0.2869745
total_Opnd      0.1953420
total_Op        0.1272853
branchCount     0.1043649

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          -1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: total_Opnd
LIME: v
SHAP: v

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1    Feature_2   Agreement 
-----------------  -----------  ----------  ----------
FEAT_IMP vs LIME   total_Opnd   v           FALSE     
FEAT_IMP vs SHAP   total_Opnd   v           FALSE     
LIME vs SHAP       v            v           TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
uniq_Op         1.298540     1.335766        1.351825           0.1735420
d               1.248175     1.295620        1.306569           0.1683262
loc             1.267153     1.277372        1.295620           0.1659554
v               1.102920     1.105839        1.143066           0.1436700
e               1.084672     1.091241        1.121898           0.1417734

=== LIME Rankings ===


Feature    Importance
--------  -----------
e           0.1151514
d           0.0994327
v           0.0641082
uniq_Op     0.0212708
lOBlank     0.0190297
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
v           0.0751883
e           0.0630110
d           0.0458473
loc         0.0370499
uniq_Op     0.0338728

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: uniq_Op
LIME: e
SHAP: v

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   uniq_Op     e           FALSE     
FEAT_IMP vs SHAP   uniq_Op     v           FALSE     
LIME vs SHAP       e           v           FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
uniq_Opnd                1.0407035     1.060302        1.100502           0.2000948
locCodeAndComment        1.0206030     1.030151        1.036181           0.1944049
uniq_Op                  1.0055276     1.020101        1.045226           0.1925083
loc                      0.9874372     1.015075        1.028643           0.1915600
v                        0.9984925     1.015075        1.034673           0.1915600

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: uniq_Opnd
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   uniq_Opnd   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature       importance.05   importance   importance.95   permutation.error
-----------  --------------  -----------  --------------  ------------------
total_Opnd         1.394631     1.406040        1.438255           0.1986724
d                  1.280537     1.302013        1.325503           0.1839734
e                  1.202013     1.234899        1.248993           0.1744903
t                  1.169799     1.194631        1.238926           0.1688004
total_Op           1.140940     1.194631        1.210738           0.1688004

=== LIME Rankings ===


Feature       Importance
-----------  -----------
e              0.1260567
total_Op       0.1259240
t              0.1120480
total_Opnd     0.0853226
v_g            0.0796081
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature       Importance
-----------  -----------
b              0.1705057
total_Op       0.0949896
d              0.0675942
total_Opnd     0.0647190
v_g            0.0614139

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: total_Opnd
LIME: e
SHAP: b

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1    Feature_2   Agreement 
-----------------  -----------  ----------  ----------
FEAT_IMP vs LIME   total_Opnd   e           FALSE     
FEAT_IMP vs SHAP   total_Opnd   b           FALSE     
LIME vs SHAP       e            b           FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=multinom ===
Applying data scaling for method: multinom
# weights:  23 (22 variable)
initial  value 1461.847404 
iter  10 value 745.390684
iter  20 value 710.878606
final  value 709.912664 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature        importance.05   importance   importance.95   permutation.error
------------  --------------  -----------  --------------  ------------------
total_Op            1.384138     1.472414        1.486207           0.2024656
loc                 1.371034     1.420690        1.464138           0.1953532
v_g                 1.386897     1.400000        1.437241           0.1925083
total_Opnd          1.333103     1.375862        1.413103           0.1891892
branchCount         1.336552     1.368966        1.435172           0.1882409

=== LIME Rankings ===


Feature        Importance
------------  -----------
v_g             0.3450139
total_Op        0.2908700
iv_g            0.2066938
branchCount     0.1966401
lOCode          0.1835855
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
b            0.2691437
v_g          0.1907047
total_Op     0.1607946
loc          0.1178668
lOCode       0.1147236

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: total_Op
LIME: v_g
SHAP: b

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   total_Op    v_g         FALSE     
FEAT_IMP vs SHAP   total_Op    b           FALSE     
LIME vs SHAP       v_g         b           FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature              importance.05   importance   importance.95   permutation.error
------------------  --------------  -----------  --------------  ------------------
uniq_Op                   1.177617     1.184116        1.205054           0.1555239
locCodeAndComment         1.046209     1.057762        1.057762           0.1389284
b                         1.047653     1.054152        1.073646           0.1384542
iv_g                      1.037545     1.046931        1.059206           0.1375059
v_g                       1.033213     1.039711        1.042599           0.1365576

=== LIME Rankings ===


Feature       Importance
-----------  -----------
b              0.2120987
uniq_Op        0.0871599
total_Opnd     0.0768067
i              0.0525183
v_g            0.0458975
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
i           0.0929044
b           0.0887614
lOBlank     0.0854971
iv_g        0.0717010
uniq_Op     0.0479604

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: uniq_Op
LIME: b
SHAP: i

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   uniq_Op     b           FALSE     
FEAT_IMP vs SHAP   uniq_Op     i           FALSE     
LIME vs SHAP       b           i           FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
d               4.187629     4.237113        4.338144           0.1948791
lOBlank         2.251546     2.422680        2.443299           0.1114272
uniq_Op         2.088660     2.206186        2.261856           0.1014699
i               2.136083     2.185567        2.247423           0.1005216
loc             2.051546     2.154639        2.204124           0.0990991

=== LIME Rankings ===


Feature              Importance
------------------  -----------
locCodeAndComment     0.0271827
lOBlank               0.0068686
b                     0.0065826
v_g                   0.0064015
branchCount           0.0061889
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
lOComment      3.240869
ev_g           2.715557
d              2.426815
i              1.790544
iv_g           1.713977

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: d
LIME: locCodeAndComment
SHAP: lOComment

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   d                   locCodeAndComment   FALSE     
FEAT_IMP vs SHAP   d                   lOComment           FALSE     
LIME vs SHAP       locCodeAndComment   lOComment           FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature       importance.05   importance   importance.95   permutation.error
-----------  --------------  -----------  --------------  ------------------
e                  4.922543     4.945087        4.980925           0.8112850
t                  4.934104     4.939306        4.994220           0.8103367
n                  4.916763     4.936416        4.964740           0.8098625
total_Op           4.802312     4.815029        4.866474           0.7899478
total_Opnd         4.780925     4.789017        4.814451           0.7856804

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: no rows to aggregate 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 1 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 1 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 1 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
loc             1.668966     2.000000        2.096552           0.0275012
i               1.427586     1.551724        1.620690           0.0213371
lOCode          1.462069     1.517241        1.648276           0.0208630
lOBlank         1.275862     1.310345        1.406897           0.0180180
d               1.137931     1.172414        1.241379           0.0161214

=== LIME Rankings ===


Feature     Importance
---------  -----------
loc          0.0415715
lOCode       0.0360314
total_Op     0.0201034
lOBlank      0.0181458
n            0.0179417
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature       Importance
-----------  -----------
b               0.066832
i               0.029700
total_Opnd      0.029584
lOComment       0.028844
total_Op        0.026724

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              NA                 0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: loc
LIME: loc
SHAP: b

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   loc         loc         TRUE      
FEAT_IMP vs SHAP   loc         b           FALSE     
LIME vs SHAP       loc         b           FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
loc                    1            1               1           0.1545756
v_g                    1            1               1           0.1545756
ev_g                   1            1               1           0.1545756
iv_g                   1            1               1           0.1545756
n                      1            1               1           0.1545756

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature        Importance
------------  -----------
b                       0
branchCount             0
d                       0
e                       0
ev_g                    0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: loc
SHAP: b

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   loc         b           FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature       importance.05   importance   importance.95   permutation.error
-----------  --------------  -----------  --------------  ------------------
uniq_Opnd         1.0062305     1.009346        1.011838           0.1536273
loc               0.9981308     1.006231        1.006231           0.1531532
d                 1.0031153     1.006231        1.009346           0.1531532
total_Opnd        1.0062305     1.006231        1.008723           0.1531532
n                 1.0031153     1.003115        1.005607           0.1526790

=== LIME Rankings ===


Feature    Importance
--------  -----------
lOBlank     0.0266030
b           0.0241677
iv_g        0.0206530
e           0.0201769
t           0.0199298
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
b             0.0102117
uniq_Op       0.0053925
d             0.0043673
uniq_Opnd     0.0036930
l             0.0036823

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: uniq_Opnd
LIME: lOBlank
SHAP: b

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   uniq_Opnd   lOBlank     FALSE     
FEAT_IMP vs SHAP   uniq_Opnd   b           FALSE     
LIME vs SHAP       lOBlank     b           FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
v                 1.707947     1.721854        1.755629           0.2465624
uniq_Opnd         1.194040     1.218543        1.246358           0.1744903
d                 1.185431     1.205298        1.222517           0.1725936
iv_g              1.139073     1.145695        1.155629           0.1640588
v_g               1.040397     1.059603        1.068874           0.1517307

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: v
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   v           NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
loc             1.000000     1.003077        1.003077           0.1545756
v_g             1.003077     1.003077        1.003077           0.1545756
ev_g            1.003077     1.003077        1.003077           0.1545756
iv_g            1.000615     1.003077        1.003077           0.1545756
n               1.000000     1.003077        1.003077           0.1545756

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: loc
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   loc         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature       importance.05   importance   importance.95   permutation.error
-----------  --------------  -----------  --------------  ------------------
uniq_Opnd          1.083276     1.105802        1.117406           0.1536273
d                  1.075085     1.095563        1.098976           0.1522048
total_Opnd         1.083276     1.095563        1.111945           0.1522048
loc                1.064846     1.078498        1.101706           0.1498340
i                  1.075768     1.078498        1.088055           0.1498340

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: uniq_Opnd
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   uniq_Opnd   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
i                 1.214694     1.240816        1.269388           0.1441441
lOBlank           1.161633     1.208163        1.215510           0.1403509
uniq_Opnd         1.124082     1.146939        1.157551           0.1332385
iv_g              1.089796     1.110204        1.118367           0.1289711
d                 1.086531     1.102041        1.163265           0.1280228

=== LIME Rankings ===


Feature              Importance
------------------  -----------
locCodeAndComment     0.2053023
lOBlank               0.1246156
b                     0.0922583
e                     0.0907474
t                     0.0829545
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
b           0.0851159
i           0.0503216
l           0.0422291
iv_g        0.0349495
lOBlank     0.0297039

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: i
LIME: locCodeAndComment
SHAP: b

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1           Feature_2           Agreement 
-----------------  ------------------  ------------------  ----------
FEAT_IMP vs LIME   i                   locCodeAndComment   FALSE     
FEAT_IMP vs SHAP   i                   b                   FALSE     
LIME vs SHAP       locCodeAndComment   b                   FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=kc1, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
total_Op         1.313699     1.380137        1.406849           0.1910858
d                1.342466     1.349315        1.378767           0.1868184
v_g              1.254795     1.263699        1.280822           0.1749644
iv_g             1.227397     1.250000        1.264384           0.1730678
lOCode           1.158904     1.198630        1.232877           0.1659554

=== LIME Rankings ===


Feature     Importance
---------  -----------
total_Op     0.2868900
v_g          0.2778934
iv_g         0.2737721
b            0.2393220
lOCode       0.1633973
Warning messages:
1: ev_g does not contain enough variance to use quantile binning. Using standard binning instead. 
2: lOComment does not contain enough variance to use quantile binning. Using standard binning instead. 
3: locCodeAndComment does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
b            0.2578261
total_Op     0.1514570
d            0.1280778
v_g          0.1245720
iv_g         0.1167831

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: total_Op
LIME: total_Op
SHAP: b

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   total_Op    total_Op    TRUE      
FEAT_IMP vs SHAP   total_Op    b           FALSE     
LIME vs SHAP       total_Op    b           FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: liver-disorders
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
mcv                    1            1               1           0.4202899
alkphos                1            1               1           0.4202899
sgpt                   1            1               1           0.4202899
sgot                   1            1               1           0.4202899
gammagt                1            1               1           0.4202899

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
alkphos             0
drinks              0
gammagt             0
mcv                 0
sgot                0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: mcv
SHAP: alkphos

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   mcv         alkphos     FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
gammagt         1.139394     1.166667         1.19697           0.4463768
mcv             1.000000     1.000000         1.00000           0.3826087
alkphos         1.000000     1.000000         1.00000           0.3826087
sgpt            1.000000     1.000000         1.00000           0.3826087
sgot            1.000000     1.000000         1.00000           0.3826087

=== LIME Rankings ===


Feature    Importance
--------  -----------
gammagt     0.1409492
drinks      0.0033692
mcv         0.0032139
alkphos     0.0025755
sgpt        0.0025314

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
gammagt      0.125673
alkphos      0.000000
drinks       0.000000
mcv          0.000000
sgot         0.000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: gammagt
LIME: gammagt
SHAP: gammagt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   gammagt     gammagt     TRUE      
FEAT_IMP vs SHAP   gammagt     gammagt     TRUE      
LIME vs SHAP       gammagt     gammagt     TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3524            -nan     0.1000   -0.0002
     2        1.3461            -nan     0.1000    0.0003
     3        1.3339            -nan     0.1000    0.0045
     4        1.3236            -nan     0.1000    0.0032
     5        1.3149            -nan     0.1000    0.0042
     6        1.3070            -nan     0.1000    0.0005
     7        1.2986            -nan     0.1000    0.0009
     8        1.2895            -nan     0.1000    0.0025
     9        1.2818            -nan     0.1000    0.0029
    10        1.2769            -nan     0.1000    0.0001
    20        1.2213            -nan     0.1000   -0.0003
    40        1.1375            -nan     0.1000   -0.0005
    50        1.1038            -nan     0.1000   -0.0029



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
gammagt         1.451163     1.534884        1.702326           0.3826087
sgpt            1.386046     1.406977        1.458139           0.3507246
sgot            1.100000     1.139535        1.204651           0.2840580
alkphos         1.072093     1.116279        1.137209           0.2782609
drinks          1.034884     1.046512        1.081395           0.2608696

=== LIME Rankings ===


Feature    Importance
--------  -----------
sgpt        0.1467703
gammagt     0.1350441
sgot        0.0754325
alkphos     0.0576637
mcv         0.0408347

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
sgpt        0.1210864
gammagt     0.0953114
alkphos     0.0510081
mcv         0.0372754
sgot        0.0334463

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: gammagt
LIME: sgpt
SHAP: sgpt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   gammagt     sgpt        FALSE     
FEAT_IMP vs SHAP   gammagt     sgpt        FALSE     
LIME vs SHAP       sgpt        sgpt        TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
gammagt        1.4740741     1.592593        1.632099           0.3739130
sgpt           1.4419753     1.555556        1.617284           0.3652174
sgot           1.1481481     1.234568        1.355556           0.2898551
drinks         1.1604938     1.234568        1.266667           0.2898551
mcv            0.9925926     1.086420        1.148148           0.2550725

=== LIME Rankings ===


Feature    Importance
--------  -----------
sgpt        0.2426347
mcv         0.2086252
sgot        0.1973845
gammagt     0.1741044
alkphos     0.0468364

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
sgpt        0.2783578
gammagt     0.1632189
sgot        0.0950241
mcv         0.0777832
alkphos     0.0399375

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: gammagt
LIME: sgpt
SHAP: sgpt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   gammagt     sgpt        FALSE     
FEAT_IMP vs SHAP   gammagt     sgpt        FALSE     
LIME vs SHAP       sgpt        sgpt        TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
gammagt         1.651948     1.727273        1.761039           0.3855072
sgpt            1.527273     1.558442        1.607792           0.3478261
drinks          1.241558     1.272727        1.366234           0.2840580
alkphos         1.132467     1.168831        1.200000           0.2608696
sgot            1.072727     1.155844        1.179221           0.2579710

=== LIME Rankings ===


Feature    Importance
--------  -----------
gammagt     0.1966708
sgpt        0.0873120
sgot        0.0323910
alkphos     0.0259966
drinks      0.0195418

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
gammagt     0.1768076
sgpt        0.1048263
sgot        0.0330608
drinks      0.0287205
alkphos     0.0270093

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: gammagt
LIME: gammagt
SHAP: gammagt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   gammagt     gammagt     TRUE      
FEAT_IMP vs SHAP   gammagt     gammagt     TRUE      
LIME vs SHAP       gammagt     gammagt     TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
drinks         1.0331126     1.046358        1.063576           0.4579710
mcv            0.9986755     1.039735        1.046358           0.4550725
sgpt           1.0066225     1.013245        1.051656           0.4434783
sgot           1.0026490     1.013245        1.019867           0.4434783
alkphos        1.0000000     1.000000        1.027815           0.4376812

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: drinks
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   drinks      NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
sgpt            1.432258     1.505376        1.615054           0.4057971
gammagt         1.475269     1.483871        1.544086           0.4000000
sgot            1.206452     1.354839        1.393548           0.3652174
alkphos         1.075269     1.075269        1.135484           0.2898551
mcv             1.023656     1.043011        1.068817           0.2811594

=== LIME Rankings ===


Feature    Importance
--------  -----------
sgpt        0.1853549
sgot        0.1267413
gammagt     0.1184133
mcv         0.0463614
alkphos     0.0325727

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
sgpt        0.2129892
gammagt     0.0958584
sgot        0.0617027
alkphos     0.0244999
drinks      0.0203627

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: sgpt
LIME: sgpt
SHAP: sgpt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   sgpt        sgpt        TRUE      
FEAT_IMP vs SHAP   sgpt        sgpt        TRUE      
LIME vs SHAP       sgpt        sgpt        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=multinom ===
Applying data scaling for method: multinom
# weights:  8 (7 variable)
initial  value 239.135777 
iter  10 value 206.169306
final  value 205.505029 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
sgpt           1.3313725     1.431372        1.474510           0.4231884
sgot           1.3392157     1.392157        1.441177           0.4115942
gammagt        1.2294118     1.245098        1.309804           0.3681159
alkphos        0.9647059     1.049020        1.127451           0.3101449
drinks         1.0313725     1.039216        1.088235           0.3072464

=== LIME Rankings ===


Feature    Importance
--------  -----------
sgpt        0.2518996
sgot        0.2180237
gammagt     0.1074736
mcv         0.0982098
alkphos     0.0538757

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
sgpt        0.1750914
sgot        0.1002579
gammagt     0.0534738
alkphos     0.0418890
mcv         0.0405788

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: sgpt
LIME: sgpt
SHAP: sgpt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   sgpt        sgpt        TRUE      
FEAT_IMP vs SHAP   sgpt        sgpt        TRUE      
LIME vs SHAP       sgpt        sgpt        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
gammagt         2.470833     2.625000        2.683333           0.3652174
sgpt            2.100000     2.270833        2.287500           0.3159420
alkphos         1.566667     1.666667        1.745833           0.2318841
mcv             1.533333     1.604167        1.783333           0.2231884
drinks          1.325000     1.395833        1.429167           0.1942029

=== LIME Rankings ===


Feature    Importance
--------  -----------
gammagt     0.2039842
sgpt        0.1920584
mcv         0.1417372
alkphos     0.0742305
sgot        0.0478054

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
sgpt        0.2126039
gammagt     0.1970289
alkphos     0.0999507
mcv         0.0638252
drinks      0.0355313

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP            -1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: gammagt
LIME: gammagt
SHAP: sgpt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   gammagt     gammagt     TRUE      
FEAT_IMP vs SHAP   gammagt     sgpt        FALSE     
LIME vs SHAP       gammagt     sgpt        FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
alkphos        11.114286    11.857143        12.82857           0.2405797
drinks          9.057143    11.571429        12.11429           0.2347826
sgpt           10.142857    11.000000        12.25714           0.2231884
mcv             9.514286    10.142857        10.80000           0.2057971
sgot            8.771429     9.142857         9.40000           0.1855072

=== LIME Rankings ===


Feature    Importance
--------  -----------
sgpt        0.1399171
sgot        0.1091619
mcv         0.1078918
alkphos     0.0833139
gammagt     0.0362242

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
mcv         0.2260220
sgpt        0.2145048
sgot        0.1388584
gammagt     0.1269588
alkphos     0.1159011

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: alkphos
LIME: sgpt
SHAP: mcv

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   alkphos     sgpt        FALSE     
FEAT_IMP vs SHAP   alkphos     mcv         FALSE     
LIME vs SHAP       sgpt        mcv         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
sgpt           1.1285714     1.174603        1.260317           0.4289855
sgot           1.0126984     1.095238        1.107937           0.4000000
gammagt        1.0523810     1.079365        1.133333           0.3942029
drinks         1.0444444     1.063492        1.096825           0.3884058
mcv            0.9714286     1.015873        1.074603           0.3710145

=== LIME Rankings ===


Feature    Importance
--------  -----------
mcv         0.2233177
sgot        0.1528519
sgpt        0.1199660
gammagt     0.1156521
alkphos     0.0371730

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
sgot        0.0823589
sgpt        0.0705506
gammagt     0.0511295
mcv         0.0506108
alkphos     0.0406872

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: sgpt
LIME: mcv
SHAP: sgot

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   sgpt        mcv         FALSE     
FEAT_IMP vs SHAP   sgpt        sgot        FALSE     
LIME vs SHAP       mcv         sgot        FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
gammagt        0.2110145    0.2260870       0.2359420           0.2260870
sgpt           0.1976812    0.2202899       0.2318841           0.2202899
sgot           0.1020290    0.1072464       0.1246377           0.1072464
alkphos        0.0811594    0.0840580       0.0944928           0.0840580
mcv            0.0620290    0.0695652       0.0898551           0.0695652
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
sgpt        0.1258367
gammagt     0.1210096
sgot        0.1039065
mcv         0.0928584
alkphos     0.0502241

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
sgpt         0.132828
gammagt      0.117844
mcv          0.089248
sgot         0.056676
alkphos      0.038224

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: gammagt
LIME: sgpt
SHAP: sgpt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   gammagt     sgpt        FALSE     
FEAT_IMP vs SHAP   gammagt     sgpt        FALSE     
LIME vs SHAP       sgpt        sgpt        TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
mcv                    1            1               1           0.4202899
alkphos                1            1               1           0.4202899
sgpt                   1            1               1           0.4202899
sgot                   1            1               1           0.4202899
gammagt                1            1               1           0.4202899

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
alkphos             0
drinks              0
gammagt             0
mcv                 0
sgot                0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: mcv
SHAP: alkphos

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   mcv         alkphos     FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
sgot           1.0196970    1.0681818       1.1075758           0.4086957
gammagt        1.0272727    1.0606061       1.0757576           0.4057971
alkphos        1.0075758    1.0151515       1.0848485           0.3884058
sgpt           0.9878788    1.0075758       1.0227273           0.3855072
drinks         0.9378788    0.9621212       0.9969697           0.3681159

=== LIME Rankings ===


Feature    Importance
--------  -----------
sgot        0.0746582
mcv         0.0711579
gammagt     0.0555571
alkphos     0.0315767
sgpt        0.0189599

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
mcv         0.0191881
sgot        0.0178051
alkphos     0.0164708
gammagt     0.0157810
sgpt        0.0070096

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: sgot
LIME: sgot
SHAP: mcv

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   sgot        sgot        TRUE      
FEAT_IMP vs SHAP   sgot        mcv         FALSE     
LIME vs SHAP       sgot        mcv         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
sgpt            1.344898     1.459184        1.512245           0.4144928
sgot            1.400000     1.438775        1.524490           0.4086957
gammagt         1.228571     1.255102        1.332653           0.3565217
drinks          1.057143     1.091837        1.100000           0.3101449
mcv             1.042857     1.071429        1.148980           0.3043478

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: sgpt
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   sgpt        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
gammagt         1.126415     1.169811        1.277359           0.3594203
alkphos         1.101887     1.150943        1.198113           0.3536232
mcv             1.043396     1.141509        1.160377           0.3507246
sgot            1.122642     1.141509        1.160377           0.3507246
sgpt            1.116981     1.132076        1.226415           0.3478261

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: gammagt
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   gammagt     NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1967 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
sgpt            1.903704     2.222222        2.325926           0.3478261
sgot            1.700000     1.814815        1.829630           0.2840580
gammagt         1.674074     1.740741        1.862963           0.2724638
alkphos         1.396296     1.537037        1.555556           0.2405797
mcv             1.422222     1.500000        1.566667           0.2347826

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: sgpt
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   sgpt        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
drinks          1.400000     1.550725        1.565217           0.3101449
sgpt            1.318841     1.478261        1.501449           0.2956522
mcv             1.353623     1.449275        1.571014           0.2898551
alkphos         1.434783     1.449275        1.614493           0.2898551
sgot            1.220290     1.376812        1.402899           0.2753623

=== LIME Rankings ===


Feature    Importance
--------  -----------
sgot        0.1245973
mcv         0.1066120
sgpt        0.0875493
gammagt     0.0689439
drinks      0.0374245

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
sgpt        0.1166667
mcv         0.0965333
gammagt     0.0886000
sgot        0.0817333
alkphos     0.0699333

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: drinks
LIME: sgot
SHAP: sgpt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   drinks      sgot        FALSE     
FEAT_IMP vs SHAP   drinks      sgpt        FALSE     
LIME vs SHAP       sgot        sgpt        FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=liver-disorders, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
sgpt           1.3254902     1.431372        1.480392           0.4231884
sgot           1.3392157     1.372549        1.449020           0.4057971
gammagt        1.2313725     1.254902        1.303922           0.3710145
alkphos        0.9705882     1.078431        1.119608           0.3188406
drinks         1.0254902     1.058823        1.088235           0.3130435

=== LIME Rankings ===


Feature    Importance
--------  -----------
sgpt        0.2480571
sgot        0.2135603
gammagt     0.1055410
mcv         0.0988103
alkphos     0.0533304

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
sgpt        0.1650753
sgot        0.0960629
gammagt     0.0507283
alkphos     0.0408653
mcv         0.0402497

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: sgpt
LIME: sgpt
SHAP: sgpt

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   sgpt        sgpt        TRUE      
FEAT_IMP vs SHAP   sgpt        sgpt        TRUE      
LIME vs SHAP       sgpt        sgpt        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: mfeat-factors
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att181          3.695699     3.741935        3.756989              0.3480
att19           3.347312     3.489247        3.550538              0.3245
att1            2.202151     2.247312        2.358064              0.2090
att88           2.203226     2.247312        2.256989              0.2090
att94           1.997850     2.059140        2.162366              0.1915

=== LIME Rankings ===


Feature    Importance
--------  -----------
att19       0.0487502
att8        0.0422743
att181      0.0280508
att94       0.0226657
att1        0.0205024

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att8        0.3016574
att19       0.1743983
att212      0.1080000
att88       0.0985594
att181      0.0627982

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att181
LIME: att19
SHAP: att8

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att181      att19       FALSE     
FEAT_IMP vs SHAP   att181      att8        FALSE     
LIME vs SHAP       att19       att8        FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=fda ===
No scaling applied for method: fda
Error in get(ctr, mode = "function", envir = parent.frame()) : 
  object 'contr.earth.response' of mode 'function' was not found
Calls: train_model ... model.matrix -> model.matrix.default -> contrasts -> get
Execution halted
FAILED - See error above


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        2.3026            -nan     0.1000    0.8575
     2        1.8030            -nan     0.1000    0.4299
     3        1.5575            -nan     0.1000    0.2931
     4        1.3841            -nan     0.1000    0.2392
     5        1.2445            -nan     0.1000    0.2091
     6        1.1207            -nan     0.1000    0.1610
     7        1.0252            -nan     0.1000    0.1226
     8        0.9523            -nan     0.1000    0.1147
     9        0.8837            -nan     0.1000    0.0833
    10        0.8291            -nan     0.1000    0.0912
    20        0.4723            -nan     0.1000    0.0267
    40        0.2426            -nan     0.1000    0.0058
    50        0.1919            -nan     0.1000    0.0040



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att212          2.535484     2.596774        2.658065              0.0805
att97           1.558064     1.629032        1.667742              0.0505
att37           1.458065     1.580645        1.632258              0.0490
att181          1.361290     1.387097        1.412903              0.0430
att109          1.274193     1.290323        1.319355              0.0400

=== LIME Rankings ===


Feature    Importance
--------  -----------
att212      0.2338977
att205      0.1225357
att8        0.0799616
att1        0.0275237
att38       0.0267128

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att212      0.4162665
att8        0.1252759
att205      0.0987848
att1        0.0278367
att38       0.0212317

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att212
LIME: att212
SHAP: att212

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att212      att212      TRUE      
FEAT_IMP vs SHAP   att212      att212      TRUE      
LIME vs SHAP       att212      att212      TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning messages:
1: glm.fit: fitted probabilities numerically 0 or 1 occurred 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
3: glm.fit: fitted probabilities numerically 0 or 1 occurred 
4: glm.fit: fitted probabilities numerically 0 or 1 occurred 
5: glm.fit: fitted probabilities numerically 0 or 1 occurred 
6: glm.fit: fitted probabilities numerically 0 or 1 occurred 
7: glm.fit: fitted probabilities numerically 0 or 1 occurred 
8: glm.fit: fitted probabilities numerically 0 or 1 occurred 
9: glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===
Error in get_featimp: The total size of the 2 globals exported is 689.42 MiB. This exceeds the maximum allowed size 500.00 MiB per by R option "future.globals.maxSize". This limit is set to protect against transfering too large objects to parallel workers by mistake, which may not be intended and could be costly. See help("future.globals.maxSize", package = "future") for further explainations and how to adjust or remove this threshold There are two globals: FUN (344.72 MiB of class function) and MoreArgs (344.70 MiB of class list) 

=== LIME Rankings ===


Feature    Importance
--------  -----------
att1        0.1362769
att212      0.0783905
att97       0.0310511
att133      0.0270813
att86       0.0185200

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att212      0.3650501
att1        0.2838190
att133      0.0677006
att86       0.0594727
att97       0.0413722

=== Top-3 Spearman (on common top-3 features only) ===


Pair            Spearman   Common_Features
-------------  ---------  ----------------
LIME vs SHAP          -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair           Spearman    Common_Features
-------------  ---------  ----------------
LIME vs SHAP   NA                        0

=== Top-1 Features ===
LIME: att1
SHAP: att212

=== Top-1 Feature Agreement (pairwise) ===


Pair           Feature_1   Feature_2   Agreement 
-------------  ----------  ----------  ----------
LIME vs SHAP   att1        att212      FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1            4.903226     5.177419        5.358065              0.1605
att6            3.470968     3.596774        3.658065              0.1115
att97           3.258065     3.290323        3.522581              0.1020
att85           3.216129     3.258065        3.506452              0.1010
att86           2.809677     3.016129        3.045161              0.0935

=== LIME Rankings ===


Feature    Importance
--------  -----------
att1        0.1119166
att8        0.0815106
att205      0.0408325
att179      0.0374191
att212      0.0287727

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att212      0.1879885
att179      0.1708231
att1        0.1356615
att8        0.1239808
att3        0.0942962

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att1
LIME: att1
SHAP: att212

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att1        att1        TRUE      
FEAT_IMP vs SHAP   att1        att212      FALSE     
LIME vs SHAP       att1        att212      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att23           1.000000      1.02439        1.024390               0.021
att35           1.004878      1.02439        1.024390               0.021
att59           1.000000      1.02439        1.024390               0.021
att145          1.000000      1.02439        1.024390               0.021
att167          1.004878      1.02439        1.043902               0.021

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att23
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att23       NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att136          1.144395     1.148729        1.155755              0.7685
att125          1.110463     1.121076        1.126308              0.7500
att208          1.105082     1.112108        1.117040              0.7440
att195          1.086996     1.098655        1.104634              0.7350
att6            1.089985     1.091928        1.098655              0.7305

=== LIME Rankings ===


Feature    Importance
--------  -----------
att6        0.0193262
att136      0.0151796
att208      0.0135399
att186      0.0120402
att147      0.0112189

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att147      0.0192464
att123      0.0188494
att136      0.0186053
att208      0.0150608
att104      0.0124932

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att136
LIME: att6
SHAP: att147

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att136      att6        FALSE     
FEAT_IMP vs SHAP   att136      att147      FALSE     
LIME vs SHAP       att6        att147      FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=multinom ===
Applying data scaling for method: multinom
# weights:  2180 (1953 variable)
initial  value 4605.170186 
iter  10 value 327.888101
iter  20 value 139.612702
iter  30 value 94.248504
iter  40 value 51.589845
iter  50 value 35.084596
iter  60 value 16.700616
iter  70 value 10.279482
iter  80 value 4.481519
iter  90 value 1.124448
iter 100 value 0.188000
final  value 0.188000 
stopped after 100 iterations


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att169            0.1879       0.1920          0.2000              0.1920
att97             0.1749       0.1855          0.1921              0.1855
att73             0.1802       0.1850          0.1930              0.1850
att18             0.1620       0.1645          0.1706              0.1645
att181            0.1578       0.1625          0.1675              0.1625
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
att184      0.0029130
att214      0.0028967
att21       0.0028401
att198      0.0025874
att116      0.0025066

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att50       0.0660090
att8        0.0504280
att71       0.0348666
att43       0.0289129
att60       0.0265716

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att169
LIME: att184
SHAP: att50

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att169      att184      FALSE     
FEAT_IMP vs SHAP   att169      att50       FALSE     
LIME vs SHAP       att184      att50       FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att212         14.314286     14.85714        15.42857              0.1040
att86          10.757143     11.42857        12.08571              0.0800
att1           10.657143     11.14286        11.80000              0.0780
att97           9.671429     10.78571        11.15714              0.0755
att94           9.314286     10.28571        10.55714              0.0720

=== LIME Rankings ===


Feature    Importance
--------  -----------
att212      0.2100606
att1        0.0741604
att11       0.0537194
att120      0.0343214
att107      0.0269075

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att212      0.4928352
att120      0.1131026
att82       0.0837802
att107      0.0777692
att1        0.0707033

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att212
LIME: att212
SHAP: att212

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att212      att212      TRUE      
FEAT_IMP vs SHAP   att212      att212      TRUE      
LIME vs SHAP       att212      att212      TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att42           1.070000     1.100000        1.113333              0.0330
att60           1.070000     1.100000        1.100000              0.0330
att121          1.053333     1.100000        1.156667              0.0330
att73           1.066667     1.083333        1.100000              0.0325
att85           1.040000     1.083333        1.100000              0.0325

=== LIME Rankings ===


Feature    Importance
--------  -----------
att94       0.0266233
att131      0.0258146
att70       0.0248023
att167      0.0237496
att35       0.0235947

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att179      0.2559137
att83       0.2528556
att167      0.2472499
att35       0.2439314
att71       0.2241233

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att42
LIME: att94
SHAP: att179

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att42       att94       FALSE     
FEAT_IMP vs SHAP   att42       att179      FALSE     
LIME vs SHAP       att94       att179      FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===
Error in get_featimp: Lapack routine dgesv: system is exactly singular: U[214,214] = 0 

=== LIME Rankings ===
Error in get_lime: Lapack routine dgesv: system is exactly singular: U[214,214] = 0 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: Lapack routine dgesv: system is exactly singular: U[214,214] = 0 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 0 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att37              5e-04        5e-04           5e-04               5e-04
att1               0e+00        0e+00           0e+00               0e+00
att2               0e+00        0e+00           0e+00               0e+00
att3               0e+00        0e+00           0e+00               0e+00
att4               0e+00        0e+00           0e+00               0e+00
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
att212      0.0303236
att8        0.0222931
att1        0.0127752
att207      0.0108536
att200      0.0074286

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att212       0.095568
att8         0.062620
att1         0.027080
att200       0.026228
att207       0.025344

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att37
LIME: att212
SHAP: att212

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att37       att212      FALSE     
FEAT_IMP vs SHAP   att37       att212      FALSE     
LIME vs SHAP       att212      att212      TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1                   1            1               1                 0.9
att2                   1            1               1                 0.9
att3                   1            1               1                 0.9
att4                   1            1               1                 0.9
att5                   1            1               1                 0.9

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att1                0
att10               0
att100              0
att101              0
att102              0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: att1
SHAP: att1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att1        att1        TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1                   1            1               1                 0.8
att2                   1            1               1                 0.8
att3                   1            1               1                 0.8
att4                   1            1               1                 0.8
att5                   1            1               1                 0.8

=== LIME Rankings ===


Feature    Importance
--------  -----------
att13       0.0004404
att38       0.0003432
att26       0.0003380
att204      0.0003379
att111      0.0003365

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att55       0.0002754
att204      0.0002691
att19       0.0002509
att43       0.0002502
att50       0.0002496

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att1
LIME: att13
SHAP: att55

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att1        att13       FALSE     
FEAT_IMP vs SHAP   att1        att55       FALSE     
LIME vs SHAP       att13       att55       FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att99              5e-04       0.0015          0.0024              0.0015
att77              0e+00       0.0005          0.0009              0.0005
att215             0e+00       0.0005          0.0005              0.0005
att1               0e+00       0.0000          0.0000              0.0000
att2               0e+00       0.0000          0.0000              0.0000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att99
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att99       NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att127         1.0196078     1.039216        1.039216              0.0265
att187         1.0196078     1.039216        1.039216              0.0265
att7           1.0196078     1.019608        1.019608              0.0260
att19          0.9647059     1.019608        1.019608              0.0260
att21          1.0039216     1.019608        1.019608              0.0260

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att127
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att127      NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att185          1.418208     1.439060        1.459618              0.4900
att212          1.283407     1.298091        1.301028              0.4420
att37           1.272247     1.281938        1.287812              0.4365
att210          1.230250     1.236417        1.249927              0.4210
att6            1.229369     1.234949        1.246990              0.4205

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att185
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att185      NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att25          1.0238095     1.047619        1.119048               0.022
att39          0.9809524     1.047619        1.066667               0.022
att52          1.0238095     1.047619        1.128571               0.022
att75          0.9809524     1.047619        1.047619               0.022
att76          0.9380952     1.047619        1.090476               0.022

=== LIME Rankings ===


Feature    Importance
--------  -----------
att85       0.0065544
att71       0.0062846
att205      0.0062433
att143      0.0060511
att83       0.0057601

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att179      0.0254000
att167      0.0252667
att71       0.0233333
att83       0.0197333
att205      0.0191333

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att25
LIME: att85
SHAP: att179

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att25       att85       FALSE     
FEAT_IMP vs SHAP   att25       att179      FALSE     
LIME vs SHAP       att85       att179      FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-factors, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att8            1.001875       1.0025        1.002500               0.802
att205          1.001500       1.0025        1.003125               0.802
att1            1.000000       1.0000        1.000625               0.800
att2            1.000000       1.0000        1.000000               0.800
att3            1.000000       1.0000        1.000000               0.800

=== LIME Rankings ===
Error in get_lime: length of 'dimnames' [2] not equal to array extent 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att8
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att8        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


Dataset: mfeat-karhunen
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1            3.745318     3.786517        3.834457              0.5055
att3            2.216479     2.280899        2.384270              0.3045
att2            2.080150     2.153558        2.198502              0.2875
att4            1.978277     2.063670        2.108614              0.2755
att11           1.844944     1.865169        1.925843              0.2490

=== LIME Rankings ===


Feature    Importance
--------  -----------
att1        0.1372612
att2        0.1297837
att3        0.0301152
att12       0.0242392
att21       0.0184734

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att1        0.3206737
att2        0.1734905
att11       0.1316833
att26       0.0491828
att3        0.0468759

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att1
LIME: att1
SHAP: att1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att1        att1        TRUE      
FEAT_IMP vs SHAP   att1        att1        TRUE      
LIME vs SHAP       att1        att1        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=fda ===
No scaling applied for method: fda
Error in get(ctr, mode = "function", envir = parent.frame()) : 
  object 'contr.earth.response' of mode 'function' was not found
Calls: train_model ... model.matrix -> model.matrix.default -> contrasts -> get
Execution halted
FAILED - See error above


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        2.3026            -nan     0.1000    0.4361
     2        2.0321            -nan     0.1000    0.2844
     3        1.8680            -nan     0.1000    0.2063
     4        1.7469            -nan     0.1000    0.1832
     5        1.6360            -nan     0.1000    0.1307
     6        1.5494            -nan     0.1000    0.1187
     7        1.4761            -nan     0.1000    0.1116
     8        1.4026            -nan     0.1000    0.1043
     9        1.3361            -nan     0.1000    0.0925
    10        1.2751            -nan     0.1000    0.0776
    20        0.8871            -nan     0.1000    0.0416
    40        0.5381            -nan     0.1000    0.0037
    50        0.4371            -nan     0.1000    0.0060



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1            2.349677     2.387097        2.507097              0.1850
att3            2.054193     2.141936        2.203871              0.1660
att4            1.905806     1.941936        1.981936              0.1505
att2            1.299355     1.354839        1.393548              0.1050
att7            1.247742     1.283871        1.316129              0.0995

=== LIME Rankings ===


Feature    Importance
--------  -----------
att7        0.1081330
att1        0.0902473
att2        0.0787172
att20       0.0223267
att4        0.0203173

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att7        0.1734077
att1        0.1417153
att2        0.1316719
att10       0.0404579
att6        0.0393683

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att1
LIME: att7
SHAP: att7

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att1        att7        FALSE     
FEAT_IMP vs SHAP   att1        att7        FALSE     
LIME vs SHAP       att7        att7        TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning messages:
1: glm.fit: fitted probabilities numerically 0 or 1 occurred 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
3: glm.fit: fitted probabilities numerically 0 or 1 occurred 
4: glm.fit: fitted probabilities numerically 0 or 1 occurred 
5: glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1            5.457627     5.652542        5.742373              0.3335
att3            3.923729     4.127119        4.394915              0.2435
att2            3.481356     3.601695        3.650847              0.2125
att5            3.437288     3.533898        3.638983              0.2085
att4            3.203390     3.262712        3.367797              0.1925

=== LIME Rankings ===


Feature    Importance
--------  -----------
att2        0.1704908
att7        0.1515459
att1        0.1232676
att10       0.0531399
att6        0.0508880

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att2        0.2321480
att1        0.2077060
att7        0.1398944
att10       0.0650097
att4        0.0625268

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att1
LIME: att2
SHAP: att2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att1        att2        FALSE     
FEAT_IMP vs SHAP   att1        att2        FALSE     
LIME vs SHAP       att2        att2        TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1            6.336735     6.448980        6.583673              0.3160
att3            4.661225     4.887755        4.904082              0.2395
att10           3.030612     3.112245        3.216327              0.1525
att2            2.893878     3.020408        3.081633              0.1480
att21           2.712245     2.795918        2.824490              0.1370

=== LIME Rankings ===


Feature    Importance
--------  -----------
att1        0.0638649
att11       0.0363310
att7        0.0339101
att19       0.0201720
att21       0.0186930

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att1        0.2228299
att10       0.1276946
att11       0.0983360
att7        0.0871879
att3        0.0828118

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att1
LIME: att1
SHAP: att1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att1        att1        TRUE      
FEAT_IMP vs SHAP   att1        att1        TRUE      
LIME vs SHAP       att1        att1        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att4            1.277419     1.322581        1.380645              0.0410
att5            1.180645     1.209677        1.251613              0.0375
att7            1.119355     1.193548        1.209677              0.0370
att2            1.100000     1.177419        1.245161              0.0365
att13           1.083871     1.112903        1.112903              0.0345

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att4
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att4        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1            1.265844     1.282961        1.284194              0.8320
att2            1.097147     1.104857        1.123978              0.7165
att3            1.066461     1.077872        1.079260              0.6990
att4            1.052583     1.069391        1.082344              0.6935
att23           1.053662     1.059368        1.073554              0.6870

=== LIME Rankings ===


Feature    Importance
--------  -----------
att1        0.0425701
att2        0.0285407
att6        0.0153452
att8        0.0095849
att22       0.0090287

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att2        0.0348275
att1        0.0270016
att6        0.0109848
att22       0.0061767
att8        0.0057434

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att1
LIME: att1
SHAP: att2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att1        att1        TRUE      
FEAT_IMP vs SHAP   att1        att2        FALSE     
LIME vs SHAP       att1        att2        FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=multinom ===
Applying data scaling for method: multinom
# weights:  660 (585 variable)
initial  value 4605.170186 
iter  10 value 347.048003
iter  20 value 38.296549
iter  30 value 12.905335
iter  40 value 5.435763
iter  50 value 2.929970
iter  60 value 1.686217
iter  70 value 1.055934
iter  80 value 0.734839
iter  90 value 0.506999
iter 100 value 0.322551
final  value 0.322551 
stopped after 100 iterations


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1              0.2049       0.2065          0.2340              0.2065
att3              0.1812       0.1880          0.1933              0.1880
att2              0.1750       0.1770          0.1869              0.1770
att5              0.1447       0.1485          0.1598              0.1485
att6              0.0750       0.0840          0.0865              0.0840
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
att2        0.0614149
att7        0.0544932
att1        0.0346531
att20       0.0342996
att58       0.0333763

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att1        0.1939713
att2        0.1852508
att7        0.1203495
att10       0.0632284
att3        0.0589941

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att1
LIME: att2
SHAP: att1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att1        att2        FALSE     
FEAT_IMP vs SHAP   att1        att1        TRUE      
LIME vs SHAP       att2        att1        FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1              29.680        30.20          30.608              0.3775
att3              16.224        16.36          17.112              0.2045
att4              12.704        14.04          14.560              0.1755
att2              12.576        13.12          14.096              0.1640
att11             10.168        11.04          11.336              0.1380

=== LIME Rankings ===


Feature    Importance
--------  -----------
att1        0.0883015
att2        0.0814113
att10       0.0418886
att7        0.0404617
att11       0.0293394

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att1        0.2897847
att7        0.1156190
att10       0.0912143
att5        0.0790665
att4        0.0740288

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att1
LIME: att1
SHAP: att1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att1        att1        TRUE      
FEAT_IMP vs SHAP   att1        att1        TRUE      
LIME vs SHAP       att1        att1        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att7            1.327835     1.391753        1.410309              0.0675
att5            1.280412     1.309278        1.348454              0.0635
att21           1.140206     1.237113        1.288660              0.0600
att2            1.164948     1.216495        1.259794              0.0590
att14           1.177320     1.216495        1.282474              0.0590

=== LIME Rankings ===


Feature    Importance
--------  -----------
att7        0.0259663
att2        0.0232539
att20       0.0231125
att53       0.0224968
att11       0.0219275

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att7        0.5129017
att1        0.3824508
att58       0.3580949
att2        0.2946545
att61       0.2642175

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att7
LIME: att7
SHAP: att7

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att7        att7        TRUE      
FEAT_IMP vs SHAP   att7        att7        TRUE      
LIME vs SHAP       att7        att7        TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1               586.6          594           619.6              0.2970
att2               403.6          412           438.2              0.2060
att3               260.0          261           283.8              0.1305
att4               214.2          239           252.6              0.1195
att21              164.6          168           179.0              0.0840

=== LIME Rankings ===
Error in get_lime: missing value where TRUE/FALSE needed 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att14       0.0270635
att26       0.0201486
att64       0.0172341
att8        0.0136717
att13       0.0100386

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att1
SHAP: att14

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att1        att14       FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att4              0.0026        3e-03          0.0035               3e-03
att1              0.0006        2e-03          0.0020               2e-03
att3              0.0001        5e-04          0.0009               5e-04
att5              0.0000        5e-04          0.0005               5e-04
att2              0.0000        0e+00          0.0004               0e+00
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
att1        0.0580045
att2        0.0522799
att7        0.0411817
att4        0.0179753
att10       0.0145083

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att1         0.145548
att2         0.116476
att7         0.089832
att11        0.048932
att5         0.038440

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att4
LIME: att1
SHAP: att1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att4        att1        FALSE     
FEAT_IMP vs SHAP   att4        att1        FALSE     
LIME vs SHAP       att1        att1        TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1                   1            1               1                 0.9
att2                   1            1               1                 0.9
att3                   1            1               1                 0.9
att4                   1            1               1                 0.9
att5                   1            1               1                 0.9

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att1                0
att10               0
att11               0
att12               0
att13               0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: att1
SHAP: att1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att1        att1        TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att6           0.9996266     1.001245        1.001245              0.8045
att24          1.0012446     1.001245        1.002489              0.8045
att51          1.0007467     1.001245        1.001245              0.8045
att1           1.0001245     1.000622        1.001742              0.8040
att3           1.0001245     1.000622        1.001742              0.8040

=== LIME Rankings ===


Feature    Importance
--------  -----------
att10       0.0028940
att1        0.0025409
att31       0.0022615
att36       0.0019488
att8        0.0018755

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att1        0.0019867
att10       0.0015596
att58       0.0013846
att8        0.0012718
att28       0.0011907

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP          NA                 0
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att6
LIME: att10
SHAP: att1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att6        att10       FALSE     
FEAT_IMP vs SHAP   att6        att1        FALSE     
LIME vs SHAP       att10       att1        FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att4              0.0345       0.0365          0.0398              0.0365
att1              0.0236       0.0250          0.0335              0.0250
att3              0.0234       0.0250          0.0273              0.0250
att5              0.0171       0.0195          0.0209              0.0195
att6              0.0185       0.0190          0.0238              0.0190
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att4
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att4        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1            1.176471     1.235294        1.349020              0.0315
att4            1.200000     1.235294        1.298039              0.0315
att7            1.086275     1.215686        1.235294              0.0310
att10           1.196078     1.215686        1.266667              0.0310
att6            1.074510     1.196078        1.196078              0.0305

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att1        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1            1.560000     1.581690        1.584507              0.5615
att26           1.349296     1.381690        1.392676              0.4905
att4            1.297183     1.308451        1.316056              0.4645
att3            1.275775     1.295775        1.319437              0.4600
att27           1.260000     1.274648        1.290704              0.4525

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att1        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att10          1.0627451     1.156863        1.192157              0.0295
att5           0.9882353     1.098039        1.113725              0.0280
att25          1.0235294     1.078431        1.109804              0.0275
att63          0.9803922     1.078431        1.129412              0.0275
att4           0.9607843     1.058823        1.113725              0.0270

=== LIME Rankings ===


Feature    Importance
--------  -----------
att2        0.0962496
att7        0.0891688
att1        0.0556746
att8        0.0417684
att6        0.0415991

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att2        0.0646667
att7        0.0549333
att1        0.0518667
att8        0.0328000
att10       0.0288000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP          NA                 0
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att10
LIME: att2
SHAP: att2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att10       att2        FALSE     
FEAT_IMP vs SHAP   att10       att2        FALSE     
LIME vs SHAP       att2        att2        TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-karhunen, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1            1.049719     1.055590        1.061212              0.8450
att7            1.021861     1.022486        1.026109              0.8185
att2            1.012617     1.016240        1.016240              0.8135
att4            1.005871     1.007495        1.008120              0.8065
att26           1.005247     1.007495        1.008744              0.8065

=== LIME Rankings ===
Error in get_lime: length of 'dimnames' [2] not equal to array extent 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att1        NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


Dataset: mfeat-zernike
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19           8.800000     9.529412        9.729412              0.0810
att40           6.941177     7.352941        7.505882              0.0625
att29           2.411765     2.705882        3.047059              0.0230
att24           1.870588     2.470588        2.588235              0.0210
att33           1.552941     1.647059        1.752941              0.0140

=== LIME Rankings ===


Feature    Importance
--------  -----------
att19       0.2468647
att29       0.1232217
att40       0.0763464
att24       0.0611002
att34       0.0097666

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19       0.5181223
att40       0.2358788
att29       0.1268262
att24       0.0354375
att33       0.0018182

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att19
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att19       TRUE      
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att19       att19       TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19            8.71282     8.948718        9.082051              0.1745
att1             1.00000     1.000000        1.000000              0.0195
att2             1.00000     1.000000        1.000000              0.0195
att3             1.00000     1.000000        1.000000              0.0195
att4             1.00000     1.000000        1.000000              0.0195

=== LIME Rankings ===


Feature    Importance
--------  -----------
att19       0.6481683
att29       0.0137022
att39       0.0095780
att13       0.0094167
att30       0.0087372

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19       0.8995119
att1        0.0000000
att10       0.0000000
att11       0.0000000
att12       0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att19
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att19       TRUE      
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att19       att19       TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.5040            -nan     0.1000    0.0743
     2        0.4326            -nan     0.1000    0.0342
     3        0.3849            -nan     0.1000    0.0224
     4        0.3497            -nan     0.1000    0.0184
     5        0.3203            -nan     0.1000    0.0140
     6        0.2955            -nan     0.1000    0.0121
     7        0.2759            -nan     0.1000    0.0082
     8        0.2562            -nan     0.1000    0.0093
     9        0.2413            -nan     0.1000    0.0064
    10        0.2282            -nan     0.1000    0.0059
    20        0.1517            -nan     0.1000    0.0016
    40        0.0895            -nan     0.1000    0.0005
    50        0.0787            -nan     0.1000    0.0008



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19           6.676923     6.923077        7.061539              0.0900
att29           1.192308     1.346154        1.376923              0.0175
att40           1.092308     1.192308        1.223077              0.0155
att13           1.076923     1.076923        1.107692              0.0140
att24           1.076923     1.076923        1.107692              0.0140

=== LIME Rankings ===


Feature    Importance
--------  -----------
att19       0.3250477
att29       0.1164216
att40       0.0583313
att23       0.0251982
att6        0.0175780

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19       0.5178297
att29       0.1969270
att40       0.0584931
att23       0.0258464
att6        0.0237884

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att19
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att19       TRUE      
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att19       att19       TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19              51.72         54.0           56.28              0.1350
att29              12.64         13.2           13.60              0.0330
att7                7.24          7.8            9.16              0.0195
att13               4.88          5.6            6.20              0.0140
att40               4.88          5.4            7.56              0.0135

=== LIME Rankings ===


Feature    Importance
--------  -----------
att19       0.5330272
att29       0.3396647
att40       0.0579739
att7        0.0440205
att13       0.0369593

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19       0.7607954
att29       0.0879843
att40       0.0311488
att13       0.0243391
att7        0.0202769

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att19
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att19       TRUE      
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att19       att19       TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19          15.666667    16.000000       16.893333              0.1200
att6            2.813333     3.200000        3.320000              0.0240
att24           2.440000     2.666667        2.906667              0.0200
att10           1.480000     1.600000        1.840000              0.0120
att13           1.280000     1.400000        1.453333              0.0105

=== LIME Rankings ===


Feature    Importance
--------  -----------
att19       0.3000940
att6        0.1429048
att10       0.0305160
att24       0.0214809
att40       0.0142553

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19       0.6185456
att6        0.1944219
att24       0.0328531
att10       0.0298664
att13       0.0039866

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att19
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att19       TRUE      
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att19       att19       TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19           3.023529     3.588235        3.694118              0.0305
att29           2.294118     2.705882        3.035294              0.0230
att7            1.082353     1.294118        1.435294              0.0110
att24           1.188235     1.235294        1.341176              0.0105
att33           1.129412     1.176471        1.235294              0.0100

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att19
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att19       NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att29           9.771429    11.142857       11.514286              0.0390
att19           8.628571     8.857143       10.914286              0.0310
att33           6.771429     7.571429        7.971429              0.0265
att13           5.142857     6.285714        6.628571              0.0220
att6            4.914286     5.714286        5.857143              0.0200

=== LIME Rankings ===


Feature    Importance
--------  -----------
att29       0.1707899
att19       0.1508125
att6        0.1090120
att13       0.0737606
att40       0.0703776

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19       0.2883230
att29       0.2400092
att6        0.1226802
att33       0.0957832
att23       0.0922069

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att29
LIME: att29
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att29       att29       TRUE      
FEAT_IMP vs SHAP   att29       att19       FALSE     
LIME vs SHAP       att29       att19       FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=multinom ===
Applying data scaling for method: multinom
# weights:  49 (48 variable)
initial  value 1386.294361 
iter  10 value 261.366664
iter  20 value 140.336751
iter  30 value 59.780909
iter  40 value 15.712334
iter  50 value 6.049486
iter  60 value 0.094133
iter  70 value 0.000597
final  value 0.000074 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att4              0.2057       0.2105          0.2218              0.2105
att25             0.1771       0.1835          0.1884              0.1835
att26             0.1596       0.1615          0.1656              0.1615
att16             0.1361       0.1400          0.1497              0.1400
att32             0.1365       0.1385          0.1500              0.1385
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
att25       0.1353761
att32       0.1212902
att26       0.1088862
att4        0.1010339
att16       0.0950831

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att29       0.2495540
att19       0.2020005
att6        0.1619976
att4        0.1482170
att40       0.1359499

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 0
LIME vs SHAP              NA                 0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att4
LIME: att25
SHAP: att29

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att4        att25       FALSE     
FEAT_IMP vs SHAP   att4        att29       FALSE     
LIME vs SHAP       att25       att29       FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19              40.04         41.2           42.76              0.1030
att6               18.20         20.2           21.80              0.0505
att40               7.84          8.2           10.52              0.0205
att12               3.24          3.6            4.12              0.0090
att34               2.00          3.4            3.60              0.0085

=== LIME Rankings ===


Feature    Importance
--------  -----------
att19       0.2104252
att6        0.0995080
att40       0.0739566
att13       0.0356930
att11       0.0210698

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19       0.5329941
att6        0.2485455
att13       0.0696061
att40       0.0261749
att11       0.0216667

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att19
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att19       TRUE      
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att19       att19       TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19           1.867391     1.913043        1.934783              0.0880
att29           1.880435     1.913043        1.921739              0.0880
att6            1.332609     1.391304        1.460870              0.0640
att28           1.295652     1.336957        1.336957              0.0615
att45           1.193478     1.282609        1.323913              0.0590

=== LIME Rankings ===


Feature    Importance
--------  -----------
att29       0.9643604
att19       0.8198570
att6        0.5327300
att7        0.5161884
att14       0.4978538

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19        6.985367
att29        5.352589
att6         1.738578
att45        1.651739
att28        1.574355

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att29
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att29       FALSE     
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att29       att19       FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att27           25.25000     25.91667        26.31667              0.1555
att46           16.11667     16.58333        16.65000              0.0995
att29           16.18333     16.50000        16.65000              0.0990
att42           16.28333     16.50000        16.58333              0.0990
att36           16.20000     16.33333        16.41667              0.0980

=== LIME Rankings ===
Error in get_lime: missing value where TRUE/FALSE needed 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: no rows to aggregate 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 1 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 1 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 1 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19             0.0121       0.0130          0.0146              0.0130
att29             0.0016       0.0020          0.0020              0.0020
att40             0.0006       0.0015          0.0019              0.0015
att23             0.0000       0.0005          0.0005              0.0005
att32             0.0001       0.0005          0.0005              0.0005
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
att19       0.1543864
att29       0.1498787
att6        0.0456464
att40       0.0308421
att23       0.0233737

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19        0.268380
att29        0.205664
att6         0.049156
att40        0.045456
att33        0.031084

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att19
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att19       TRUE      
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att19       att19       TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att1                   1            1               1                 0.1
att2                   1            1               1                 0.1
att3                   1            1               1                 0.1
att4                   1            1               1                 0.1
att5                   1            1               1                 0.1

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att1                0
att10               0
att11               0
att12               0
att13               0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: att1
SHAP: att1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att1        att1        TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19           1.408130     1.439024        1.447154              0.0885
att29           1.365854     1.373984        1.406504              0.0845
att6            1.130081     1.138211        1.138211              0.0700
att45           1.069919     1.105691        1.128455              0.0680
att12           1.060163     1.097561        1.112195              0.0675

=== LIME Rankings ===


Feature    Importance
--------  -----------
att29       0.0255640
att19       0.0238877
att6        0.0127186
att28       0.0105756
att40       0.0081629

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19       0.0291108
att29       0.0245909
att6        0.0092575
att28       0.0085930
att40       0.0070794

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att29
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att29       FALSE     
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att29       att19       FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19              21.64         22.6           24.56              0.0565
att6                7.80          9.8           10.32              0.0245
att29               8.24          8.6            9.40              0.0215
att33               7.52          8.6            9.24              0.0215
att13               2.92          3.6            4.28              0.0090

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att19
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att19       NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19           6.133333     6.750000        7.550000              0.0405
att29           3.716667     4.166667        4.500000              0.0250
att40           1.350000     1.500000        1.500000              0.0090
att13           1.283333     1.416667        1.566667              0.0085
att24           1.200000     1.416667        1.416667              0.0085

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att19
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att19       NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att29           5.330435     5.478261        5.565217              0.0630
att19           4.286956     4.434783        4.852174              0.0510
att6            2.660870     2.695652        2.800000              0.0310
att33           2.382609     2.565217        2.817391              0.0295
att1            1.000000     1.000000        1.000000              0.0115

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: att29
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   att29       NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att19               3.96          4.7            4.80              0.0235
att29               1.64          1.8            2.58              0.0090
att7                0.98          1.4            1.48              0.0070
att24               1.04          1.3            1.38              0.0065
att13               1.10          1.2            1.38              0.0060

=== LIME Rankings ===


Feature    Importance
--------  -----------
att29       0.0471613
att19       0.0392606
att6        0.0159969
att28       0.0144166
att40       0.0121193

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att19       0.2362000
att29       0.1287333
att7        0.0532000
att28       0.0463333
att40       0.0439333

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: att19
LIME: att29
SHAP: att19

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att19       att29       FALSE     
FEAT_IMP vs SHAP   att19       att19       TRUE      
LIME vs SHAP       att29       att19       FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=mfeat-zernike, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
att29             10.475       11.625          12.675              0.0465
att19              6.775        7.250           7.500              0.0290
att33              2.425        2.875           3.100              0.0115
att13              1.675        2.250           2.950              0.0090
att18              1.875        2.125           2.325              0.0085

=== LIME Rankings ===


Feature    Importance
--------  -----------
att29       0.1941806
att19       0.1422733
att28       0.0634883
att6        0.0615347
att40       0.0502607

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
att29       0.3522747
att19       0.2562052
att28       0.0806083
att6        0.0777528
att40       0.0717107

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: att29
LIME: att29
SHAP: att29

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   att29       att29       TRUE      
FEAT_IMP vs SHAP   att29       att29       TRUE      
LIME vs SHAP       att29       att29       TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: ozone-level-8hr
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V42             1.247887     1.295775        1.319718           0.0726125
V54             1.212676     1.218310        1.280282           0.0682715
V1              1.122535     1.161972        1.211268           0.0651144
V11             1.108451     1.133803        1.176056           0.0635359
V2              1.000000     1.000000        1.000000           0.0560379

=== LIME Rankings ===


Feature    Importance
--------  -----------
V42         0.0772654
V33         0.0291367
V1          0.0108114
V2          0.0100424
V54         0.0091896

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V42         0.0660863
V33         0.0244270
V11         0.0096453
V54         0.0044128
V1          0.0039343

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V42
LIME: V42
SHAP: V42

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V42         V42         TRUE      
FEAT_IMP vs SHAP   V42         V42         TRUE      
LIME vs SHAP       V42         V42         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V42              1.24086     1.268817        1.286021           0.0931334
V1               1.00000     1.000000        1.000000           0.0734017
V2               1.00000     1.000000        1.000000           0.0734017
V3               1.00000     1.000000        1.000000           0.0734017
V4               1.00000     1.000000        1.000000           0.0734017

=== LIME Rankings ===


Feature    Importance
--------  -----------
V42         0.1634417
V34         0.0118566
V12         0.0114157
V53         0.0111273
V49         0.0104952

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V42         0.0618554
V1          0.0000000
V10         0.0000000
V11         0.0000000
V12         0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V42
LIME: V42
SHAP: V42

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V42         V42         TRUE      
FEAT_IMP vs SHAP   V42         V42         TRUE      
LIME vs SHAP       V42         V42         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.4567            -nan     0.1000    0.0067
     2        0.4473            -nan     0.1000    0.0042
     3        0.4390            -nan     0.1000    0.0037
     4        0.4294            -nan     0.1000    0.0039
     5        0.4223            -nan     0.1000    0.0028
     6        0.4191            -nan     0.1000    0.0013
     7        0.4126            -nan     0.1000    0.0028
     8        0.4086            -nan     0.1000    0.0003
     9        0.4041            -nan     0.1000    0.0016
    10        0.3994            -nan     0.1000    0.0019
    20        0.3687            -nan     0.1000    0.0017
    40        0.3354            -nan     0.1000    0.0001
    50        0.3246            -nan     0.1000   -0.0000



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V43             1.044755     1.062937        1.075524           0.0599842
V1              1.030769     1.041958        1.041958           0.0588003
V42             1.036364     1.041958        1.048951           0.0588003
V13             1.002797     1.027972        1.027972           0.0580110
V40             1.020979     1.027972        1.033566           0.0580110

=== LIME Rankings ===


Feature    Importance
--------  -----------
V43         0.0185070
V42         0.0155339
V13         0.0137570
V41         0.0099271
V11         0.0094019

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V42         0.0077200
V41         0.0053489
V43         0.0050279
V13         0.0041184
V56         0.0037818

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V43
LIME: V43
SHAP: V42

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V43         V43         TRUE      
FEAT_IMP vs SHAP   V43         V42         FALSE     
LIME vs SHAP       V43         V42         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V33             4.119672     4.245902        4.491803           0.2044199
V34             1.911475     1.934426        2.039344           0.0931334
V42             1.496721     1.565574        1.565574           0.0753749
V38             1.321311     1.434426        1.478689           0.0690608
V11             1.150820     1.172131        1.188525           0.0564325

=== LIME Rankings ===


Feature    Importance
--------  -----------
V33         0.1751171
V42         0.0994548
V38         0.0962391
V1          0.0820412
V34         0.0783710

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V33         0.0850889
V34         0.0832589
V38         0.0496704
V42         0.0383629
V1          0.0295847

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V33
LIME: V33
SHAP: V33

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V33         V33         TRUE      
FEAT_IMP vs SHAP   V33         V33         TRUE      
LIME vs SHAP       V33         V33         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V42             1.773333     1.895238        1.902857           0.0785320
V56             1.563810     1.580952        1.598095           0.0655091
V32             1.516190     1.552381        1.567619           0.0643252
V41             1.470476     1.495238        1.643809           0.0619574
V37             1.241905     1.276191        1.350476           0.0528808

=== LIME Rankings ===


Feature    Importance
--------  -----------
V56         0.0368328
V41         0.0344990
V42         0.0290662
V37         0.0272892
V13         0.0247822

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V42         0.0186993
V41         0.0172221
V10         0.0129013
V56         0.0108867
V32         0.0035112

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V42
LIME: V56
SHAP: V42

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V42         V56         FALSE     
FEAT_IMP vs SHAP   V42         V42         TRUE      
LIME vs SHAP       V56         V42         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V36            1.0012739     1.006369        1.006369            0.062352
V40            0.9949045     1.006369        1.006369            0.062352
V42            0.9961783     1.006369        1.012739            0.062352
V51            1.0063694     1.006369        1.006369            0.062352
V52            1.0000000     1.006369        1.006369            0.062352

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V36
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V36         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V6              1.336416     1.381503        1.409249           0.0943173
V32             1.284393     1.341041        1.345665           0.0915549
V50             1.330636     1.341041        1.373410           0.0915549
V65             1.297110     1.329480        1.341041           0.0907656
V31             1.277457     1.312139        1.358381           0.0895817

=== LIME Rankings ===


Feature    Importance
--------  -----------
V6          0.0493675
V72         0.0476411
V58         0.0444100
V7          0.0416777
V24         0.0364765

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V38         0.0188961
V6          0.0186617
V42         0.0154561
V54         0.0139079
V58         0.0132867

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V6
LIME: V6
SHAP: V38

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V6          V6          TRUE      
FEAT_IMP vs SHAP   V6          V38         FALSE     
LIME vs SHAP       V6          V38         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=multinom ===
Applying data scaling for method: multinom
# weights:  74 (73 variable)
initial  value 1756.434956 
iter  10 value 576.710460
iter  20 value 439.774645
iter  30 value 359.963744
iter  40 value 327.933259
iter  50 value 322.739203
iter  60 value 320.995584
iter  70 value 320.868020
final  value 320.867693 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V31             5.351145     5.442748        5.618321           0.2813733
V38             3.106870     3.236641        3.413740           0.1673244
V39             3.109924     3.236641        3.351145           0.1673244
V57             3.015267     3.213741        3.288550           0.1661405
V70             2.883970     2.961832        3.146565           0.1531176

=== LIME Rankings ===


Feature    Importance
--------  -----------
V70         0.1573169
V57         0.1566737
V38         0.1088893
V40         0.1071999
V26         0.0813369

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V70         0.1766434
V57         0.1428016
V31         0.0934164
V38         0.0762262
V26         0.0558388

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V31
LIME: V70
SHAP: V70

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V31         V70         FALSE     
FEAT_IMP vs SHAP   V31         V70         FALSE     
LIME vs SHAP       V70         V70         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V21               1.5050       1.5500          1.6425           0.0489345
V1                1.3675       1.4500          1.5150           0.0457774
V12               1.3700       1.4125          1.4575           0.0445935
V42               1.2475       1.3625          1.4025           0.0430150
V54               1.2400       1.3125          1.3550           0.0414365

=== LIME Rankings ===


Feature    Importance
--------  -----------
V56         0.0260590
V51         0.0248624
V49         0.0164389
V21         0.0156857
V72         0.0153060

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V59         0.0138571
V51         0.0127338
V42         0.0108797
V46         0.0107069
V12         0.0095693

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V21
LIME: V56
SHAP: V59

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V21         V56         FALSE     
FEAT_IMP vs SHAP   V21         V59         FALSE     
LIME vs SHAP       V56         V59         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.0631413
V2                     1            1               1           0.0631413
V3                     1            1               1           0.0631413
V4                     1            1               1           0.0631413
V5                     1            1               1           0.0631413

=== LIME Rankings ===


Feature    Importance
--------  -----------
V72         0.9324574
V22         0.3235909
V21         0.2849145
V24         0.2286837
V60         0.2069276

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V70         2.0502771
V57         1.9114071
V23         1.1337593
V59         1.0612380
V24         0.9158891

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
LIME: V72
SHAP: V70

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V1          V72         FALSE     
FEAT_IMP vs SHAP   V1          V70         FALSE     
LIME vs SHAP       V72         V70         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V52            11.521053    11.631579       11.806579           0.6977111
V31             6.068421     6.230263        6.481579           0.3737174
V32             5.831579     6.019737        6.089474           0.3610892
V33             5.525000     5.572368        5.763158           0.3342541
V30             5.251316     5.296053        5.477632           0.3176796

=== LIME Rankings ===
Error in get_lime: missing value where TRUE/FALSE needed 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: no rows to aggregate 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 1 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 1 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 1 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V56            0.0016575    0.0019732       0.0023678           0.0019732
V53            0.0011839    0.0011839       0.0011839           0.0011839
V1             0.0001579    0.0007893       0.0007893           0.0007893
V13            0.0004736    0.0007893       0.0007893           0.0007893
V54            0.0007893    0.0007893       0.0007893           0.0007893
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V42         0.0227449
V41         0.0220347
V43         0.0170570
V39         0.0158005
V40         0.0155733

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V41          0.014748
V42          0.012728
V40          0.010604
V43          0.009384
V44          0.008168

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP          NA                 0
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V56
LIME: V42
SHAP: V41

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V56         V42         FALSE     
FEAT_IMP vs SHAP   V56         V41         FALSE     
LIME vs SHAP       V42         V41         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.0631413
V2                     1            1               1           0.0631413
V3                     1            1               1           0.0631413
V4                     1            1               1           0.0631413
V5                     1            1               1           0.0631413

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1                  0
V10                 0
V11                 0
V12                 0
V13                 0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          V1          TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.0631413
V2                     1            1               1           0.0631413
V3                     1            1               1           0.0631413
V4                     1            1               1           0.0631413
V5                     1            1               1           0.0631413

=== LIME Rankings ===


Feature    Importance
--------  -----------
V72         0.0019790
V12         0.0018762
V4          0.0018237
V26         0.0017441
V1          0.0017145

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.0008245
V24         0.0007339
V13         0.0007249
V15         0.0007238
V3          0.0007105

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
LIME: V72
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V1          V72         FALSE     
FEAT_IMP vs SHAP   V1          V1          TRUE      
LIME vs SHAP       V72         V1          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V57             2.165672     2.223881        2.246269           0.1176006
V28             1.583582     1.634328        1.695522           0.0864246
V70             1.489552     1.582090        1.679104           0.0836622
V31             1.401493     1.500000        1.583582           0.0793212
V46             1.419403     1.447761        1.525373           0.0765588

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V57
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V57         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.0631413
V2                     1            1               1           0.0631413
V3                     1            1               1           0.0631413
V4                     1            1               1           0.0631413
V5                     1            1               1           0.0631413

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1989 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V64             1.139310     1.151724        1.231724           0.0659037
V42             1.080000     1.103448        1.103448           0.0631413
V15             1.057931     1.096552        1.110345           0.0627466
V13             1.067586     1.089655        1.100690           0.0623520
V40             1.042759     1.055172        1.066207           0.0603788

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V64
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V64         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V10             1.048214     1.089286        1.114286           0.0481452
V11             1.073214     1.080357        1.119643           0.0477506
V59             1.021429     1.053571        1.094643           0.0465667
V2              1.037500     1.044643        1.069643           0.0461721
V3              1.035714     1.044643        1.076786           0.0461721

=== LIME Rankings ===


Feature    Importance
--------  -----------
V72         0.0246943
V56         0.0138833
V53         0.0124707
V70         0.0122289
V61         0.0100513

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V59         0.0068000
V1          0.0063333
V21         0.0057538
V13         0.0048000
V23         0.0046923

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V10
LIME: V72
SHAP: V59

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V10         V72         FALSE     
FEAT_IMP vs SHAP   V10         V59         FALSE     
LIME vs SHAP       V72         V59         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=ozone-level-8hr, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V31             3.021898     3.204380        3.274453           0.1732439
V70             2.192701     2.277372        2.347445           0.1231255
V57             1.813139     1.934307        1.953285           0.1045777
V38             1.148905     1.167883        1.237956           0.0631413
V40             1.128467     1.160584        1.178102           0.0627466

=== LIME Rankings ===


Feature    Importance
--------  -----------
V70         0.1987182
V57         0.1589712
V31         0.0681054
V38         0.0652324
V40         0.0634352

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V70         0.1276054
V57         0.0820894
V31         0.0685383
V38         0.0239074
V40         0.0204765

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -0.5                 3
FEAT_IMP vs SHAP        -0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V31
LIME: V70
SHAP: V70

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V31         V70         FALSE     
FEAT_IMP vs SHAP   V31         V70         FALSE     
LIME vs SHAP       V70         V70         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: pc4
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT          1.625714     1.678571        1.691429           0.1611797
CYCLOMATIC_COMPLEXITY         1.075714     1.100000        1.111429           0.1056241
LOC_BLANK                     1.000000     1.000000        1.000000           0.0960219
BRANCH_COUNT                  1.000000     1.000000        1.000000           0.0960219
CALL_PAIRS                    1.000000     1.000000        1.000000           0.0960219

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
LOC_CODE_AND_COMMENT      0.4167546
NUM_UNIQUE_OPERATORS      0.0473283
CYCLOMATIC_COMPLEXITY     0.0433078
ESSENTIAL_COMPLEXITY      0.0197796
DECISION_DENSITY          0.0101140
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
LOC_CODE_AND_COMMENT      0.1363303
NUM_UNIQUE_OPERATORS      0.0202868
CYCLOMATIC_COMPLEXITY     0.0036721
BRANCH_COUNT              0.0000000
CALL_PAIRS                0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
LIME: LOC_CODE_AND_COMMENT
SHAP: LOC_CODE_AND_COMMENT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
LIME vs SHAP       LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_BLANK                           1            1               1            0.122085
BRANCH_COUNT                        1            1               1            0.122085
CALL_PAIRS                          1            1               1            0.122085
LOC_CODE_AND_COMMENT                1            1               1            0.122085
LOC_COMMENTS                        1            1               1            0.122085

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
LOC_CODE_AND_COMMENT     0.2749505
ESSENTIAL_DENSITY        0.0152457
ESSENTIAL_COMPLEXITY     0.0082483
DECISION_DENSITY         0.0069499
HALSTEAD_DIFFICULTY      0.0058443
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
LOC_CODE_AND_COMMENT      0.1527549
BRANCH_COUNT              0.0000000
CALL_PAIRS                0.0000000
CONDITION_COUNT           0.0000000
CYCLOMATIC_COMPLEXITY     0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: LOC_BLANK
LIME: LOC_CODE_AND_COMMENT
SHAP: LOC_CODE_AND_COMMENT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   LOC_BLANK              LOC_CODE_AND_COMMENT   FALSE     
FEAT_IMP vs SHAP   LOC_BLANK              LOC_CODE_AND_COMMENT   FALSE     
LIME vs SHAP       LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.7029            -nan     0.1000    0.0192
     2        0.6764            -nan     0.1000    0.0105
     3        0.6458            -nan     0.1000    0.0135
     4        0.6244            -nan     0.1000    0.0109
     5        0.6059            -nan     0.1000    0.0089
     6        0.5901            -nan     0.1000    0.0074
     7        0.5799            -nan     0.1000    0.0044
     8        0.5736            -nan     0.1000    0.0020
     9        0.5675            -nan     0.1000    0.0033
    10        0.5624            -nan     0.1000    0.0024
    20        0.4992            -nan     0.1000    0.0014
    40        0.4454            -nan     0.1000    0.0000
    50        0.4255            -nan     0.1000    0.0004



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT         1.429412     1.500000        1.566177           0.1399177
CONDITION_COUNT              1.058823     1.066177        1.094118           0.0994513
CYCLOMATIC_DENSITY           1.032353     1.044118        1.058823           0.0973937
PERCENT_COMMENTS             1.023529     1.029412        1.042647           0.0960219
NUM_UNIQUE_OPERATORS         1.016177     1.022059        1.027941           0.0953361

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
LOC_CODE_AND_COMMENT     0.3673773
LOC_COMMENTS             0.0691680
CYCLOMATIC_DENSITY       0.0339785
ESSENTIAL_DENSITY        0.0177533
CONDITION_COUNT          0.0164875
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
LOC_CODE_AND_COMMENT     0.0992205
CONDITION_COUNT          0.0263080
CYCLOMATIC_DENSITY       0.0262147
PERCENT_COMMENTS         0.0106480
LOC_COMMENTS             0.0068713

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
LIME: LOC_CODE_AND_COMMENT
SHAP: LOC_CODE_AND_COMMENT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
LIME vs SHAP       LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT         2.696203     2.797468        3.078481           0.1515775
NUMBER_OF_LINES              2.126582     2.215190        2.341772           0.1200274
NUM_OPERANDS                 2.139241     2.202532        2.306329           0.1193416
CYCLOMATIC_DENSITY           1.918987     2.063291        2.151899           0.1117970
LOC_TOTAL                    1.754430     1.810127        1.891139           0.0980796

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
LOC_CODE_AND_COMMENT     0.3907592
LOC_TOTAL                0.1481574
NUMBER_OF_LINES          0.1042650
CYCLOMATIC_DENSITY       0.1014599
ESSENTIAL_DENSITY        0.0865912
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
LOC_CODE_AND_COMMENT     0.1234983
NUM_OPERANDS             0.0816382
DESIGN_COMPLEXITY        0.0723065
CYCLOMATIC_DENSITY       0.0701830
DESIGN_DENSITY           0.0636347

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
LIME: LOC_CODE_AND_COMMENT
SHAP: LOC_CODE_AND_COMMENT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
LIME vs SHAP       LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT         2.000000     2.042373        2.186441           0.1652949
LOC_COMMENTS                 1.262712     1.296610        1.338983           0.1049383
CYCLOMATIC_DENSITY           1.201695     1.245763        1.293220           0.1008230
CONDITION_COUNT              1.105085     1.135593        1.135593           0.0919067
LOC_BLANK                    1.098305     1.127119        1.147458           0.0912209

=== LIME Rankings ===


Feature                  Importance
----------------------  -----------
LOC_CODE_AND_COMMENT      0.5265388
CONDITION_COUNT           0.0678902
CYCLOMATIC_COMPLEXITY     0.0497687
ESSENTIAL_COMPLEXITY      0.0235155
LOC_COMMENTS              0.0229546
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
CONDITION_COUNT          0.0437430
LOC_CODE_AND_COMMENT     0.0370115
CYCLOMATIC_DENSITY       0.0248846
LOC_BLANK                0.0177160
NUM_OPERANDS             0.0070864

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
LIME: LOC_CODE_AND_COMMENT
SHAP: CONDITION_COUNT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   CONDITION_COUNT        FALSE     
LIME vs SHAP       LOC_CODE_AND_COMMENT   CONDITION_COUNT        FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT         1.267606     1.281690        1.329578           0.1248285
CALL_PAIRS                   1.038028     1.077465        1.090141           0.1049383
MAINTENANCE_SEVERITY         1.045070     1.063380        1.107042           0.1035665
PERCENT_COMMENTS             1.030986     1.042253        1.054930           0.1015089
PARAMETER_COUNT              1.008451     1.035211        1.059155           0.1008230

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2   Agreement 
-----------------  ---------------------  ----------  ----------
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature                     importance.05   importance   importance.95   permutation.error
-------------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT             2.022609     2.078261        2.240000           0.1639232
MODIFIED_CONDITION_COUNT         1.949565     1.991304        2.000000           0.1570645
LOC_TOTAL                        1.793044     1.930435        1.977391           0.1522634
LOC_EXECUTABLE                   1.521739     1.643478        1.714783           0.1296296
NUM_UNIQUE_OPERANDS              1.406956     1.434783        1.511304           0.1131687

=== LIME Rankings ===


Feature                     Importance
-------------------------  -----------
MODIFIED_CONDITION_COUNT     0.2675507
LOC_CODE_AND_COMMENT         0.1347946
DECISION_COUNT               0.1111697
NUM_UNIQUE_OPERANDS          0.0814576
CONDITION_COUNT              0.0695099
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                     Importance
-------------------------  -----------
MAINTENANCE_SEVERITY         0.0639031
DECISION_DENSITY             0.0617086
MODIFIED_CONDITION_COUNT     0.0540172
CYCLOMATIC_DENSITY           0.0503590
NUM_UNIQUE_OPERATORS         0.0331441

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
LIME: MODIFIED_CONDITION_COUNT
SHAP: MAINTENANCE_SEVERITY

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                  Feature_2                  Agreement 
-----------------  -------------------------  -------------------------  ----------
FEAT_IMP vs LIME   LOC_CODE_AND_COMMENT       MODIFIED_CONDITION_COUNT   FALSE     
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT       MAINTENANCE_SEVERITY       FALSE     
LIME vs SHAP       MODIFIED_CONDITION_COUNT   MAINTENANCE_SEVERITY       FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=multinom ===
Applying data scaling for method: multinom
# weights:  39 (38 variable)
initial  value 1010.608589 
iter  10 value 340.660802
iter  20 value 312.958696
iter  30 value 291.294050
iter  40 value 285.217525
iter  50 value 284.671602
iter  60 value 284.577792
iter  70 value 284.482423
iter  80 value 284.462460
iter  90 value 284.462262
iter 100 value 284.461604
final  value 284.461604 
stopped after 100 iterations


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                     importance.05   importance   importance.95   permutation.error
-------------------------  --------------  -----------  --------------  ------------------
NODE_COUNT                       4.192593     4.351852        4.651852           0.3223594
HALSTEAD_VOLUME                  3.874074     3.925926        4.042593           0.2908093
EDGE_COUNT                       3.681481     3.777778        3.907407           0.2798354
MODIFIED_CONDITION_COUNT         3.159259     3.250000        3.344444           0.2407407
HALSTEAD_ERROR_EST               2.605556     2.805556        2.840741           0.2078189

=== LIME Rankings ===


Feature                     Importance
-------------------------  -----------
MODIFIED_CONDITION_COUNT     0.2731419
MULTIPLE_CONDITION_COUNT     0.1639618
HALSTEAD_VOLUME              0.1561251
CONDITION_COUNT              0.1420307
NODE_COUNT                   0.1239583
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                     Importance
-------------------------  -----------
MODIFIED_CONDITION_COUNT     0.1444822
MULTIPLE_CONDITION_COUNT     0.1244149
NODE_COUNT                   0.1044909
EDGE_COUNT                   0.1002425
CONDITION_COUNT              0.0741190

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: NODE_COUNT
LIME: MODIFIED_CONDITION_COUNT
SHAP: MODIFIED_CONDITION_COUNT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                  Feature_2                  Agreement 
-----------------  -------------------------  -------------------------  ----------
FEAT_IMP vs LIME   NODE_COUNT                 MODIFIED_CONDITION_COUNT   FALSE     
FEAT_IMP vs SHAP   NODE_COUNT                 MODIFIED_CONDITION_COUNT   FALSE     
LIME vs SHAP       MODIFIED_CONDITION_COUNT   MODIFIED_CONDITION_COUNT   TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT         4.351020     4.530612        4.632653           0.1522634
LOC_BLANK                    2.232653     2.408163        2.497959           0.0809328
DECISION_DENSITY             2.126531     2.183673        2.355102           0.0733882
CALL_PAIRS                   1.983674     2.000000        2.085714           0.0672154
DESIGN_COMPLEXITY            1.497959     1.714286        1.816326           0.0576132

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
LOC_CODE_AND_COMMENT     0.2841467
DESIGN_COMPLEXITY        0.1096112
LOC_BLANK                0.0909014
ESSENTIAL_DENSITY        0.0541094
LOC_COMMENTS             0.0536751
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
LOC_CODE_AND_COMMENT     0.0814415
DECISION_DENSITY         0.0447924
PARAMETER_COUNT          0.0357538
ESSENTIAL_DENSITY        0.0355822
LOC_BLANK                0.0324167

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
LIME: LOC_CODE_AND_COMMENT
SHAP: LOC_CODE_AND_COMMENT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
LIME vs SHAP       LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                     importance.05   importance   importance.95   permutation.error
-------------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT             1.056098     1.060976        1.065854           0.1193416
CONDITION_COUNT                  1.030488     1.036585        1.041463           0.1165981
MODIFIED_CONDITION_COUNT         1.025610     1.036585        1.036585           0.1165981
PERCENT_COMMENTS                 1.036585     1.036585        1.047561           0.1165981
LOC_TOTAL                        1.024390     1.036585        1.041463           0.1165981

=== LIME Rankings ===


Feature                     Importance
-------------------------  -----------
ESSENTIAL_DENSITY            2.8606966
DECISION_COUNT               0.0848156
CONDITION_COUNT              0.0836373
MODIFIED_CONDITION_COUNT     0.0823417
MULTIPLE_CONDITION_COUNT     0.0799843
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature               Importance
-------------------  -----------
DECISION_DENSITY        4.215703
PARAMETER_COUNT         2.709568
DESIGN_DENSITY          1.471249
CYCLOMATIC_DENSITY      1.429339
HALSTEAD_LEVEL          1.113717

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
LIME: ESSENTIAL_DENSITY
SHAP: DECISION_DENSITY

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2           Agreement 
-----------------  ---------------------  ------------------  ----------
FEAT_IMP vs LIME   LOC_CODE_AND_COMMENT   ESSENTIAL_DENSITY   FALSE     
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   DECISION_DENSITY    FALSE     
LIME vs SHAP       ESSENTIAL_DENSITY      DECISION_DENSITY    FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===
Error in get_featimp: system is computationally singular: reciprocal condition number = 1.36016e-18 

=== LIME Rankings ===
Error in get_lime: system is computationally singular: reciprocal condition number = 1.36016e-18 
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: system is computationally singular: reciprocal condition number = 1.36016e-18 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 0 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT            105.2          110           117.4           0.0754458
CYCLOMATIC_DENSITY               35.0           41            47.4           0.0281207
PERCENT_COMMENTS                 21.8           27            33.2           0.0185185
LOC_COMMENTS                      3.2            7             8.8           0.0048011
LOC_BLANK                         1.2            2             2.8           0.0013717

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
LOC_CODE_AND_COMMENT     0.1029249
PERCENT_COMMENTS         0.0302203
CYCLOMATIC_DENSITY       0.0278619
ESSENTIAL_DENSITY        0.0246227
DECISION_DENSITY         0.0187694
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                     Importance
-------------------------  -----------
LOC_CODE_AND_COMMENT          0.061192
CYCLOMATIC_DENSITY            0.028476
MULTIPLE_CONDITION_COUNT      0.014152
MODIFIED_CONDITION_COUNT      0.013960
PERCENT_COMMENTS              0.013268

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
LIME: LOC_CODE_AND_COMMENT
SHAP: LOC_CODE_AND_COMMENT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
LIME vs SHAP       LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_BLANK                           1            1               1            0.122085
BRANCH_COUNT                        1            1               1            0.122085
CALL_PAIRS                          1            1               1            0.122085
LOC_CODE_AND_COMMENT                1            1               1            0.122085
LOC_COMMENTS                        1            1               1            0.122085

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                  Importance
----------------------  -----------
BRANCH_COUNT                      0
CALL_PAIRS                        0
CONDITION_COUNT                   0
CYCLOMATIC_COMPLEXITY             0
CYCLOMATIC_DENSITY                0

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP           1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: LOC_BLANK
SHAP: BRANCH_COUNT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2      Agreement 
-----------------  ----------  -------------  ----------
FEAT_IMP vs SHAP   LOC_BLANK   BRANCH_COUNT   FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
PARAMETER_COUNT              1.0000000     1.005525        1.005525           0.1248285
BRANCH_COUNT                 1.0000000     1.000000        1.000000           0.1241427
CYCLOMATIC_COMPLEXITY        1.0000000     1.000000        1.000000           0.1241427
CYCLOMATIC_DENSITY           0.9944751     1.000000        1.000000           0.1241427
DESIGN_COMPLEXITY            0.9955801     1.000000        1.000000           0.1241427

=== LIME Rankings ===


Feature                     Importance
-------------------------  -----------
LOC_CODE_AND_COMMENT         0.0424351
DECISION_COUNT               0.0305283
CONDITION_COUNT              0.0264258
MULTIPLE_CONDITION_COUNT     0.0257977
MODIFIED_CONDITION_COUNT     0.0241260
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
DECISION_DENSITY         0.0046318
MAINTENANCE_SEVERITY     0.0026183
PERCENT_COMMENTS         0.0021512
PARAMETER_COUNT          0.0016713
LOC_BLANK                0.0011993

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: PARAMETER_COUNT
LIME: LOC_CODE_AND_COMMENT
SHAP: DECISION_DENSITY

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   PARAMETER_COUNT        LOC_CODE_AND_COMMENT   FALSE     
FEAT_IMP vs SHAP   PARAMETER_COUNT        DECISION_DENSITY       FALSE     
LIME vs SHAP       LOC_CODE_AND_COMMENT   DECISION_DENSITY       FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                     importance.05   importance   importance.95   permutation.error
-------------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT             1.947368     2.096491        2.112281           0.1639232
MODIFIED_CONDITION_COUNT         1.649123     1.754386        1.868421           0.1371742
BRANCH_COUNT                     1.614035     1.701754        1.761403           0.1330590
LOC_TOTAL                        1.603509     1.640351        1.664912           0.1282579
NUMBER_OF_LINES                  1.414035     1.517544        1.556140           0.1186557

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2   Agreement 
-----------------  ---------------------  ----------  ----------
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                  importance.05   importance   importance.95   permutation.error
----------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT           1.09750      1.11875         1.16375           0.1227709
PERCENT_COMMENTS               1.02500      1.03125         1.03125           0.1131687
DECISION_DENSITY               1.00750      1.01875         1.02875           0.1117970
MAINTENANCE_SEVERITY           0.99625      1.01250         1.02375           0.1111111
CYCLOMATIC_COMPLEXITY          1.00000      1.00625         1.00625           0.1104252

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2   Agreement 
-----------------  ---------------------  ----------  ----------
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1999 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT         1.471724     1.489655        1.514483           0.1481481
DESIGN_COMPLEXITY            1.008276     1.034483        1.067586           0.1028807
PARAMETER_COUNT              1.011035     1.027586        1.040000           0.1021948
ESSENTIAL_COMPLEXITY         1.013793     1.013793        1.026207           0.1008230
NUM_UNIQUE_OPERANDS          1.001379     1.006897        1.012414           0.1001372

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2   Agreement 
-----------------  ---------------------  ----------  ----------
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
LOC_CODE_AND_COMMENT         1.405941     1.415842        1.504951           0.0980796
CALL_PAIRS                   1.205941     1.257426        1.273267           0.0871056
PERCENT_COMMENTS             1.180198     1.217822        1.273267           0.0843621
LOC_COMMENTS                 1.093069     1.178218        1.251485           0.0816187
DESIGN_DENSITY               1.093069     1.128713        1.186139           0.0781893

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
LOC_CODE_AND_COMMENT     0.2731849
ESSENTIAL_COMPLEXITY     0.0611423
DESIGN_COMPLEXITY        0.0503833
NUM_UNIQUE_OPERANDS      0.0448107
ESSENTIAL_DENSITY        0.0364920
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
DECISION_DENSITY         0.0405778
MAINTENANCE_SEVERITY     0.0264000
ESSENTIAL_DENSITY        0.0247333
LOC_CODE_AND_COMMENT     0.0232095
PERCENT_COMMENTS         0.0158667

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: LOC_CODE_AND_COMMENT
LIME: LOC_CODE_AND_COMMENT
SHAP: DECISION_DENSITY

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   LOC_CODE_AND_COMMENT   LOC_CODE_AND_COMMENT   TRUE      
FEAT_IMP vs SHAP   LOC_CODE_AND_COMMENT   DECISION_DENSITY       FALSE     
LIME vs SHAP       LOC_CODE_AND_COMMENT   DECISION_DENSITY       FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=pc4, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature                     importance.05   importance   importance.95   permutation.error
-------------------------  --------------  -----------  --------------  ------------------
MODIFIED_CONDITION_COUNT         2.358929     2.589286        2.619643           0.1989026
BRANCH_COUNT                     2.207143     2.250000        2.282143           0.1728395
LOC_CODE_AND_COMMENT             1.535714     1.633929        1.641071           0.1255144
LOC_TOTAL                        1.616071     1.633929        1.737500           0.1255144
LOC_COMMENTS                     1.350000     1.375000        1.450000           0.1056241

=== LIME Rankings ===


Feature                     Importance
-------------------------  -----------
MODIFIED_CONDITION_COUNT     0.5528000
BRANCH_COUNT                 0.1355977
DECISION_COUNT               0.1352292
LOC_CODE_AND_COMMENT         0.1211831
CYCLOMATIC_DENSITY           0.0969760
Warning messages:
1: ESSENTIAL_COMPLEXITY does not contain enough variance to use quantile binning. Using standard binning instead. 
2: ESSENTIAL_DENSITY does not contain enough variance to use quantile binning. Using standard binning instead. 

=== SHAP (IML Shapley) Rankings ===


Feature                     Importance
-------------------------  -----------
MODIFIED_CONDITION_COUNT     0.1023602
BRANCH_COUNT                 0.0647430
MAINTENANCE_SEVERITY         0.0631806
DECISION_DENSITY             0.0427309
PERCENT_COMMENTS             0.0423585

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: MODIFIED_CONDITION_COUNT
LIME: MODIFIED_CONDITION_COUNT
SHAP: MODIFIED_CONDITION_COUNT

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1                  Feature_2                  Agreement 
-----------------  -------------------------  -------------------------  ----------
FEAT_IMP vs LIME   MODIFIED_CONDITION_COUNT   MODIFIED_CONDITION_COUNT   TRUE      
FEAT_IMP vs SHAP   MODIFIED_CONDITION_COUNT   MODIFIED_CONDITION_COUNT   TRUE      
LIME vs SHAP       MODIFIED_CONDITION_COUNT   MODIFIED_CONDITION_COUNT   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: phoneme
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1              1.924571     1.948571        1.955048           0.3225095
V2              1.903238     1.939048        1.954667           0.3209332
V3              1.430476     1.478095        1.500952           0.2446406
V4              1.290667     1.323810        1.344762           0.2191047
V5              1.129905     1.161905        1.171048           0.1923077

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.1341007
V4          0.1258773
V2          0.0905808
V3          0.0481367
V5          0.0329877

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2          0.1400491
V4          0.1066457
V5          0.0879498
V1          0.0841276
V3          0.0406699

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
LIME: V1
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V1          V1          TRUE      
FEAT_IMP vs SHAP   V1          V2          FALSE     
LIME vs SHAP       V1          V2          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              1.800922     1.820277        1.899539           0.4981084
V1              1.000000     1.000000        1.000000           0.2736444
V2              1.000000     1.000000        1.000000           0.2736444
V3              1.000000     1.000000        1.000000           0.2736444
V5              1.000000     1.000000        1.000000           0.2736444

=== LIME Rankings ===


Feature    Importance
--------  -----------
V4          0.2203827
V1          0.0071398
V2          0.0063505
V3          0.0033006
V5          0.0029822

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V4          0.1546298
V1          0.0000000
V2          0.0000000
V3          0.0000000
V5          0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V4
SHAP: V4

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V4          TRUE      
FEAT_IMP vs SHAP   V4          V4          TRUE      
LIME vs SHAP       V4          V4          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3414            -nan     0.1000    0.0222
     2        1.3045            -nan     0.1000    0.0179
     3        1.2741            -nan     0.1000    0.0145
     4        1.2453            -nan     0.1000    0.0134
     5        1.2229            -nan     0.1000    0.0109
     6        1.2035            -nan     0.1000    0.0101
     7        1.1851            -nan     0.1000    0.0084
     8        1.1683            -nan     0.1000    0.0077
     9        1.1543            -nan     0.1000    0.0060
    10        1.1407            -nan     0.1000    0.0068
    20        1.0488            -nan     0.1000    0.0026
    40        0.9597            -nan     0.1000    0.0012
    50        0.9427            -nan     0.1000    0.0003



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              1.323423     1.354354        1.396096           0.2843632
V2              1.109610     1.147147        1.159159           0.2408575
V3              1.088589     1.114114        1.119219           0.2339218
V1              1.089189     1.108108        1.115315           0.2326608
V5              1.049549     1.057057        1.076276           0.2219420

=== LIME Rankings ===


Feature    Importance
--------  -----------
V4          0.1415604
V3          0.1101463
V1          0.0823905
V5          0.0623309
V2          0.0394985

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V4          0.1062149
V3          0.0727966
V5          0.0364189
V2          0.0251273
V1          0.0242142

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V4
SHAP: V4

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V4          TRUE      
FEAT_IMP vs SHAP   V4          V4          TRUE      
LIME vs SHAP       V4          V4          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              1.541627     1.653908        1.690909           0.3269231
V2              1.347687     1.373206        1.394896           0.2714376
V1              1.301116     1.355662        1.361085           0.2679697
V3              1.066348     1.087719        1.108772           0.2150063
V5              1.056778     1.073365        1.074960           0.2121690

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.2291409
V4          0.0826144
V3          0.0695372
V5          0.0645760
V2          0.0435747

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V3          0.1270452
V4          0.0584767
V1          0.0574210
V2          0.0567589
V5          0.0428721

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V1
SHAP: V3

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V1          FALSE     
FEAT_IMP vs SHAP   V4          V3          FALSE     
LIME vs SHAP       V1          V3          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1              2.211667     2.277778        2.313889           0.2585120
V3              2.098333     2.144444        2.182222           0.2433796
V2              2.065000     2.116667        2.150000           0.2402270
V4              1.422778     1.491667        1.516111           0.1692938
V5              1.265000     1.294444        1.310556           0.1469105

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.1562769
V3          0.1027626
V2          0.0671021
V5          0.0411920
V4          0.0314174

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.2152046
V2          0.1420353
V4          0.0928093
V3          0.0780848
V5          0.0160971

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
LIME: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V1          V1          TRUE      
FEAT_IMP vs SHAP   V1          V1          TRUE      
LIME vs SHAP       V1          V1          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4               1.17625      1.19250         1.23425           0.3007566
V5               1.16150      1.18125         1.20525           0.2979193
V1               1.14075      1.16000         1.16975           0.2925599
V3               1.09775      1.11875         1.12675           0.2821564
V2               1.06800      1.07750         1.10150           0.2717528

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V4          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              1.497415     1.511565        1.543401           0.3502522
V2              1.203537     1.243537        1.259320           0.2881463
V5              1.143129     1.186395        1.191565           0.2749054
V3              1.152381     1.168708        1.213605           0.2708071
V1              1.111293     1.115646        1.134966           0.2585120

=== LIME Rankings ===


Feature    Importance
--------  -----------
V4          0.2240167
V3          0.1066327
V1          0.0775953
V5          0.0527583
V2          0.0248643

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V4          0.1873262
V3          0.1129689
V1          0.0415702
V2          0.0337581
V5          0.0295472

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V4
SHAP: V4

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V4          TRUE      
FEAT_IMP vs SHAP   V4          V4          TRUE      
LIME vs SHAP       V4          V4          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=multinom ===
Applying data scaling for method: multinom
# weights:  7 (6 variable)
initial  value 2198.662857 
iter  10 value 1664.060508
final  value 1663.887300 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              1.256724     1.289731        1.313447           0.3325977
V3              1.095599     1.117359        1.138142           0.2881463
V2              1.073839     1.089242        1.104890           0.2808953
V1              1.058435     1.073350        1.102445           0.2767970
V5              1.051345     1.067237        1.080685           0.2752207

=== LIME Rankings ===


Feature    Importance
--------  -----------
V4          0.2181460
V1          0.1758006
V3          0.1617761
V5          0.0517906
V2          0.0110422

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V3          0.1633912
V4          0.1419141
V1          0.0666306
V5          0.0226925
V2          0.0135394

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V4
SHAP: V3

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V4          TRUE      
FEAT_IMP vs SHAP   V4          V3          FALSE     
LIME vs SHAP       V4          V3          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1              1.986858     2.006160        2.048049           0.3080076
V2              1.916632     1.971253        1.999179           0.3026482
V3              1.746612     1.778234        1.827926           0.2730139
V4              1.371253     1.392197        1.408214           0.2137453
V5              1.110062     1.139630        1.151129           0.1749685

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.0916253
V2          0.0835762
V4          0.0700728
V3          0.0611440
V5          0.0446501

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V3          0.1214801
V1          0.0915861
V2          0.0858213
V4          0.0749138
V5          0.0590930

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -0.5                 3
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
LIME: V1
SHAP: V3

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V1          V1          TRUE      
FEAT_IMP vs SHAP   V1          V3          FALSE     
LIME vs SHAP       V1          V3          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4                3.8112        3.920          3.9872           0.3089533
V3                3.7120        3.848          3.9864           0.3032787
V5                3.6448        3.688          3.7240           0.2906683
V2                3.4400        3.572          3.6472           0.2815259
V1                3.2752        3.476          3.5112           0.2739596

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1         10.3468493
V3          3.1628990
V5          2.2487135
V2          0.6714614
V4          0.4005290

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          5.9613251
V3          4.0795185
V2          1.7282106
V4          1.0527115
V5          0.7486737

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V1          FALSE     
FEAT_IMP vs SHAP   V4          V1          FALSE     
LIME vs SHAP       V1          V1          TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1              1.540118     1.606195        1.613864           0.3433165
V2              1.329498     1.345133        1.391740           0.2875158
V3              1.233333     1.264012        1.281121           0.2701765
V4              1.114159     1.125369        1.174041           0.2405422
V5              1.093510     1.122419        1.135103           0.2399117

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.2576170
V5          0.1007692
V2          0.0695977
V4          0.0523754
V3          0.0498219

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.1235574
V4          0.0794409
V5          0.0667098
V3          0.0607090
V2          0.0359536

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
LIME: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V1          V1          TRUE      
FEAT_IMP vs SHAP   V1          V1          TRUE      
LIME vs SHAP       V1          V1          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1             0.2023329    0.2093317       0.2228247           0.2093317
V3             0.1644388    0.1674023       0.1676545           0.1674023
V2             0.1540353    0.1604666       0.1656368           0.1604666
V4             0.1481715    0.1516393       0.1546028           0.1516393
V5             0.0728878    0.0759773       0.0769231           0.0759773
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V5          0.0906559
V1          0.0826449
V3          0.0597701
V2          0.0279520
V4          0.0249794

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V2           0.128744
V1           0.112980
V5           0.088040
V4           0.059464
V3           0.056512

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
LIME: V5
SHAP: V2

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V1          V5          FALSE     
FEAT_IMP vs SHAP   V1          V2          FALSE     
LIME vs SHAP       V5          V2          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1                 0.5
V2                     1            1               1                 0.5
V3                     1            1               1                 0.5
V4                     1            1               1                 0.5
V5                     1            1               1                 0.5

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1                  0
V2                  0
V3                  0
V4                  0
V5                  0

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP           1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          V1          TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              1.199755     1.211750        1.237699           0.3121059
V2              1.112607     1.139535        1.150551           0.2935057
V1              1.128519     1.135863        1.163770           0.2925599
V3              1.079804     1.093023        1.105753           0.2815259
V5              1.056548     1.057527        1.066585           0.2723834

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.0976355
V4          0.0971303
V3          0.0776961
V5          0.0204210
V2          0.0087622

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V3          0.0739142
V4          0.0597442
V1          0.0355413
V2          0.0095526
V5          0.0086470

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V1
SHAP: V3

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V1          FALSE     
FEAT_IMP vs SHAP   V4          V3          FALSE     
LIME vs SHAP       V1          V3          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              1.271338     1.299363        1.324586           0.3215637
V1              1.147006     1.160510        1.175796           0.2872005
V2              1.156688     1.157962        1.182420           0.2865700
V3              1.065478     1.082802        1.089172           0.2679697
V5              1.080510     1.082802        1.089427           0.2679697

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V4          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1              1.817442     1.852713        1.863954           0.3013871
V3              1.559690     1.585271        1.619767           0.2578815
V2              1.484109     1.523256        1.538372           0.2477932
V4              1.305426     1.343023        1.363566           0.2184741
V5              1.150388     1.180233        1.202326           0.1919924

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1              1.483881     1.513302        1.550861           0.3048550
V2              1.449452     1.507042        1.519875           0.3035939
V4              1.180282     1.194053        1.219405           0.2405422
V3              1.113928     1.134585        1.153991           0.2285624
V5              1.066354     1.100156        1.115806           0.2216267

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V3              2.922105     2.961403        3.011930           0.2660782
V1              2.759298     2.803509        2.907368           0.2518916
V2              2.428772     2.589474        2.643509           0.2326608
V4              2.317895     2.445614        2.496140           0.2197352
V5              2.111579     2.192982        2.218947           0.1970366

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.1214064
V3          0.1152332
V5          0.0822435
V4          0.0757927
V2          0.0099600

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V5          0.1159333
V1          0.1102000
V3          0.0979333
V2          0.0970000
V4          0.0870667

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V3
LIME: V1
SHAP: V5

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V3          V1          FALSE     
FEAT_IMP vs SHAP   V3          V5          FALSE     
LIME vs SHAP       V1          V5          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=phoneme, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              1.255990     1.289731        1.313692           0.3325977
V3              1.095599     1.117359        1.138142           0.2881463
V2              1.073594     1.089242        1.104890           0.2808953
V1              1.058680     1.073350        1.102445           0.2767970
V5              1.052567     1.068460        1.080929           0.2755359

=== LIME Rankings ===


Feature    Importance
--------  -----------
V4          0.2178918
V1          0.1756464
V3          0.1615742
V5          0.0516916
V2          0.0110491

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V3          0.1631643
V4          0.1417279
V1          0.0665676
V5          0.0226479
V2          0.0135334

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V4
SHAP: V3

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V4          TRUE      
FEAT_IMP vs SHAP   V4          V3          FALSE     
LIME vs SHAP       V4          V3          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: qsar-biodeg
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1              1.602367     1.698225        1.715976           0.2720379
V10             1.530177     1.585799        1.652071           0.2540284
V38             1.280473     1.349112        1.389349           0.2161137
V3              1.240237     1.272189        1.313610           0.2037915
V13             1.166864     1.195266        1.211834           0.1914692

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.1921281
V39         0.1543290
V26         0.0286948
V21         0.0212672
V6          0.0210061
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.2297347
V10         0.1622780
V38         0.0798762
V3          0.0471526
V17         0.0442271

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
LIME: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V1          V1          TRUE      
FEAT_IMP vs SHAP   V1          V1          TRUE      
LIME vs SHAP       V1          V1          TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V36             1.535252     1.568345        1.634532           0.4132701
V1              1.000000     1.000000        1.000000           0.2635071
V2              1.000000     1.000000        1.000000           0.2635071
V3              1.000000     1.000000        1.000000           0.2635071
V4              1.000000     1.000000        1.000000           0.2635071

=== LIME Rankings ===


Feature    Importance
--------  -----------
V36         0.6372180
V19         0.0270049
V29         0.0150470
V41         0.0142550
V6          0.0102131
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V36          0.412461
V1           0.000000
V10          0.000000
V11          0.000000
V12          0.000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V36
LIME: V36
SHAP: V36

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V36         V36         TRUE      
FEAT_IMP vs SHAP   V36         V36         TRUE      
LIME vs SHAP       V36         V36         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2347            -nan     0.1000    0.0190
     2        1.1954            -nan     0.1000    0.0179
     3        1.1682            -nan     0.1000    0.0123
     4        1.1424            -nan     0.1000    0.0121
     5        1.1176            -nan     0.1000    0.0120
     6        1.0973            -nan     0.1000    0.0095
     7        1.0828            -nan     0.1000    0.0054
     8        1.0670            -nan     0.1000    0.0070
     9        1.0497            -nan     0.1000    0.0087
    10        1.0333            -nan     0.1000    0.0064
    20        0.9236            -nan     0.1000    0.0025
    40        0.8025            -nan     0.1000    0.0024
    50        0.7606            -nan     0.1000    0.0012



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V36             1.173034     1.280899        1.328090           0.2161137
V30             1.048315     1.106742        1.120225           0.1867299
V12             1.046067     1.061798        1.066292           0.1791469
V38             1.030337     1.061798        1.088764           0.1791469
V1              1.044944     1.056180        1.131461           0.1781991

=== LIME Rankings ===


Feature    Importance
--------  -----------
V36         0.2145277
V38         0.1095710
V1          0.0906903
V12         0.0731720
V22         0.0687517
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V36         0.1624954
V1          0.0640011
V22         0.0586477
V30         0.0517940
V38         0.0485191

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V36
LIME: V36
SHAP: V36

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V36         V36         TRUE      
FEAT_IMP vs SHAP   V36         V36         TRUE      
LIME vs SHAP       V36         V36         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V38             1.737143     1.842857        1.898571           0.2445498
V1              1.404286     1.464286        1.547143           0.1943128
V41             1.287143     1.335714        1.398571           0.1772512
V37             1.294286     1.328571        1.350000           0.1763033
V36             1.167143     1.207143        1.284286           0.1601896

=== LIME Rankings ===


Feature    Importance
--------  -----------
V36         0.1490992
V41         0.1484190
V1          0.1480949
V38         0.1409247
V11         0.1118105
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.1692024
V38         0.1649400
V36         0.1291705
V37         0.1149875
V41         0.0747637

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V38
LIME: V36
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V38         V36         FALSE     
FEAT_IMP vs SHAP   V38         V1          FALSE     
LIME vs SHAP       V36         V1          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V36             1.866187     2.000000        2.073381           0.2635071
V1              1.369784     1.446043        1.474820           0.1905213
V12             1.231655     1.258993        1.289209           0.1658768
V38             1.182734     1.208633        1.241727           0.1592417
V8              1.168345     1.201439        1.220144           0.1582938

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.1843513
V36         0.1270254
V38         0.0535057
V8          0.0525708
V27         0.0514311
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V36         0.2122330
V1          0.1537854
V38         0.0845934
V30         0.0704927
V27         0.0607195

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V36
LIME: V1
SHAP: V36

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V36         V1          FALSE     
FEAT_IMP vs SHAP   V36         V36         TRUE      
LIME vs SHAP       V1          V36         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V34             1.063584     1.092485        1.107514           0.1791469
V25             1.041619     1.086705        1.114451           0.1781991
V20             1.045087     1.063584        1.068208           0.1744076
V1              1.034682     1.046243        1.110983           0.1715640
V9              1.035838     1.046243        1.084393           0.1715640

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
There were 12 warnings (use warnings() to see them)

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V34
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V34         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V13             2.222680     2.309278        2.435052           0.2123223
V30             1.711340     1.886598        1.962887           0.1734597
V10             1.758763     1.783505        1.841237           0.1639810
V16             1.688660     1.773196        1.903093           0.1630332
V8              1.684536     1.731959        1.857732           0.1592417

=== LIME Rankings ===


Feature    Importance
--------  -----------
V30         0.1219829
V10         0.1014226
V3          0.1000910
V5          0.0911955
V26         0.0839348
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V13         0.1361021
V14         0.0956960
V8          0.0758944
V3          0.0727947
V16         0.0722040

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              NA                 0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V13
LIME: V30
SHAP: V13

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V13         V30         FALSE     
FEAT_IMP vs SHAP   V13         V13         TRUE      
LIME vs SHAP       V30         V13         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=multinom ===
Applying data scaling for method: multinom
# weights:  43 (42 variable)
initial  value 731.270275 
iter  10 value 369.002381
iter  20 value 305.817903
iter  30 value 300.129800
iter  40 value 297.826693
iter  50 value 297.245256
iter  60 value 297.207895
iter  70 value 297.207165
iter  70 value 297.207163
iter  70 value 297.207163
final  value 297.207163 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V13             1.906452     2.040323        2.087097           0.2398104
V7              1.950000     2.016129        2.091935           0.2369668
V15             1.903226     1.975807        2.125806           0.2322275
V39             1.708065     1.814516        1.846774           0.2132701
V1              1.564516     1.637097        1.683871           0.1924171

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.0344355
V15         0.0341105
V19         0.0285569
V6          0.0276680
V39         0.0253018
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V15         0.2425547
V1          0.1911979
V13         0.1520098
V39         0.1370074
V7          0.1213814

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V13
LIME: V1
SHAP: V15

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V13         V1          FALSE     
FEAT_IMP vs SHAP   V13         V15         FALSE     
LIME vs SHAP       V1          V15         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V38             4.841667     4.958333        5.183333           0.1127962
V34             4.591667     4.875000        5.316667           0.1109005
V3              4.391667     4.500000        4.500000           0.1023697
V7              3.325000     3.625000        3.941667           0.0824645
V35             2.983333     3.250000        3.541667           0.0739336

=== LIME Rankings ===


Feature    Importance
--------  -----------
V37         0.0458059
V12         0.0402604
V36         0.0393325
V28         0.0280045
V7          0.0279177
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V38         0.0925817
V28         0.0893629
V36         0.0748105
V30         0.0727649
V22         0.0593761

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V38
LIME: V37
SHAP: V38

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V38         V37         FALSE     
FEAT_IMP vs SHAP   V38         V38         TRUE      
LIME vs SHAP       V37         V38         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V27             1.435979     1.481481        1.507937           0.2654028
V13             1.420106     1.449735        1.489947           0.2597156
V1              1.440212     1.444444        1.458201           0.2587678
V22             1.367196     1.417989        1.442328           0.2540284
V15             1.407407     1.412698        1.438095           0.2530806

=== LIME Rankings ===


Feature    Importance
--------  -----------
V23         0.0800454
V11         0.0682844
V5          0.0674208
V26         0.0597439
V15         0.0478753
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.2118353
V27         0.2024155
V14         0.1760221
V22         0.1661797
V15         0.1598896

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              NA                 0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V27
LIME: V23
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V27         V23         FALSE     
FEAT_IMP vs SHAP   V27         V1          FALSE     
LIME vs SHAP       V23         V1          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===
Error in get_featimp: Lapack routine dgesv: system is exactly singular: U[19,19] = 0 

=== LIME Rankings ===
Error in get_lime: Lapack routine dgesv: system is exactly singular: U[19,19] = 0 
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: Lapack routine dgesv: system is exactly singular: U[19,19] = 0 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 0 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V36            0.0053081    0.0075829       0.0102370           0.0075829
V39            0.0039810    0.0066351       0.0066351           0.0066351
V1             0.0028436    0.0047393       0.0056872           0.0047393
V12            0.0047393    0.0047393       0.0056872           0.0047393
V22            0.0039810    0.0047393       0.0064455           0.0047393
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V36         0.0496236
V39         0.0449890
V1          0.0317435
V12         0.0267548
V22         0.0257681
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V36          0.083740
V1           0.061180
V22          0.050564
V39          0.050468
V27          0.042180

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V36
LIME: V36
SHAP: V36

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V36         V36         TRUE      
FEAT_IMP vs SHAP   V36         V36         TRUE      
LIME vs SHAP       V36         V36         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.3374408
V2                     1            1               1           0.3374408
V3                     1            1               1           0.3374408
V4                     1            1               1           0.3374408
V5                     1            1               1           0.3374408

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1                  0
V10                 0
V11                 0
V12                 0
V13                 0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          V1          TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V14             1.032143     1.049107        1.064286           0.2227488
V10             1.027679     1.035714        1.058036           0.2199052
V11             1.008929     1.031250        1.039286           0.2189573
V38             1.019643     1.031250        1.043750           0.2189573
V5              1.000893     1.026786        1.034821           0.2180095

=== LIME Rankings ===


Feature    Importance
--------  -----------
V5          0.0547032
V11         0.0521263
V15         0.0444798
V1          0.0431698
V27         0.0374624
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.0221882
V27         0.0185268
V22         0.0170569
V15         0.0158149
V39         0.0115903

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V14
LIME: V5
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V14         V5          FALSE     
FEAT_IMP vs SHAP   V14         V1          FALSE     
LIME vs SHAP       V5          V1          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V13             2.050000     2.112069        2.162069           0.2322275
V7              1.703448     1.870690        1.877586           0.2056872
V15             1.627586     1.672414        1.839655           0.1838863
V14             1.444828     1.525862        1.606897           0.1677725
V8              1.451724     1.500000        1.515517           0.1649289

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
There were 13 warnings (use warnings() to see them)
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V13
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V13         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V37             1.068702     1.129771        1.163359           0.1402844
V8              1.045802     1.114504        1.126718           0.1383886
V38             1.106870     1.114504        1.175572           0.1383886
V13             1.027481     1.099237        1.155725           0.1364929
V1              1.001527     1.091603        1.149618           0.1355450

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
There were 13 warnings (use warnings() to see them)
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V37
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V37         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1              1.655474     1.737226        1.837956           0.2255924
V16             1.308029     1.350365        1.382482           0.1753555
V13             1.264234     1.277372        1.321168           0.1658768
V36             1.214598     1.255475        1.284671           0.1630332
V34             1.186861     1.226277        1.258394           0.1592417

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 
There were 12 warnings (use warnings() to see them)

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V20             1.119231     1.173077        1.173077           0.1156398
V25             1.107692     1.125000        1.150000           0.1109005
V40             1.101923     1.125000        1.150000           0.1109005
V9              1.046154     1.096154        1.144231           0.1080569
V38             1.096154     1.096154        1.142308           0.1080569

=== LIME Rankings ===


Feature    Importance
--------  -----------
V40         0.2199813
V5          0.1575650
V11         0.1397532
V21         0.1135246
V3          0.1085923
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1          0.0534667
V22         0.0507333
V37         0.0374000
V14         0.0316667
V10         0.0307333

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V20
LIME: V40
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V20         V40         FALSE     
FEAT_IMP vs SHAP   V20         V1          FALSE     
LIME vs SHAP       V40         V1          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=qsar-biodeg, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V7                1.8496        1.928          1.9984           0.2284360
V13               1.7296        1.824          1.8544           0.2161137
V15               1.4560        1.504          1.6320           0.1781991
V8                1.3504        1.376          1.4032           0.1630332
V6                1.2416        1.280          1.3440           0.1516588

=== LIME Rankings ===


Feature    Importance
--------  -----------
V15         0.0949976
V6          0.0853486
V32         0.0693489
V11         0.0690207
V1          0.0642724
There were 12 warnings (use warnings() to see them)

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V15         0.1565506
V13         0.1436087
V7          0.1335835
V37         0.1170197
V1          0.1074542

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          -1                 3
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V7
LIME: V15
SHAP: V15

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V7          V15         FALSE     
FEAT_IMP vs SHAP   V7          V15         FALSE     
LIME vs SHAP       V15         V15         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: tic-tac-toe
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square         2.013095     2.047619        2.254762           0.3590814
top_left_square              1.444048     1.523810        1.572619           0.2672234
top_right_square             1.475000     1.517857        1.580952           0.2661795
bottom_right_square          1.365476     1.392857        1.398810           0.2442589
bottom_left_square           1.339286     1.375000        1.408333           0.2411273

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.4294271
bottom_right_square      0.0730910
bottom_left_square       0.0674118
top_right_square         0.0621924
top_left_square          0.0472793

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.2595197
bottom_right_square      0.0542560
top_right_square         0.0440782
top_left_square          0.0197159
bottom_left_square       0.0187857

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: middle_middle_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   middle_middle_square   TRUE      
LIME vs SHAP       middle_middle_square   middle_middle_square   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square         1.452778     1.465278        1.623611           0.4405010
top_left_square              1.000000     1.000000        1.000000           0.3006263
top_middle_square            1.000000     1.000000        1.000000           0.3006263
top_right_square             1.000000     1.000000        1.000000           0.3006263
middle_left_square           1.000000     1.000000        1.000000           0.3006263

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.3793209
bottom_left_square       0.0000231
bottom_right_square      0.0000201
middle_left_square       0.0000188
top_right_square         0.0000181

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.2257982
bottom_left_square       0.0000000
bottom_middle_square     0.0000000
bottom_right_square      0.0000000
middle_left_square       0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: middle_middle_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   middle_middle_square   TRUE      
LIME vs SHAP       middle_middle_square   middle_middle_square   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2683            -nan     0.1000    0.0111
     2        1.2510            -nan     0.1000    0.0086
     3        1.2383            -nan     0.1000    0.0071
     4        1.2273            -nan     0.1000    0.0048
     5        1.2227            -nan     0.1000    0.0018
     6        1.2097            -nan     0.1000    0.0047
     7        1.2033            -nan     0.1000    0.0011
     8        1.1954            -nan     0.1000    0.0040
     9        1.1890            -nan     0.1000    0.0016
    10        1.1841            -nan     0.1000    0.0013
    20        1.1339            -nan     0.1000    0.0000
    40        1.0716            -nan     0.1000    0.0007
    50        1.0502            -nan     0.1000    0.0005



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square         1.287660     1.382979        1.442553           0.3392484
top_left_square              1.124255     1.174468        1.199149           0.2881002
top_right_square             1.102979     1.131915        1.135319           0.2776618
bottom_left_square           1.108085     1.131915        1.167660           0.2776618
bottom_right_square          1.088511     1.131915        1.146383           0.2776618

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.2897525
bottom_left_square       0.0961613
top_right_square         0.0825700
top_left_square          0.0784990
bottom_right_square      0.0675215

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.1875072
bottom_left_square       0.0707101
top_right_square         0.0550307
top_left_square          0.0506448
bottom_right_square      0.0460189

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: middle_middle_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   middle_middle_square   TRUE      
LIME vs SHAP       middle_middle_square   middle_middle_square   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square          22.6125      23.5625         24.9125           0.3935282
top_right_square              21.3125      21.6875         23.2000           0.3622129
bottom_right_square           21.5625      21.6875         22.3500           0.3622129
top_left_square               21.1500      21.5625         23.1500           0.3601253
bottom_left_square            21.2500      21.5000         22.4625           0.3590814

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.2761800
middle_right_square      0.2452230
top_right_square         0.2424669
top_left_square          0.2400100
middle_left_square       0.2313608

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
top_middle_square        0.2489556
middle_middle_square     0.2426884
top_right_square         0.2331889
middle_left_square       0.2272655
top_left_square          0.1939047

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: top_middle_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   top_middle_square      FALSE     
LIME vs SHAP       middle_middle_square   top_middle_square      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square          14.9000      15.3750         16.5625           0.2567850
top_right_square               8.8875       9.8125         10.5375           0.1638831
bottom_left_square             9.0625       9.5625          9.7750           0.1597077
bottom_right_square            9.0875       9.1875          9.5000           0.1534447
top_left_square                8.6250       8.8750          9.3750           0.1482255

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.4199021
top_right_square         0.2228825
bottom_right_square      0.1648345
bottom_left_square       0.1545617
top_left_square          0.1377739

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
top_right_square         0.2886231
middle_middle_square     0.2028162
middle_left_square       0.1579626
bottom_right_square      0.1287103
top_left_square          0.1053084

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: top_right_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   top_right_square       FALSE     
LIME vs SHAP       middle_middle_square   top_right_square       FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square         1.197656     1.226562        1.238281           0.3277662
bottom_right_square          1.067969     1.109375        1.151563           0.2964509
top_middle_square            1.089063     1.101562        1.132031           0.2943633
top_left_square              1.043750     1.082031        1.107813           0.2891441
top_right_square             1.048437     1.058594        1.058594           0.2828810

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2   Agreement 
-----------------  ---------------------  ----------  ----------
FEAT_IMP vs SHAP   middle_middle_square   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square          23.7125      24.2500         25.3125           0.4050104
top_left_square               21.0000      21.9375         22.2875           0.3663883
bottom_right_square           20.4875      21.8750         22.3750           0.3653445
bottom_left_square            20.6250      21.2500         21.5625           0.3549061
top_right_square              20.1750      21.0000         21.5125           0.3507307

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.2551921
middle_right_square      0.2541611
top_middle_square        0.2473218
top_right_square         0.2278246
top_left_square          0.2197500

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.2506714
top_middle_square        0.2449663
middle_right_square      0.2331218
bottom_left_square       0.2206457
top_left_square          0.2181923

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: middle_middle_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   middle_middle_square   TRUE      
LIME vs SHAP       middle_middle_square   middle_middle_square   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=multinom ===
Applying data scaling for method: multinom
# weights:  20 (19 variable)
initial  value 664.034999 
iter  10 value 49.359215
iter  20 value 40.201993
iter  30 value 38.444022
iter  40 value 38.428199
final  value 38.428198 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square          22.6125      23.5625         24.9125           0.3935282
top_right_square              21.3125      21.6875         23.2000           0.3622129
bottom_right_square           21.5625      21.6875         22.3500           0.3622129
top_left_square               21.1000      21.5625         23.1375           0.3601253
bottom_left_square            21.2500      21.5000         22.4625           0.3590814

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.2747945
middle_right_square      0.2452253
top_right_square         0.2438041
top_left_square          0.2413291
middle_left_square       0.2320466

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
top_middle_square        0.2497983
middle_middle_square     0.2426885
top_right_square         0.2333510
middle_left_square       0.2276263
top_left_square          0.1936200

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: top_middle_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   top_middle_square      FALSE     
LIME vs SHAP       middle_middle_square   top_middle_square      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square           27.725       28.875          30.250           0.2411273
top_left_square                23.000       23.000          24.525           0.1920668
bottom_right_square            19.125       19.750          19.850           0.1649269
bottom_left_square             18.200       19.125          19.875           0.1597077
top_right_square               17.200       18.625          20.100           0.1555324

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.3350423
bottom_right_square      0.2073130
top_left_square          0.1869354
bottom_left_square       0.1563428
top_right_square         0.1322199

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
top_right_square         0.2342740
top_left_square          0.1691042
middle_middle_square     0.1462365
top_middle_square        0.1286712
bottom_left_square       0.0924594

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP            -1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: top_right_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   top_right_square       FALSE     
LIME vs SHAP       middle_middle_square   top_right_square       FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square         1.673620     1.748466        1.769325           0.2974948
top_right_square             1.332515     1.343558        1.414724           0.2286013
top_left_square              1.331288     1.337423        1.377914           0.2275574
bottom_right_square          1.301840     1.337423        1.401227           0.2275574
bottom_left_square           1.284663     1.325153        1.349693           0.2254697

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     2.4088241
top_left_square          1.0201428
bottom_left_square       1.0156078
top_right_square         0.7584076
top_middle_square        0.7535850

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     1.4369177
top_left_square          1.0025317
top_right_square         0.6357786
bottom_left_square       0.6230711
middle_left_square       0.5307701

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: middle_middle_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   middle_middle_square   TRUE      
LIME vs SHAP       middle_middle_square   middle_middle_square   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===
Error in get_featimp: system is computationally singular: reciprocal condition number = 1.19418e-17 

=== LIME Rankings ===
Error in get_lime: system is computationally singular: reciprocal condition number = 1.19418e-17 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: system is computationally singular: reciprocal condition number = 1.19418e-17 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 0 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 0 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square        0.2208768    0.2254697       0.2448852           0.2254697
top_right_square            0.1160752    0.1263048       0.1407098           0.1263048
bottom_right_square         0.1263048    0.1263048       0.1382046           0.1263048
top_left_square             0.1112735    0.1231733       0.1313152           0.1231733
bottom_left_square          0.1154489    0.1221294       0.1334029           0.1221294
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.3266398
top_right_square         0.1319646
top_left_square          0.1296228
bottom_left_square       0.1143613
bottom_right_square      0.0916514

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
top_left_square           0.153960
middle_middle_square      0.142100
top_right_square          0.137716
top_middle_square         0.094400
bottom_left_square        0.058244

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: top_left_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   top_left_square        FALSE     
LIME vs SHAP       middle_middle_square   top_left_square        FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
top_left_square                     1            1               1           0.3465553
top_middle_square                   1            1               1           0.3465553
top_right_square                    1            1               1           0.3465553
middle_left_square                  1            1               1           0.3465553
middle_middle_square                1            1               1           0.3465553

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
bottom_left_square               0
bottom_middle_square             0
bottom_right_square              0
middle_left_square               0
middle_middle_square             0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: top_left_square
SHAP: bottom_left_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1         Feature_2            Agreement 
-----------------  ----------------  -------------------  ----------
FEAT_IMP vs SHAP   top_left_square   bottom_left_square   FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square        1.2156584    1.2419929       1.3010676           0.3643006
top_right_square            0.9843416    0.9964413       1.0113879           0.2922756
top_left_square             0.9537367    0.9893238       1.0128114           0.2901879
bottom_right_square         0.9594306    0.9822064       1.0049822           0.2881002
bottom_left_square          0.9352313    0.9679715       0.9928826           0.2839248

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.1474984
top_right_square         0.0473282
top_left_square          0.0459942
bottom_left_square       0.0418147
top_middle_square        0.0355945

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.0916122
top_right_square         0.0294917
bottom_left_square       0.0291240
top_left_square          0.0254537
top_middle_square        0.0227174

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: middle_middle_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   middle_middle_square   TRUE      
LIME vs SHAP       middle_middle_square   middle_middle_square   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square          22.6125      23.5625         24.9125           0.3935282
top_right_square              21.3125      21.6875         23.2000           0.3622129
bottom_right_square           21.5625      21.6875         22.3500           0.3622129
top_left_square               21.1500      21.5625         23.1500           0.3601253
bottom_left_square            21.2500      21.5000         22.4625           0.3590814

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2   Agreement 
-----------------  ---------------------  ----------  ----------
FEAT_IMP vs SHAP   middle_middle_square   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square         2.322727     2.371212        2.424242           0.3267223
top_left_square              1.600000     1.636364        1.684848           0.2254697
top_right_square             1.590909     1.636364        1.710606           0.2254697
bottom_left_square           1.562121     1.636364        1.642424           0.2254697
bottom_right_square          1.565152     1.621212        1.665151           0.2233820

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2   Agreement 
-----------------  ---------------------  ----------  ----------
FEAT_IMP vs SHAP   middle_middle_square   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square         1.544601     1.615023        1.631925           0.3590814
bottom_right_square          1.203756     1.225352        1.234742           0.2724426
top_right_square             1.178404     1.206573        1.218779           0.2682672
bottom_left_square           1.171831     1.192488        1.228169           0.2651357
top_left_square              1.153991     1.187793        1.213145           0.2640919

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2   Agreement 
-----------------  ---------------------  ----------  ----------
FEAT_IMP vs SHAP   middle_middle_square   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square        0.2022965    0.2192067       0.2240084           0.2192067
top_left_square             0.1409186    0.1576200       0.1609603           0.1576200
top_right_square            0.1371608    0.1565762       0.1617954           0.1565762
bottom_left_square          0.1432150    0.1524008       0.1605428           0.1524008
bottom_right_square         0.1463466    0.1503132       0.1640919           0.1503132
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.3077423
top_left_square          0.1650611
top_right_square         0.1629038
bottom_left_square       0.1311966
bottom_right_square      0.1001446

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
top_left_square          0.1976310
top_right_square         0.1620556
middle_middle_square     0.1271048
top_middle_square        0.0855786
bottom_left_square       0.0547222

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 3
FEAT_IMP vs SHAP        -0.5                 3
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: top_left_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   top_left_square        FALSE     
LIME vs SHAP       middle_middle_square   top_left_square        FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=tic-tac-toe, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature                 importance.05   importance   importance.95   permutation.error
---------------------  --------------  -----------  --------------  ------------------
middle_middle_square          22.6125      23.5625         24.9125           0.3935282
bottom_right_square           21.4500      21.6250         22.1875           0.3611691
top_left_square               21.0875      21.5625         23.1375           0.3601253
top_right_square              21.2500      21.5625         23.1875           0.3601253
bottom_left_square            21.0750      21.4375         22.4000           0.3580376

=== LIME Rankings ===


Feature                 Importance
---------------------  -----------
middle_middle_square     0.2782853
middle_right_square      0.2441640
top_right_square         0.2417920
top_left_square          0.2394894
middle_left_square       0.2293058

=== SHAP (IML Shapley) Rankings ===


Feature                 Importance
---------------------  -----------
top_middle_square        0.2476810
middle_middle_square     0.2433110
top_right_square         0.2330666
middle_left_square       0.2266264
top_left_square          0.1946142

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: middle_middle_square
LIME: middle_middle_square
SHAP: top_middle_square

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1              Feature_2              Agreement 
-----------------  ---------------------  ---------------------  ----------
FEAT_IMP vs LIME   middle_middle_square   middle_middle_square   TRUE      
FEAT_IMP vs SHAP   middle_middle_square   top_middle_square      FALSE     
LIME vs SHAP       middle_middle_square   top_middle_square      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


Dataset: vowel
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1        16.900000    18.000000       18.133333           0.1090909
Feature_3         5.766667     6.333333        7.466667           0.0383838
Feature_2         4.566667     5.000000        5.133333           0.0303030
Feature_0         3.400000     3.666667        4.000000           0.0222222
Feature_8         2.166667     2.500000        2.633333           0.0151515

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.2290538
Feature_3     0.0813431
Feature_2     0.0530054
Feature_0     0.0127559
Feature_5     0.0125689

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.0718077
Feature_3     0.0074286
Feature_2     0.0073569
Feature_0     0.0060000
Feature_8     0.0020000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1         2.804651            3        3.046512           0.1303030
Feature_0         1.000000            1        1.000000           0.0434343
Feature_2         1.000000            1        1.000000           0.0434343
Feature_3         1.000000            1        1.000000           0.0434343
Feature_4         1.000000            1        1.000000           0.0434343

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.3191713
Feature_4     0.0076403
Feature_5     0.0062629
Feature_3     0.0059049
Feature_8     0.0044849

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.0952629
Feature_0     0.0000000
Feature_2     0.0000000
Feature_3     0.0000000
Feature_4     0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.5155            -nan     0.1000    0.0520
     2        0.4587            -nan     0.1000    0.0277
     3        0.4323            -nan     0.1000    0.0166
     4        0.4027            -nan     0.1000    0.0134
     5        0.3777            -nan     0.1000    0.0129
     6        0.3566            -nan     0.1000    0.0107
     7        0.3404            -nan     0.1000    0.0072
     8        0.3311            -nan     0.1000    0.0051
     9        0.3194            -nan     0.1000    0.0053
    10        0.3088            -nan     0.1000    0.0048
    20        0.2150            -nan     0.1000    0.0015
    40        0.1374            -nan     0.1000    0.0010
    50        0.1177            -nan     0.1000    0.0006



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1        11.090909    11.181818       11.490909           0.1242424
Feature_3         2.909091     3.545454        3.781818           0.0393939
Feature_2         2.181818     2.363636        2.527273           0.0262626
Feature_5         1.109091     1.181818        1.181818           0.0131313
Feature_7         1.090909     1.181818        1.254546           0.0131313

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.3536881
Feature_3     0.0546409
Feature_2     0.0303869
Feature_5     0.0119526
Feature_0     0.0089770

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_3     0.0436984
Feature_1     0.0423980
Feature_2     0.0144364
Feature_5     0.0011392
Feature_7     0.0009003

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_3

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_3   FALSE     
LIME vs SHAP       Feature_1   Feature_3   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1           13.025       13.750          14.525           0.1111111
Feature_2            3.300        3.625           3.950           0.0292929
Feature_3            3.250        3.625           3.850           0.0292929
Feature_9            2.925        3.125           4.025           0.0252525
Feature_7            1.400        1.625           1.725           0.0131313

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.3311209
Feature_9     0.0972841
Feature_3     0.0769212
Feature_2     0.0729573
Feature_7     0.0344371

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.1262455
Feature_3     0.0615892
Feature_9     0.0505183
Feature_2     0.0171059
Feature_8     0.0085345

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1            32.50        34.75           34.95           0.1404040
Feature_0             5.65         7.25            7.85           0.0292929
Feature_2             4.05         4.25            4.70           0.0171717
Feature_8             3.30         4.00            4.20           0.0161616
Feature_3             3.35         3.75            4.00           0.0151515

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.4276468
Feature_0     0.0175252
Feature_4     0.0139642
Feature_5     0.0132354
Feature_3     0.0117617

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.1885388
Feature_0     0.0642214
Feature_2     0.0039911
Feature_3     0.0039911
Feature_8     0.0018137

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_0                1            1               1           0.0909091
Feature_1                1            1               1           0.0909091
Feature_2                1            1               1           0.0909091
Feature_3                1            1               1           0.0909091
Feature_4                1            1               1           0.0909091

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Feature_0
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Feature_0   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1         4.516129     4.580645        4.832258           0.1434343
Feature_0         1.135484     1.193548        1.277419           0.0373737
Feature_6         1.045161     1.193548        1.225807           0.0373737
Feature_3         1.064516     1.161290        1.277419           0.0363636
Feature_4         1.161290     1.161290        1.193548           0.0363636

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.4036994
Feature_0     0.0351974
Feature_3     0.0277881
Feature_6     0.0219177
Feature_7     0.0191382

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.2063491
Feature_3     0.0752895
Feature_5     0.0213680
Feature_9     0.0178114
Feature_0     0.0166429

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=multinom ===
Applying data scaling for method: multinom
# weights:  12 (11 variable)
initial  value 686.215709 
iter  10 value 110.577210
iter  20 value 68.612804
iter  30 value 68.332117
final  value 68.331776 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1         7.941667     8.208333        8.900000           0.1989899
Feature_0         3.291667     3.458333        3.575000           0.0838384
Feature_3         1.958333     2.083333        2.225000           0.0505051
Feature_5         1.625000     1.875000        2.075000           0.0454545
Feature_4         1.641667     1.750000        1.908333           0.0424242

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.4665036
Feature_0     0.0791344
Feature_5     0.0636534
Feature_3     0.0470657
Feature_4     0.0355114

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.2409452
Feature_5     0.0635946
Feature_3     0.0559791
Feature_0     0.0442854
Feature_9     0.0268496

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1             90.6           99            99.8           0.1000000
Feature_3             58.4           61            62.0           0.0616162
Feature_4             28.4           34            35.8           0.0343434
Feature_2             11.8           15            17.8           0.0151515
Feature_6              8.6           14            19.0           0.0141414

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.2149612
Feature_3     0.0774028
Feature_0     0.0392676
Feature_4     0.0359295
Feature_6     0.0345413

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.1353333
Feature_3     0.0685000
Feature_4     0.0491667
Feature_6     0.0076667
Feature_0     0.0055000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_0                1            1               1           0.0909091
Feature_1                1            1               1           0.0909091
Feature_2                1            1               1           0.0909091
Feature_3                1            1               1           0.0909091
Feature_4                1            1               1           0.0909091

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_5      19.45302
Feature_6      18.85728
Feature_1      18.05070
Feature_3      12.81206
Feature_7      11.12660

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_5     22.598341
Feature_3     12.901423
Feature_1     12.007896
Feature_4      8.490466
Feature_9      6.295016

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_0
LIME: Feature_5
SHAP: Feature_5

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_0   Feature_5   FALSE     
FEAT_IMP vs SHAP   Feature_0   Feature_5   FALSE     
LIME vs SHAP       Feature_5   Feature_5   TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1            19.50        20.00           22.10           0.0808081
Feature_0            16.65        17.75           19.45           0.0717172
Feature_2            15.30        15.75           16.70           0.0636364
Feature_4            13.45        14.50           14.50           0.0585859
Feature_9            12.45        14.25           15.45           0.0575758

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.0090111
Feature_3     0.0057984
Feature_6     0.0050231
Feature_4     0.0036635
Feature_2     0.0029019

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_0     0.0990272
Feature_1     0.0819468
Feature_3     0.0561365
Feature_5     0.0471204
Feature_2     0.0413186

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_0

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_0   FALSE     
LIME vs SHAP       Feature_1   Feature_0   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1        0.1115152    0.1151515       0.1177778           0.1151515
Feature_2        0.0123232    0.0131313       0.0141414           0.0131313
Feature_3        0.0082828    0.0111111       0.0127273           0.0111111
Feature_6        0.0020202    0.0020202       0.0020202           0.0020202
Feature_4        0.0000000    0.0010101       0.0020202           0.0010101
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.2476782
Feature_3     0.0326427
Feature_5     0.0324791
Feature_4     0.0268361
Feature_7     0.0263583

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1      0.072964
Feature_3      0.052856
Feature_5      0.046124
Feature_9      0.023820
Feature_2      0.013272

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_0                1            1               1           0.0909091
Feature_1                1            1               1           0.0909091
Feature_2                1            1               1           0.0909091
Feature_3                1            1               1           0.0909091
Feature_4                1            1               1           0.0909091

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_0             0
Feature_1             0
Feature_2             0
Feature_3             0
Feature_4             0

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP           1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_0
SHAP: Feature_0

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Feature_0   Feature_0   TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1         1.186667     1.200000        1.210667           0.0909091
Feature_4         1.122667     1.160000        1.173333           0.0878788
Feature_5         1.112000     1.160000        1.160000           0.0878788
Feature_3         1.106667     1.120000        1.141333           0.0848485
Feature_7         1.106667     1.106667        1.144000           0.0838384

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.0487360
Feature_5     0.0353682
Feature_3     0.0270462
Feature_4     0.0226481
Feature_8     0.0170828

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.0243789
Feature_5     0.0240558
Feature_3     0.0228877
Feature_4     0.0176828
Feature_8     0.0109314

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1         7.285714     7.333333        7.771429           0.1555556
Feature_3         2.200000     2.571429        2.723810           0.0545455
Feature_0         2.019048     2.142857        2.342857           0.0454545
Feature_4         1.533333     1.666667        1.800000           0.0353535
Feature_6         1.447619     1.666667        1.714286           0.0353535

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Feature_1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Feature_1   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1         3.063158     3.368421        3.568421           0.0646465
Feature_5         2.000000     2.210526        2.463158           0.0424242
Feature_7         1.578947     1.631579        1.842105           0.0313131
Feature_3         1.484211     1.578947        1.842105           0.0303030
Feature_0         1.389474     1.526316        1.621053           0.0292929

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Feature_1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Feature_1   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1933 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1        11.472727    11.909091       12.309091           0.1323232
Feature_0         2.418182     3.090909        3.454546           0.0343434
Feature_2         2.272727     2.363636        2.600000           0.0262626
Feature_9         2.018182     2.181818        2.254545           0.0242424
Feature_3         1.727273     1.818182        1.890909           0.0202020

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Feature_1
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Feature_1   NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_5             35.4           38            41.2           0.0383838
Feature_1             24.2           27            28.0           0.0272727
Feature_2             16.0           19            20.8           0.0191919
Feature_9             12.0           15            16.6           0.0151515
Feature_7             10.4           14            16.8           0.0141414

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.0577693
Feature_5     0.0469868
Feature_3     0.0236763
Feature_6     0.0171691
Feature_4     0.0157750

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_5     0.0716667
Feature_3     0.0694667
Feature_1     0.0520000
Feature_9     0.0423333
Feature_0     0.0220000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Feature_5
LIME: Feature_1
SHAP: Feature_5

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_5   Feature_1   FALSE     
FEAT_IMP vs SHAP   Feature_5   Feature_5   TRUE      
LIME vs SHAP       Feature_1   Feature_5   FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=vowel, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature      importance.05   importance   importance.95   permutation.error
----------  --------------  -----------  --------------  ------------------
Feature_1         6.577778     6.888889        7.311111           0.1878788
Feature_0         2.562963     2.740741        2.888889           0.0747475
Feature_3         1.711111     1.925926        2.000000           0.0525253
Feature_5         1.407407     1.518519        1.674074           0.0414141
Feature_4         1.303704     1.370370        1.466667           0.0373737

=== LIME Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.4564066
Feature_0     0.0739934
Feature_5     0.0530251
Feature_3     0.0476695
Feature_4     0.0314111

=== SHAP (IML Shapley) Rankings ===


Feature      Importance
----------  -----------
Feature_1     0.2309569
Feature_3     0.0606481
Feature_5     0.0540928
Feature_0     0.0380763
Feature_9     0.0221845

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Feature_1
LIME: Feature_1
SHAP: Feature_1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Feature_1   Feature_1   TRUE      
FEAT_IMP vs SHAP   Feature_1   Feature_1   TRUE      
LIME vs SHAP       Feature_1   Feature_1   TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: waveform-5000
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.632545     1.684284        1.700695              0.2422
x12             1.389152     1.406120        1.421697              0.2022
x10             1.329346     1.365786        1.371627              0.1964
x5              1.308206     1.335188        1.355216              0.1920
x16             1.081780     1.093185        1.104311              0.1572

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.2176925
x10         0.1420170
x12         0.1109631
x5          0.0681452
x9          0.0578510

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.1676434
x10         0.1509379
x9          0.0650846
x5          0.0633012
x12         0.0622787

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.916254     1.941696        1.964664              0.4396
x1              1.000000     1.000000        1.000000              0.2264
x2              1.000000     1.000000        1.000000              0.2264
x3              1.000000     1.000000        1.000000              0.2264
x4              1.000000     1.000000        1.000000              0.2264

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.6112948
x30         0.0080389
x27         0.0070105
x6          0.0067946
x23         0.0066505

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.4465836
x1          0.0000000
x10         0.0000000
x12         0.0000000
x13         0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2254            -nan     0.1000    0.0267
     2        1.1787            -nan     0.1000    0.0236
     3        1.1375            -nan     0.1000    0.0187
     4        1.1044            -nan     0.1000    0.0166
     5        1.0777            -nan     0.1000    0.0126
     6        1.0506            -nan     0.1000    0.0126
     7        1.0267            -nan     0.1000    0.0114
     8        1.0078            -nan     0.1000    0.0093
     9        0.9888            -nan     0.1000    0.0090
    10        0.9745            -nan     0.1000    0.0063
    20        0.8638            -nan     0.1000    0.0033
    40        0.7489            -nan     0.1000    0.0019
    50        0.7123            -nan     0.1000    0.0009



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.705587     1.712290        1.763129              0.2452
x10             1.296927     1.304469        1.355307              0.1868
x12             1.268436     1.283520        1.305307              0.1838
x5              1.133240     1.156425        1.174860              0.1656
x6              1.059497     1.071229        1.080168              0.1534

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.2184466
x10         0.1226518
x12         0.1003103
x5          0.0586913
x17         0.0300864

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.1651230
x10         0.0944707
x12         0.0849888
x5          0.0380450
x6          0.0253016

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.691075     1.732240        1.812386              0.1902
x5              1.347905     1.362477        1.390528              0.1496
x10             1.272860     1.304189        1.316576              0.1432
x12             1.268488     1.304189        1.332605              0.1432
x9              1.253552     1.293260        1.302368              0.1420

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.2406124
x10         0.1591651
x9          0.1113752
x12         0.1105033
x5          0.0901453

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.1961990
x9          0.1493848
x10         0.1384603
x16         0.0813302
x7          0.0798867

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             2.197414     2.217672        2.275431              0.2058
x10             1.658621     1.756466        1.766379              0.1630
x12             1.453017     1.480603        1.502155              0.1374
x5              1.267672     1.282328        1.307328              0.1190
x15             1.202155     1.230603        1.245259              0.1142

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.3533994
x10         0.1474501
x12         0.1172445
x5          0.0571449
x15         0.0505613

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.1963012
x10         0.1600718
x17         0.0946921
x6          0.0833489
x12         0.0789439

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.233237     1.250000        1.295087              0.1730
x12             1.238439     1.250000        1.277457              0.1730
x10             1.178324     1.183526        1.221098              0.1638
x5              1.112717     1.141619        1.169364              0.1580
x9              1.102023     1.128613        1.131214              0.1562

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: x11
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   x11         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.290399     1.338257        1.350369              0.1812
x10             1.289513     1.302806        1.344165              0.1764
x6              1.227770     1.237814        1.267651              0.1676
x9              1.210044     1.228951        1.272378              0.1664
x5              1.153619     1.192024        1.214771              0.1614

=== LIME Rankings ===


Feature    Importance
--------  -----------
x10         0.1588174
x11         0.1496562
x9          0.1158324
x6          0.1093501
x12         0.0842994

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x10         0.1407700
x9          0.1327433
x11         0.1292677
x6          0.0773278
x17         0.0651948

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP        -1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x10
SHAP: x10

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x10         FALSE     
FEAT_IMP vs SHAP   x11         x10         FALSE     
LIME vs SHAP       x10         x10         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=multinom ===
Applying data scaling for method: multinom
# weights:  42 (41 variable)
initial  value 3465.735903 
iter  10 value 1749.316333
iter  20 value 1542.918907
iter  30 value 1522.294696
iter  40 value 1516.398123
iter  50 value 1516.107915
final  value 1516.107371 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.393093     1.408633        1.441151              0.1958
x10             1.278273     1.290647        1.294101              0.1794
x12             1.229065     1.257554        1.265611              0.1748
x5              1.213237     1.241727        1.244029              0.1726
x6              1.228201     1.237410        1.265899              0.1720

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.1821180
x10         0.1609391
x12         0.1122277
x9          0.1066539
x6          0.1030342

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.1273078
x10         0.1234261
x9          0.0947248
x6          0.0788757
x16         0.0618238

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x12             1.672921     1.699360        1.779105              0.1594
x11             1.637100     1.654584        1.691258              0.1552
x10             1.537313     1.609808        1.630704              0.1510
x5              1.376972     1.405117        1.457996              0.1318
x16             1.267804     1.328358        1.355224              0.1246

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.1880163
x12         0.1102243
x10         0.1083058
x16         0.0844474
x17         0.0686397

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.1404392
x10         0.1099741
x12         0.1046950
x9          0.0991647
x6          0.0800608

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP        -0.5                 3
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x12
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x12         x11         FALSE     
FEAT_IMP vs SHAP   x12         x11         FALSE     
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x12             1.002990     1.006579        1.006579              0.3366
x11             1.004904     1.005383        1.007536              0.3362
x10             1.000718     1.004785        1.005263              0.3360
x4              1.000598     1.003588        1.004665              0.3356
x5              1.002392     1.003588        1.004546              0.3356

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.8271679
x10         0.7354736
x34         0.6483157
x20         0.6243909
x23         0.5703387

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11          6.240815
x10          4.418958
x29          4.416790
x20          3.764503
x30          3.554575

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x12
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x12         x11         FALSE     
FEAT_IMP vs SHAP   x12         x11         FALSE     
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.260000     1.301613        1.364839              0.1614
x10             1.174193     1.211290        1.227097              0.1502
x9              1.138710     1.167742        1.186452              0.1448
x6              1.149355     1.153226        1.189677              0.1430
x7              1.105161     1.133871        1.148710              0.1406

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.1235614
x10         0.1153745
x9          0.0802084
x12         0.0735442
x6          0.0694448

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.1444579
x10         0.1281031
x9          0.0748886
x16         0.0559964
x17         0.0527129

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11              0.07824       0.0804         0.08316              0.0804
x10              0.02788       0.0300         0.03488              0.0300
x12              0.02120       0.0234         0.02552              0.0234
x9               0.00512       0.0064         0.00688              0.0064
x5               0.00520       0.0062         0.00772              0.0062
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.1310232
x10         0.0948938
x12         0.0707855
x9          0.0444118
x5          0.0328435

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11          0.153600
x10          0.107392
x9           0.050284
x12          0.045556
x5           0.042532

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x1                     1            1               1              0.3384
x2                     1            1               1              0.3384
x3                     1            1               1              0.3384
x4                     1            1               1              0.3384
x5                     1            1               1              0.3384

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x1                  0
x10                 0
x11                 0
x12                 0
x13                 0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: x1
SHAP: x1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   x1          x1          TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.277929     1.291553        1.332698              0.1896
x10             1.227793     1.264305        1.295368              0.1856
x12             1.152316     1.179836        1.190191              0.1732
x9              1.114441     1.126703        1.133242              0.1654
x17             1.081199     1.091281        1.125886              0.1602

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.0727074
x10         0.0672802
x12         0.0531798
x9          0.0369243
x6          0.0271704

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.0450922
x10         0.0375941
x9          0.0236241
x12         0.0224226
x6          0.0167630

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.329630     1.354701        1.387180              0.1902
x10             1.234473     1.260684        1.272650              0.1770
x12             1.159829     1.193732        1.200855              0.1676
x9              1.132764     1.163818        1.182336              0.1634
x6              1.154986     1.160969        1.201994              0.1630

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: x11
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   x11         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.489041     1.506849        1.559361              0.1320
x10             1.303653     1.360731        1.366210              0.1192
x9              1.227854     1.253425        1.301370              0.1098
x12             1.226941     1.232877        1.260274              0.1080
x5              1.176256     1.191781        1.242922              0.1044

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: x11
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   x11         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1998 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x12             1.330263     1.355263        1.418640              0.2472
x6              1.264693     1.286184        1.291667              0.2346
x17             1.181579     1.199561        1.210965              0.2188
x11             1.184211     1.196272        1.220175              0.2182
x10             1.171711     1.183114        1.195395              0.2158

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: x12
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   x12         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.237728     1.286004        1.310750              0.1268
x10             1.206085     1.223124        1.251927              0.1206
x12             1.169574     1.184584        1.218256              0.1168
x9              1.096146     1.129817        1.148884              0.1114
x13             1.084787     1.103448        1.117647              0.1088

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.1571969
x10         0.1480286
x12         0.1142862
x9          0.0895377
x17         0.0611153

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.1086667
x10         0.0809619
x12         0.0574667
x9          0.0534667
x5          0.0424000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=waveform-5000, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
x11             1.394236     1.410663        1.444380              0.1958
x10             1.281268     1.292507        1.295101              0.1794
x12             1.231700     1.260807        1.266571              0.1750
x5              1.216138     1.240634        1.246109              0.1722
x6              1.229107     1.239193        1.266859              0.1720

=== LIME Rankings ===


Feature    Importance
--------  -----------
x11         0.1822864
x10         0.1610242
x12         0.1122520
x9          0.1065501
x6          0.1027484

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
x11         0.1273718
x10         0.1233433
x9          0.0945163
x6          0.0786042
x16         0.0615861

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: x11
LIME: x11
SHAP: x11

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   x11         x11         TRUE      
FEAT_IMP vs SHAP   x11         x11         TRUE      
LIME vs SHAP       x11         x11         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: wdbc
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V28             5.488889     5.925926        6.229630           0.2811951
V24             4.762963     4.925926        5.251852           0.2337434
V17             1.066667     1.185185        1.185185           0.0562390
V1              1.000000     1.000000        1.000000           0.0474517
V2              1.000000     1.000000        1.000000           0.0474517

=== LIME Rankings ===


Feature    Importance
--------  -----------
V24         0.4002942
V28         0.2507537
V14         0.0935644
V8          0.0891727
V17         0.0612811

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V28         0.2417247
V24         0.2028840
V8          0.1511240
V14         0.0474660
V17         0.0035778

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V28
LIME: V24
SHAP: V28

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V28         V24         FALSE     
FEAT_IMP vs SHAP   V28         V28         TRUE      
LIME vs SHAP       V24         V28         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V24             5.565217      5.73913        5.817391           0.4639719
V1              1.000000      1.00000        1.000000           0.0808436
V2              1.000000      1.00000        1.000000           0.0808436
V3              1.000000      1.00000        1.000000           0.0808436
V4              1.000000      1.00000        1.000000           0.0808436

=== LIME Rankings ===


Feature    Importance
--------  -----------
V24         0.7545862
V21         0.0131808
V20         0.0122786
V5          0.0108099
V8          0.0105182

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V24         0.6129907
V1          0.0000000
V10         0.0000000
V11         0.0000000
V12         0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP              NA                 1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V24
LIME: V24
SHAP: V24

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V24         V24         TRUE      
FEAT_IMP vs SHAP   V24         V24         TRUE      
LIME vs SHAP       V24         V24         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.1914            -nan     0.1000    0.0633
     2        1.0786            -nan     0.1000    0.0540
     3        0.9835            -nan     0.1000    0.0417
     4        0.9023            -nan     0.1000    0.0364
     5        0.8332            -nan     0.1000    0.0335
     6        0.7736            -nan     0.1000    0.0290
     7        0.7197            -nan     0.1000    0.0260
     8        0.6702            -nan     0.1000    0.0211
     9        0.6274            -nan     0.1000    0.0200
    10        0.5916            -nan     0.1000    0.0159
    20        0.3768            -nan     0.1000    0.0069
    40        0.2293            -nan     0.1000    0.0022
    50        0.1986            -nan     0.1000    0.0003



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V24             1.763636     2.090909        2.309091           0.0404218
V28             1.745454     2.000000        2.327273           0.0386643
V22             1.545454     1.909091        2.072727           0.0369069
V27             1.563636     1.818182        1.890909           0.0351494
V8              1.636364     1.727273        1.727273           0.0333919

=== LIME Rankings ===


Feature    Importance
--------  -----------
V28         0.2379395
V24         0.2065570
V23         0.1829023
V8          0.1301128
V27         0.0885848

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V28         0.1318185
V24         0.1298936
V23         0.1196671
V8          0.0963588
V27         0.0489643

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V24
LIME: V28
SHAP: V28

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V24         V28         FALSE     
FEAT_IMP vs SHAP   V24         V28         FALSE     
LIME vs SHAP       V28         V28         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V24            22.114286    24.428571       24.885714           0.3005272
V21            15.371429    16.857143       17.314286           0.2073814
V8             11.228571    12.142857       12.628571           0.1493849
V4              6.342857     7.142857        8.057143           0.0878735
V2              4.085714     5.000000        5.114286           0.0615114

=== LIME Rankings ===


Feature    Importance
--------  -----------
V21         0.3933756
V24         0.3910183
V4          0.1902993
V8          0.1285390
V28         0.1216795

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V24         0.2324030
V21         0.2030667
V8          0.1169907
V28         0.0834655
V29         0.0423952

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          -1                 2
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V24
LIME: V21
SHAP: V24

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V24         V21         FALSE     
FEAT_IMP vs SHAP   V24         V24         TRUE      
LIME vs SHAP       V21         V24         FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V28            12.933333    14.166667       14.833333           0.1493849
V21             9.500000    10.666667       11.500000           0.1124780
V8              6.033333     6.166667        6.666667           0.0650264
V23             5.433333     6.000000        7.633333           0.0632689
V2              3.533333     3.666667        4.266667           0.0386643

=== LIME Rankings ===


Feature    Importance
--------  -----------
V28         0.5969770
V8          0.1856686
V23         0.1731167
V21         0.1438227
V18         0.0987791

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V28         0.2919003
V23         0.1914797
V8          0.1605619
V21         0.0631136
V18         0.0512798

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         1.0                 2
FEAT_IMP vs SHAP         1.0                 2
LIME vs SHAP             0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V28
LIME: V28
SHAP: V28

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V28         V28         TRUE      
FEAT_IMP vs SHAP   V28         V28         TRUE      
LIME vs SHAP       V28         V28         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V2                 1.104         1.24           1.304           0.0544815
V22                1.088         1.16           1.272           0.0509666
V1                 1.008         1.12           1.152           0.0492091
V4                 1.040         1.12           1.152           0.0492091
V24                1.080         1.12           1.184           0.0492091

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V2
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V2          NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V22             4.833333     5.333333        6.300000           0.0562390
V29             3.000000     3.166667        3.300000           0.0333919
V14             2.200000     2.833333        2.966667           0.0298770
V27             2.400000     2.833333        3.333333           0.0298770
V11             2.366667     2.666667        2.966667           0.0281195

=== LIME Rankings ===


Feature    Importance
--------  -----------
V11         0.2425748
V14         0.2219009
V20         0.2010047
V24         0.1608675
V29         0.1352588

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V29         0.0874249
V24         0.0614335
V11         0.0604869
V21         0.0585103
V14         0.0513598

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V22
LIME: V11
SHAP: V29

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V22         V11         FALSE     
FEAT_IMP vs SHAP   V22         V29         FALSE     
LIME vs SHAP       V11         V29         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=multinom ===
Applying data scaling for method: multinom
# weights:  32 (31 variable)
initial  value 394.400746 
iter  10 value 53.457191
iter  20 value 27.646283
iter  30 value 18.866236
iter  40 value 16.196943
iter  50 value 15.336033
iter  60 value 14.793582
iter  70 value 14.340637
iter  80 value 13.847773
iter  90 value 13.481332
iter 100 value 12.881769
final  value 12.881769 
stopped after 100 iterations


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V4              62.00000     63.00000        65.13333           0.3321617
V23             33.80000     34.66667        39.00000           0.1827768
V1              26.40000     27.33333        32.20000           0.1441125
V7              23.00000     25.66667        26.93333           0.1353251
V24             21.86667     25.00000        27.13333           0.1318102

=== LIME Rankings ===


Feature    Importance
--------  -----------
V1          0.3599042
V4          0.3011099
V11         0.1924023
V20         0.1877050
V13         0.1846098

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V4          0.2814164
V1          0.2682749
V23         0.1401433
V6          0.1204133
V7          0.1049245

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP            -1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V4
LIME: V1
SHAP: V4

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V4          V1          FALSE     
FEAT_IMP vs SHAP   V4          V4          TRUE      
LIME vs SHAP       V1          V4          FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V28                19.25        20.25           21.30           0.1423550
V14                12.55        13.00           13.80           0.0913884
V24                 9.10        10.25           11.65           0.0720562
V21                 7.90         9.50            9.95           0.0667838
V22                 8.60         9.50            9.75           0.0667838

=== LIME Rankings ===


Feature    Importance
--------  -----------
V28         0.3388892
V24         0.2148269
V14         0.1814959
V22         0.1737786
V7          0.1485764

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V28         0.2690028
V24         0.1640436
V14         0.1128588
V7          0.1064630
V22         0.0523538

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V28
LIME: V28
SHAP: V28

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V28         V28         TRUE      
FEAT_IMP vs SHAP   V28         V28         TRUE      
LIME vs SHAP       V28         V28         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V22             1.626667     1.800000        1.986667           0.0474517
V23             1.480000     1.600000        1.773333           0.0421793
V24             1.306667     1.533333        1.586667           0.0404218
V8              1.413333     1.466667        1.586667           0.0386643
V20             1.400000     1.466667        1.520000           0.0386643

=== LIME Rankings ===


Feature    Importance
--------  -----------
V17         0.2270507
V20         0.2264099
V1          0.1501016
V15         0.1462630
V4          0.1415340

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V4           1.517594
V24          1.278767
V1           1.272683
V3           1.242855
V21          1.128696

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V22
LIME: V17
SHAP: V4

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V22         V17         FALSE     
FEAT_IMP vs SHAP   V22         V4          FALSE     
LIME vs SHAP       V17         V4          FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1              22.48000     22.66667        22.77333           0.5975395
V3              21.88000     22.06667        22.24000           0.5817223
V21             21.54667     21.73333        22.02667           0.5729350
V24             21.01333     21.33333        21.65333           0.5623902
V4              20.94667     21.13333        21.57333           0.5571178

=== LIME Rankings ===
Error in get_lime: missing value where TRUE/FALSE needed 

=== SHAP (IML Shapley) Rankings ===
Error in get_shap: no rows to aggregate 

=== Top-3 Spearman ===
Not enough valid rankings (need at least 2, got 1 )

=== Top-1 Spearman ===
Not enough valid rankings (need at least 2, got 1 )

=== Top-1 Feature Agreement Count ===
Not enough valid rankings (need at least 2, got 1 )

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V11            0.0017575    0.0017575       0.0017575           0.0017575
V14            0.0000000    0.0017575       0.0017575           0.0017575
V22            0.0000000    0.0017575       0.0017575           0.0017575
V28            0.0003515    0.0017575       0.0017575           0.0017575
V1             0.0000000    0.0000000       0.0000000           0.0000000
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature    Importance
--------  -----------
V28         0.1107867
V24         0.1039369
V21         0.0894336
V23         0.0803662
V8          0.0454863

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V28          0.098912
V24          0.093412
V23          0.078964
V21          0.071868
V8           0.060440

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 0
FEAT_IMP vs SHAP          NA                 0
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V11
LIME: V28
SHAP: V28

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V11         V28         FALSE     
FEAT_IMP vs SHAP   V11         V28         FALSE     
LIME vs SHAP       V28         V28         TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V1                     1            1               1           0.3725835
V2                     1            1               1           0.3725835
V3                     1            1               1           0.3725835
V4                     1            1               1           0.3725835
V5                     1            1               1           0.3725835

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V1                  0
V10                 0
V11                 0
V12                 0
V13                 0

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: V1
SHAP: V1

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V1          V1          TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V21            1.0878049     1.146341        1.190244           0.0826011
V3             1.0585366     1.121951        1.141463           0.0808436
V23            1.0000000     1.121951        1.146341           0.0808436
V2             1.0146341     1.073171        1.097561           0.0773286
V4             0.9804878     1.073171        1.136585           0.0773286

=== LIME Rankings ===


Feature    Importance
--------  -----------
V11         0.0519077
V13         0.0507393
V14         0.0491798
V24         0.0393247
V4          0.0387175

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V28         0.0227319
V8          0.0219836
V23         0.0182510
V7          0.0180204
V21         0.0179432

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V21
LIME: V11
SHAP: V28

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V21         V11         FALSE     
FEAT_IMP vs SHAP   V21         V28         FALSE     
LIME vs SHAP       V11         V28         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V22             2.714286     3.714286        4.714286           0.0456942
V27             3.028571     3.285714        4.314286           0.0404218
V8              1.828571     3.142857        3.400000           0.0386643
V30             2.314286     3.000000        3.285714           0.0369069
V14             2.142857     2.428571        2.571429           0.0298770

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V22
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V22         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V22             1.371429     1.571429        1.685714           0.0386643
V28             1.157143     1.357143        1.485714           0.0333919
V20             1.100000     1.285714        1.342857           0.0316344
V21             1.085714     1.285714        1.285714           0.0316344
V24             1.157143     1.285714        1.285714           0.0316344

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V22
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V22         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1999 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V28             5.100000     5.583333        5.733333           0.1177504
V21             4.866667     5.166667        5.850000           0.1089631
V22             2.600000     2.750000        2.750000           0.0579965
V8              1.350000     1.750000        1.883333           0.0369069
V23             1.600000     1.666667        1.750000           0.0351494

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: V28
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   V28         NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V21            0.9636364     1.454546        1.836364           0.0281195
V22            1.2181818     1.454546        1.890909           0.0281195
V25            1.4545455     1.454546        1.527273           0.0281195
V2             1.2181818     1.363636        1.781818           0.0263620
V3             1.2000000     1.363636        1.363636           0.0263620

=== LIME Rankings ===


Feature    Importance
--------  -----------
V11         0.1963418
V14         0.1819254
V13         0.1568929
V20         0.1442703
V24         0.1421465

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V28         0.0570667
V29         0.0465333
V8          0.0464000
V24         0.0436667
V23         0.0430000

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: V21
LIME: V11
SHAP: V28

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V21         V11         FALSE     
FEAT_IMP vs SHAP   V21         V28         FALSE     
LIME vs SHAP       V11         V28         FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wdbc, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature    importance.05   importance   importance.95   permutation.error
--------  --------------  -----------  --------------  ------------------
V24            14.600000    16.333333       17.133333           0.1722320
V22             3.600000     4.833333        5.333333           0.0509666
V11             3.233333     3.666667        4.233333           0.0386643
V8              1.866667     2.666667        3.333333           0.0281195
V27             2.000000     2.333333        2.733333           0.0246046

=== LIME Rankings ===


Feature    Importance
--------  -----------
V24         0.3937406
V11         0.3471566
V14         0.1575747
V20         0.1410461
V8          0.1205086

=== SHAP (IML Shapley) Rankings ===


Feature    Importance
--------  -----------
V24         0.2866934
V11         0.0872325
V29         0.0740753
V8          0.0699342
V27         0.0432406

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP           1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: V24
LIME: V24
SHAP: V24

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   V24         V24         TRUE      
FEAT_IMP vs SHAP   V24         V24         TRUE      
LIME vs SHAP       V24         V24         TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


Dataset: wilt
Generated: Mon Nov 24 10:36:01 PM CET 2025
======================================


========================================
Model: C5.0
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=C5.0 ===
No scaling applied for method: C5.0
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: ctree
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=ctree ===
No scaling applied for method: ctree


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_R          11.631818    11.988636       12.220455           0.2180203
Mean_G           8.406818     8.579546        8.636364           0.1560240
Mean_NIR         1.875000     1.931818        2.034091           0.0351312
GLCM_Pan         1.000000     1.000000        1.000000           0.0181856
SD_Plan          1.000000     1.000000        1.000000           0.0181856

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.2030914
Mean_NIR     0.0872998
Mean_R       0.0775108
SD_Plan      0.0084010
GLCM_Pan     0.0079586

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_R       0.3716336
Mean_G       0.2969280
Mean_NIR     0.1864502
GLCM_Pan     0.0000000
SD_Plan      0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -0.5                 3
FEAT_IMP vs SHAP         1.0                 3
LIME vs SHAP            -0.5                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Mean_R
LIME: Mean_G
SHAP: Mean_R

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_R      Mean_G      FALSE     
FEAT_IMP vs SHAP   Mean_R      Mean_R      TRUE      
LIME vs SHAP       Mean_G      Mean_R      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: fda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=fda ===
No scaling applied for method: fda
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
GLCM_Pan                1            1               1           0.0541434
Mean_G                  1            1               1           0.0541434
Mean_R                  1            1               1           0.0541434
Mean_NIR                1            1               1           0.0541434
SD_Plan                 1            1               1           0.0541434

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.2713146
SD_Plan      0.0029383
Mean_NIR     0.0028641
GLCM_Pan     0.0024755
Mean_R       0.0015943

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.0423252
GLCM_Pan     0.0000000
Mean_NIR     0.0000000
Mean_R       0.0000000
SD_Plan      0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP               1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: GLCM_Pan
LIME: Mean_G
SHAP: Mean_G

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   GLCM_Pan    Mean_G      FALSE     
FEAT_IMP vs SHAP   GLCM_Pan    Mean_G      FALSE     
LIME vs SHAP       Mean_G      Mean_G      TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gbm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=gbm ===
No scaling applied for method: gbm
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.4144            -nan     0.1000    0.0028
     2        0.4087            -nan     0.1000    0.0020
     3        0.4019            -nan     0.1000    0.0030
     4        0.3970            -nan     0.1000    0.0020
     5        0.3929            -nan     0.1000    0.0023
     6        0.3886            -nan     0.1000    0.0020
     7        0.3838            -nan     0.1000    0.0023
     8        0.3787            -nan     0.1000    0.0023
     9        0.3737            -nan     0.1000    0.0021
    10        0.3691            -nan     0.1000    0.0023
    20        0.3292            -nan     0.1000    0.0019
    40        0.2700            -nan     0.1000    0.0008
    50        0.2472            -nan     0.1000    0.0005



=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_G           1.410811     1.474903        1.488803           0.0789419
Mean_R           1.401544     1.413127        1.460232           0.0756355
GLCM_Pan         1.000000     1.000000        1.000000           0.0535235
Mean_NIR         1.000000     1.000000        1.000000           0.0535235
SD_Plan          1.000000     1.000000        1.000000           0.0535235

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.1558043
Mean_R       0.0948479
GLCM_Pan     0.0051426
SD_Plan      0.0047441
Mean_NIR     0.0046836

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_R       0.2051467
Mean_G       0.1529074
SD_Plan      0.0052928
GLCM_Pan     0.0000000
Mean_NIR     0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP          -1                 2
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: Mean_G
LIME: Mean_G
SHAP: Mean_R

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_G      Mean_G      TRUE      
FEAT_IMP vs SHAP   Mean_G      Mean_R      FALSE     
LIME vs SHAP       Mean_G      Mean_R      FALSE     

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: gcvEarth
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=gcvEarth ===
No scaling applied for method: gcvEarth
Loading required package: earth
Loading required package: Formula
Loading required package: plotmo
Loading required package: plotrix


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_R          16.184849    16.515152       17.063636           0.2252532
Mean_G          14.642424    14.742424       14.945455           0.2010746
Mean_NIR         1.924242     2.045454        2.163636           0.0278983
SD_Plan          1.066667     1.106061        1.203030           0.0150858
GLCM_Pan         1.000000     1.000000        1.000000           0.0136392

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.3652466
Mean_R       0.1261874
Mean_NIR     0.0412696
SD_Plan      0.0105325
GLCM_Pan     0.0063348

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.4464015
Mean_R       0.4252187
Mean_NIR     0.0160490
SD_Plan      0.0117907
GLCM_Pan     0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Mean_R
LIME: Mean_G
SHAP: Mean_G

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_R      Mean_G      FALSE     
FEAT_IMP vs SHAP   Mean_R      Mean_G      FALSE     
LIME vs SHAP       Mean_G      Mean_G      TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: JRip
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=JRip ===
No scaling applied for method: JRip


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_R          25.444444    25.537037       26.011111           0.2849762
Mean_G          23.992593    24.351852       24.411111           0.2717504
Mean_NIR         1.622222     1.685185        1.833333           0.0188055
GLCM_Pan         1.000000     1.000000        1.000000           0.0111593
SD_Plan          1.000000     1.000000        1.000000           0.0111593

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.4139495
Mean_R       0.1518438
Mean_NIR     0.0392986
GLCM_Pan     0.0148965
SD_Plan      0.0107373

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.4682654
Mean_R       0.4106568
Mean_NIR     0.0170837
GLCM_Pan     0.0000000
SD_Plan      0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Mean_R
LIME: Mean_G
SHAP: Mean_G

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_R      Mean_G      FALSE     
FEAT_IMP vs SHAP   Mean_R      Mean_G      FALSE     
LIME vs SHAP       Mean_G      Mean_G      TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: lvq
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=lvq ===
Applying data scaling for method: lvq


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
GLCM_Pan                1            1               1           0.0539368
Mean_G                  1            1               1           0.0539368
Mean_R                  1            1               1           0.0539368
Mean_NIR                1            1               1           0.0539368
SD_Plan                 1            1               1           0.0539368

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: GLCM_Pan
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   GLCM_Pan    NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: mlpML
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=mlpML ===
Applying data scaling for method: mlpML


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
At least one layer had zero units and were removed. The new structure is 1 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_G          9.2301887     9.314465        9.361006           0.3060550
Mean_R          7.7484277     7.773585        7.918239           0.2554247
Mean_NIR        2.1522013     2.163522        2.227673           0.0710891
SD_Plan         1.0264151     1.056604        1.099371           0.0347179
GLCM_Pan        0.9786164     1.006289        1.022641           0.0330647

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.3822990
Mean_R       0.1427669
Mean_NIR     0.0462741
SD_Plan      0.0097563
GLCM_Pan     0.0080069

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.4307635
Mean_R       0.2195155
Mean_NIR     0.0381012
SD_Plan      0.0128368
GLCM_Pan     0.0059513

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Mean_G
LIME: Mean_G
SHAP: Mean_G

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_G      Mean_G      TRUE      
FEAT_IMP vs SHAP   Mean_G      Mean_G      TRUE      
LIME vs SHAP       Mean_G      Mean_G      TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: multinom
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=multinom ===
Applying data scaling for method: multinom
# weights:  7 (6 variable)
initial  value 3354.139207 
iter  10 value 501.076674
iter  20 value 401.703707
final  value 401.579806 
converged


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_G          9.5909091     9.688312        9.841558           0.3083282
Mean_R          7.8883117     8.071429        8.089610           0.2568713
Mean_NIR        2.4272727     2.474026        2.583117           0.0787353
SD_Plan         1.0220779     1.051948        1.088312           0.0334780
GLCM_Pan        0.9935065     1.000000        1.005195           0.0318248

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.5114188
Mean_R       0.1957391
Mean_NIR     0.0627673
SD_Plan      0.0132905
GLCM_Pan     0.0103366

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.5073255
Mean_R       0.2238330
Mean_NIR     0.0588802
SD_Plan      0.0138369
GLCM_Pan     0.0005881

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Mean_G
LIME: Mean_G
SHAP: Mean_G

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_G      Mean_G      TRUE      
FEAT_IMP vs SHAP   Mean_G      Mean_G      TRUE      
LIME vs SHAP       Mean_G      Mean_G      TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


========================================
Model: naive_bayes
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=naive_bayes ===
No scaling applied for method: naive_bayes
Error: Only one model should be specified in tuneGrid with no resampling
Execution halted
FAILED - See error above


========================================
Model: PART
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=PART ===
No scaling applied for method: PART


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_R          33.419512    33.658537        34.72195           0.2851829
Mean_G          32.653658    32.926829        33.19024           0.2789833
Mean_NIR         2.302439     2.390244         2.55122           0.0202521
GLCM_Pan         1.000000     1.000000         1.00000           0.0084728
SD_Plan          1.000000     1.000000         1.00000           0.0084728

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.2926779
Mean_R       0.1992983
Mean_NIR     0.0671220
GLCM_Pan     0.0139795
SD_Plan      0.0125557

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.4429005
Mean_R       0.3863559
Mean_NIR     0.0125633
GLCM_Pan     0.0000000
SD_Plan      0.0000000

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Mean_R
LIME: Mean_G
SHAP: Mean_G

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_R      Mean_G      FALSE     
FEAT_IMP vs SHAP   Mean_R      Mean_G      FALSE     
LIME vs SHAP       Mean_G      Mean_G      TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rbfDDA
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=rbfDDA ===
Applying data scaling for method: rbfDDA


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
GLCM_Pan                1            1               1           0.0539368
Mean_G                  1            1               1           0.0539368
Mean_R                  1            1               1           0.0539368
Mean_NIR                1            1               1           0.0539368
SD_Plan                 1            1               1           0.0539368

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G        4.513682
Mean_R        3.170872
Mean_NIR      2.603904
GLCM_Pan      1.948557
SD_Plan       0.995364

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_NIR     12.903295
Mean_G        9.690124
SD_Plan       4.705824
GLCM_Pan      4.691251
Mean_R        4.225457

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 2
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              -1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: GLCM_Pan
LIME: Mean_G
SHAP: Mean_NIR

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   GLCM_Pan    Mean_G      FALSE     
FEAT_IMP vs SHAP   GLCM_Pan    Mean_NIR    FALSE     
LIME vs SHAP       Mean_G      Mean_NIR    FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: rda
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=rda ===
Applying data scaling for method: rda


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_R           8.122727     8.488636        8.629546           0.1543707
Mean_G           4.368182     4.500000        4.579546           0.0818351
Mean_NIR         1.822727     1.988636        2.027273           0.0361645
SD_Plan          1.477273     1.500000        1.654546           0.0272784
GLCM_Pan         1.220454     1.318182        1.336364           0.0239719

=== LIME Rankings ===
Error in get_lime: missing value where TRUE/FALSE needed 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_R       0.2932803
Mean_G       0.2402742
Mean_NIR     0.1556583
SD_Plan      0.1158409
GLCM_Pan     0.0389208

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP           1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: Mean_R
SHAP: Mean_R

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Mean_R      Mean_R      TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: rf
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=rf ===
No scaling applied for method: rf


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_R          0.2268237    0.2326927       0.2336846           0.2326927
Mean_G          0.1966522    0.1983881       0.2011986           0.1983881
Mean_NIR        0.0133912    0.0152924       0.0156644           0.0152924
SD_Plan         0.0080595    0.0095061       0.0103740           0.0095061
GLCM_Pan        0.0026865    0.0030998       0.0035131           0.0030998
Warning message:
In initialize(...) :
  Model error is 0, switching from compare='ratio' to compare='difference'

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.2624707
Mean_R       0.1087076
Mean_NIR     0.0310258
SD_Plan      0.0202483
GLCM_Pan     0.0090002

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_G        0.400200
Mean_R        0.363100
Mean_NIR      0.078568
SD_Plan       0.054084
GLCM_Pan      0.021640

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME         0.5                 3
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Mean_R
LIME: Mean_G
SHAP: Mean_G

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_R      Mean_G      FALSE     
FEAT_IMP vs SHAP   Mean_R      Mean_G      FALSE     
LIME vs SHAP       Mean_G      Mean_G      TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: rpart
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=rpart ===
No scaling applied for method: rpart


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
GLCM_Pan                1            1               1           0.0539368
Mean_G                  1            1               1           0.0539368
Mean_R                  1            1               1           0.0539368
Mean_NIR                1            1               1           0.0539368
SD_Plan                 1            1               1           0.0539368

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
GLCM_Pan             0
Mean_G               0
Mean_NIR             0
Mean_R               0
SD_Plan              0

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP           1                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        1

=== Top-1 Features ===
FEAT_IMP: GLCM_Pan
SHAP: GLCM_Pan

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   GLCM_Pan    GLCM_Pan    TRUE      

Agreeing pairs: 1 / 1 (100.0%)

=== All Results Recorded ===


========================================
Model: simpls
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=simpls ===
Applying data scaling for method: simpls


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
GLCM_Pan                1            1               1           0.0539368
Mean_G                  1            1               1           0.0539368
Mean_R                  1            1               1           0.0539368
Mean_NIR                1            1               1           0.0539368
SD_Plan                 1            1               1           0.0539368

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.0257045
SD_Plan      0.0148211
Mean_NIR     0.0132115
GLCM_Pan     0.0014517
Mean_R       0.0013201

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_NIR     0.0061898
SD_Plan      0.0038518
Mean_G       0.0029441
GLCM_Pan     0.0004041
Mean_R       0.0000108

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME          NA                 1
FEAT_IMP vs SHAP          NA                 1
LIME vs SHAP              -1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        0

=== Top-1 Features ===
FEAT_IMP: GLCM_Pan
LIME: Mean_G
SHAP: Mean_NIR

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   GLCM_Pan    Mean_G      FALSE     
FEAT_IMP vs SHAP   GLCM_Pan    Mean_NIR    FALSE     
LIME vs SHAP       Mean_G      Mean_NIR    FALSE     

Agreeing pairs: 0 / 3 (0.0%)

=== All Results Recorded ===


========================================
Model: svmLinear
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=svmLinear ===
Applying data scaling for method: svmLinear


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_G          7.6211111     7.722222        7.853333           0.2872494
Mean_R          6.3988889     6.427778        6.512222           0.2390990
Mean_NIR        1.5788889     1.666667        1.692222           0.0619963
SD_Plan         0.9700000     1.005556        1.022222           0.0374044
GLCM_Pan        0.9944444     1.000000        1.010000           0.0371978

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Mean_G
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Mean_G      NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: svmRadial
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=svmRadial ===
Applying data scaling for method: svmRadial


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_R           4.408392     4.510490        4.562238           0.1332920
Mean_G           3.324476     3.363636        3.468532           0.0994007
Mean_NIR         1.230769     1.258741        1.363636           0.0371978
SD_Plan          1.144056     1.160839        1.200000           0.0343046
GLCM_Pan         1.092308     1.118881        1.135664           0.0330647

=== LIME Rankings ===
Error in get_lime: Response is constant across permutations. Please check your model 
Warning message:
In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
Warning messages:
1: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
2: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
3: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
4: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs
5: In method$prob(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab class probability calculations failed; returning NAs

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Mean_R
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Mean_R      NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: rfRules
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=rfRules ===
No scaling applied for method: rfRules
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
2000 rules (length<=2) were extracted from the first 500 trees.


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_R           4.966871     5.184049        5.249080           0.1746229
Mean_G           4.867485     5.036810        5.133742           0.1696632
GLCM_Pan         1.000000     1.000000        1.000000           0.0336846
Mean_NIR         1.000000     1.000000        1.000000           0.0336846
SD_Plan          1.000000     1.000000        1.000000           0.0336846

=== LIME Rankings ===
Error in get_lime: only classification models that produce probabilities are allowed 

=== Top-3 Spearman (on common top-3 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs SHAP   NA                        0

=== Top-1 Features ===
FEAT_IMP: Mean_R
SHAP: NA

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs SHAP   Mean_R      NA          FALSE     

Agreeing pairs: 0 / 1 (0.0%)

=== All Results Recorded ===


========================================
Model: knn
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=knn ===
Applying data scaling for method: knn


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_R           4.944348     5.121739        5.333913           0.1217194
Mean_G           3.158261     3.226087        3.424348           0.0766687
Mean_NIR         1.636522     1.695652        1.730435           0.0402976
SD_Plan          1.389565     1.495652        1.546087           0.0355445
GLCM_Pan         1.326957     1.400000        1.480000           0.0332713

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.0323659
Mean_R       0.0209389
GLCM_Pan     0.0161326
Mean_NIR     0.0106971
SD_Plan      0.0094720

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.2262667
Mean_R       0.2152000
Mean_NIR     0.1649333
SD_Plan      0.1208667
GLCM_Pan     0.0899333

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME        -1.0                 2
FEAT_IMP vs SHAP         0.5                 3
LIME vs SHAP             1.0                 2

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        0
FEAT_IMP vs SHAP   NA                        0
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Mean_R
LIME: Mean_G
SHAP: Mean_G

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_R      Mean_G      FALSE     
FEAT_IMP vs SHAP   Mean_R      Mean_G      FALSE     
LIME vs SHAP       Mean_G      Mean_G      TRUE      

Agreeing pairs: 1 / 3 (33.3%)

=== All Results Recorded ===


========================================
Model: bayesglm
========================================
Loading required package: ggplot2
Loading required package: lattice


=== Processing: Dataset=wilt, Method=bayesglm ===
Applying data scaling for method: bayesglm


=== Trained model ===
Model class: train
Is trained_model NULL?: FALSE 
Warning message:
fitted probabilities numerically 0 or 1 occurred 

=== IML Rankings ===


feature     importance.05   importance   importance.95   permutation.error
---------  --------------  -----------  --------------  ------------------
Mean_G           9.624837     9.732026        9.856209           0.3077082
Mean_R           7.905882     8.104575        8.125490           0.2562513
Mean_NIR         2.431373     2.464052        2.580392           0.0779087
SD_Plan          1.032680     1.052288        1.095425           0.0332713
GLCM_Pan         1.006536     1.013072        1.018301           0.0320314

=== LIME Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.5116991
Mean_R       0.1961443
Mean_NIR     0.0620740
SD_Plan      0.0131267
GLCM_Pan     0.0102891

=== SHAP (IML Shapley) Rankings ===


Feature     Importance
---------  -----------
Mean_G       0.5053943
Mean_R       0.2226726
Mean_NIR     0.0586696
SD_Plan      0.0135648
GLCM_Pan     0.0006056

=== Top-3 Spearman (on common top-3 features only) ===


Pair                Spearman   Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME           1                 3
FEAT_IMP vs SHAP           1                 3
LIME vs SHAP               1                 3

=== Top-1 Spearman (on common top-1 features only) ===


Pair               Spearman    Common_Features
-----------------  ---------  ----------------
FEAT_IMP vs LIME   NA                        1
FEAT_IMP vs SHAP   NA                        1
LIME vs SHAP       NA                        1

=== Top-1 Features ===
FEAT_IMP: Mean_G
LIME: Mean_G
SHAP: Mean_G

=== Top-1 Feature Agreement (pairwise) ===


Pair               Feature_1   Feature_2   Agreement 
-----------------  ----------  ----------  ----------
FEAT_IMP vs LIME   Mean_G      Mean_G      TRUE      
FEAT_IMP vs SHAP   Mean_G      Mean_G      TRUE      
LIME vs SHAP       Mean_G      Mean_G      TRUE      

Agreeing pairs: 3 / 3 (100.0%)

=== All Results Recorded ===


