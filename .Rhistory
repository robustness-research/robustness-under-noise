class ~ .,
data = df,
method = "multinom",
trControl = control,
tuneGrid = expand.grid(decay = c(0)),
MaxNWts = 10000
)
cat("Training complete.\n")
# Create a predictor object from the trained model
predictor <- Predictor$new(fit)
# Calculate feature importance
featImp <- FeatureImp$new(predictor, loss = "ce")
# Display feature importance results
print(featImp)
# Extract the results dataframe
importance_df <- featImp$results
importance_df <- importance_df[order(-importance_df$importance), ]
print(importance_df)
# Create a bar plot of feature importance
p1 <- ggplot(importance_df, aes(x = reorder(feature, importance), y = importance)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = paste("Attribute Importance for", dataset, "using", method),
x = "Attribute",
y = "Importance") +
theme_minimal() +
theme(axis.text.y = element_text(size = 8))
# Create a histogram of importance values
p2 <- ggplot(importance_df, aes(x = importance)) +
geom_histogram(bins = 10, fill = "steelblue", color = "black") +
labs(title = "Distribution of Importance Values",
x = "Importance",
y = "Count") +
theme_minimal()
# Display the plots side by side
grid.arrange(p1, p2, ncol = 2)
# Save feature importance data
data_dir <- "../results/attribute_importance/"
plots_dir <- "../results/plots/"
# Create directories if they don't exist
if (!dir.exists(data_dir)) {
dir.create(data_dir, recursive = TRUE)
}
if (!dir.exists(plots_dir)) {
dir.create(plots_dir, recursive = TRUE)
}
# Save the feature importance dataframe
result_file <- paste0(data_dir, dataset, "_", method, "_importance.rds")
saveRDS(importance_df, file = result_file)
cat("Saved feature importance to:", result_file, "\n")
# Also save as a CSV for easier viewing
csv_file <- paste0(data_dir, dataset, "_", method, "_importance.csv")
write.csv(importance_df, file = csv_file, row.names = FALSE)
cat("Saved feature importance to CSV:", csv_file, "\n")
print(p1)
# Save only the bar plot
plot_file <- paste0(plots_dir, "importance_plot.png")
ggsave(plot_file, p1, width = 40, height = 40, dpi = 600)
cat("Saved importance bar plot to:", plot_file, "\n")
# Calculate mean kappa loss for each noise level in both datasets
top_stats <- mfeat_multinom_top %>%
group_by(noise) %>%
summarise(
mean_kappa_loss = mean(kappa_loss),
sd_kappa_loss = sd(kappa_loss)
)
popular_stats <- mfeat_multinom_popular %>%
group_by(noise) %>%
summarise(
mean_kappa_loss = mean(kappa_loss),
sd_kappa_loss = sd(kappa_loss)
)
# Combine the stats
combined_stats <- top_stats %>%
rename(top_mean = mean_kappa_loss, top_sd = sd_kappa_loss) %>%
left_join(popular_stats %>%
rename(popular_mean = mean_kappa_loss, popular_sd = sd_kappa_loss),
by = "noise") %>%
mutate(difference = top_mean - popular_mean)
# Print the combined stats
print(combined_stats)
# Plot the difference in mean kappa loss
ggplot(combined_stats, aes(x = factor(noise), y = difference)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Difference in Mean Kappa Loss (Top - Popular)",
x = "Noise Level",
y = "Difference") +
theme_bw()
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally) # extensi贸n de ggplot2
library(factoextra) # visualizacion de los clusters
library(NbClust) # determinar el mejor numero de grupos
library(cluster) # medidas de evaluacion como silhouette
library(gridExtra) # For grid.arrange to place plots side by side
library(grid) # For text grobs
# Load files
datasets <- readRDS("../files/datasets.rds")
method_names = readRDS("../files/method_names.rds")
# Remove svmLinear for testing on most popular key attribute
method_names <- method_names[! method_names %in% c("svmLinear")]
noise_level <- readRDS("../files/noise.rds")
noise_names <- readRDS("../files/noise_names.rds")
instances_names = readRDS("../files/instances_names.rds")
# Load results
KLC_res <- readRDS("../results/KLC_plot_deciles.rds")
KLC_p <- readRDS("../results/KLC_plot_deciles_popular.rds")
# Filter data for mfeat-zernike dataset and multinom technique from both datasets
mfeat_multinom_top <- KLC_res %>%
filter(dataset_name == "mfeat-zernike" & technique == "multinom")
mfeat_multinom_popular <- KLC_p %>%
filter(dataset_name == "mfeat-zernike" & technique == "multinom")
# Print the number of rows in each filtered dataset
cat("Top attribute dataset rows:", nrow(mfeat_multinom_top), "\n")
cat("Popular attribute dataset rows:", nrow(mfeat_multinom_popular), "\n")
# Create plot for top attribute
plot_top <- ggplot(mfeat_multinom_top, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(title = "mfeat-zernike with multinom (Top Attribute)",
x = "Instances",
y = "Kappa Loss",
color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1))
# Create plot for popular attribute
plot_popular <- ggplot(mfeat_multinom_popular, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(title = "mfeat-zernike with multinom (Popular Attribute)",
x = "Instances",
y = "Kappa Loss",
color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1))
# Display plots side by side
grid.arrange(plot_top, plot_popular, ncol = 2)
# Save the comparison plot
comparison_plot <- grid.arrange(plot_top, plot_popular, ncol = 2)
ggsave("../results/plots/plot_comparison.png", comparison_plot, width = 40, height = 40, dpi = 600)
# Calculate mean kappa loss for each noise level in both datasets
top_stats <- mfeat_multinom_top %>%
group_by(noise) %>%
summarise(
mean_kappa_loss = mean(kappa_loss),
sd_kappa_loss = sd(kappa_loss)
)
popular_stats <- mfeat_multinom_popular %>%
group_by(noise) %>%
summarise(
mean_kappa_loss = mean(kappa_loss),
sd_kappa_loss = sd(kappa_loss)
)
# Combine the stats
combined_stats <- top_stats %>%
rename(top_mean = mean_kappa_loss, top_sd = sd_kappa_loss) %>%
left_join(popular_stats %>%
rename(popular_mean = mean_kappa_loss, popular_sd = sd_kappa_loss),
by = "noise") %>%
mutate(difference = top_mean - popular_mean)
# Print the combined stats
print(combined_stats)
# Plot the difference in mean kappa loss
ggplot(combined_stats, aes(x = factor(noise), y = difference)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Difference in Mean Kappa Loss (Top - Popular)",
x = "Noise Level",
y = "Difference") +
theme_bw()
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally) # extensi贸n de ggplot2
library(factoextra) # visualizacion de los clusters
library(NbClust) # determinar el mejor numero de grupos
library(cluster) # medidas de evaluacion como silhouette
library(gridExtra) # For grid.arrange to place plots side by side
library(grid) # For text grobs
# Load files
datasets <- readRDS("../files/datasets.rds")
method_names = readRDS("../files/method_names.rds")
# Remove svmLinear for testing on most popular key attribute
method_names <- method_names[! method_names %in% c("svmLinear")]
noise_level <- readRDS("../files/noise.rds")
noise_names <- readRDS("../files/noise_names.rds")
instances_names = readRDS("../files/instances_names.rds")
# Load results
KLC_res <- readRDS("../results/KLC_plot_deciles.rds")
KLC_p <- readRDS("../results/KLC_plot_deciles_popular.rds")
# Filter data for mfeat-zernike dataset and multinom technique from both datasets
mfeat_multinom_top <- KLC_res %>%
filter(dataset_name == "mfeat-zernike" & technique == "multinom")
mfeat_multinom_popular <- KLC_p %>%
filter(dataset_name == "mfeat-zernike" & technique == "multinom")
# Print the number of rows in each filtered dataset
cat("Top attribute dataset rows:", nrow(mfeat_multinom_top), "\n")
cat("Popular attribute dataset rows:", nrow(mfeat_multinom_popular), "\n")
# Create plot for top attribute
plot_top <- ggplot(mfeat_multinom_top, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(title = "mfeat-zernike with multinom (Top Attribute)",
x = "Instances",
y = "Kappa Loss",
color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1))
# Create plot for popular attribute
plot_popular <- ggplot(mfeat_multinom_popular, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(title = "mfeat-zernike with multinom (Popular Attribute)",
x = "Instances",
y = "Kappa Loss",
color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1))
# Display plots side by side
grid.arrange(plot_top, plot_popular, ncol = 2)
# Save the comparison plot
comparison_plot <- grid.arrange(plot_top, plot_popular, ncol = 2)
ggsave("../results/plots/plot_comparison.png", comparison_plot, width = 40, height = 40, dpi = 600)
# Calculate mean kappa loss for each noise level in both datasets
top_stats <- mfeat_multinom_top %>%
group_by(noise) %>%
summarise(
mean_kappa_loss = mean(kappa_loss),
sd_kappa_loss = sd(kappa_loss)
)
popular_stats <- mfeat_multinom_popular %>%
group_by(noise) %>%
summarise(
mean_kappa_loss = mean(kappa_loss),
sd_kappa_loss = sd(kappa_loss)
)
# Combine the stats
combined_stats <- top_stats %>%
rename(top_mean = mean_kappa_loss, top_sd = sd_kappa_loss) %>%
left_join(popular_stats %>%
rename(popular_mean = mean_kappa_loss, popular_sd = sd_kappa_loss),
by = "noise") %>%
mutate(difference = top_mean - popular_mean)
# Print the combined stats
print(combined_stats)
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
library(caret)
library(iml)
library(dplyr)
library(ggplot2)
library(gridExtra)
# Set seed for reproducibility
set.seed(1)
# Load the dataset
dataset <- "mfeat-zernike"
ds_filename <- paste0("../datasets/", dataset, ".rds")
df <- readRDS(ds_filename)
# Load the control settings
control <- readRDS("../files/control.rds")
# Print dataset info
cat("Dataset:", dataset, "\n")
cat("Number of observations:", nrow(df), "\n")
cat("Number of attributes:", ncol(df) - 1, "\n")
cat("Class distribution:\n")
print(table(df$class))
# Train the model
method <- "multinom"
cat("Training", method, "model...\n")
# Training the multinom model as in Calculator_MIA.R
fit <- caret::train(
class ~ .,
data = df,
method = "multinom",
trControl = control,
tuneGrid = expand.grid(decay = c(0)),
MaxNWts = 10000
)
cat("Training complete.\n")
# Create a predictor object from the trained model
predictor <- Predictor$new(fit)
# Calculate feature importance
featImp <- FeatureImp$new(predictor, loss = "ce")
# Display feature importance results
print(featImp)
# Extract the results dataframe
importance_df <- featImp$results
importance_df <- importance_df[order(-importance_df$importance), ]
print(importance_df)
# Create a bar plot of feature importance
p1 <- ggplot(importance_df, aes(x = reorder(feature, importance), y = importance)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = paste("Attribute Importance for", dataset, "using", method),
x = "Attribute",
y = "Importance") +
theme_minimal() +
theme(axis.text.y = element_text(size = 8))
# Create a histogram of importance values
p2 <- ggplot(importance_df, aes(x = importance)) +
geom_histogram(bins = 10, fill = "steelblue", color = "black") +
labs(title = "Distribution of Importance Values",
x = "Importance",
y = "Count") +
theme_minimal()
# Display the plots side by side
grid.arrange(p1, p2, ncol = 2)
# Save feature importance data
data_dir <- "../results/attribute_importance/"
plots_dir <- "../results/plots/"
# Create directories if they don't exist
if (!dir.exists(data_dir)) {
dir.create(data_dir, recursive = TRUE)
}
if (!dir.exists(plots_dir)) {
dir.create(plots_dir, recursive = TRUE)
}
# Save the feature importance dataframe
result_file <- paste0(data_dir, dataset, "_", method, "_importance.rds")
saveRDS(importance_df, file = result_file)
cat("Saved feature importance to:", result_file, "\n")
# Also save as a CSV for easier viewing
csv_file <- paste0(data_dir, dataset, "_", method, "_importance.csv")
write.csv(importance_df, file = csv_file, row.names = FALSE)
cat("Saved feature importance to CSV:", csv_file, "\n")
print(p1)
# Save only the bar plot
plot_file <- paste0(plots_dir, "importance_plot.png")
ggsave(plot_file, p1, width = 40, height = 40, dpi = 600)
cat("Saved importance bar plot to:", plot_file, "\n")
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally) # extensi贸n de ggplot2
library(factoextra) # visualizacion de los clusters
library(NbClust) # determinar el mejor numero de grupos
library(cluster) # medidas de evaluacion como silhouette
library(gridExtra) # For grid.arrange to place plots side by side
library(grid) # For text grobs
# Load files
datasets <- readRDS("../files/datasets.rds")
method_names = readRDS("../files/method_names.rds")
# Remove svmLinear for testing on most popular key attribute
method_names <- method_names[! method_names %in% c("svmLinear")]
noise_level <- readRDS("../files/noise.rds")
noise_names <- readRDS("../files/noise_names.rds")
instances_names = readRDS("../files/instances_names.rds")
# Load results
KLC_res <- readRDS("../results/KLC_plot_deciles.rds")
KLC_p <- readRDS("../results/KLC_plot_deciles_popular.rds")
# Filter data for mfeat-zernike dataset and multinom technique from both datasets
mfeat_multinom_top <- KLC_res %>%
filter(dataset_name == "mfeat-zernike" & technique == "multinom")
mfeat_multinom_popular <- KLC_p %>%
filter(dataset_name == "mfeat-zernike" & technique == "multinom")
# Print the number of rows in each filtered dataset
cat("Top attribute dataset rows:", nrow(mfeat_multinom_top), "\n")
cat("Popular attribute dataset rows:", nrow(mfeat_multinom_popular), "\n")
# Create plot for top attribute
plot_top <- ggplot(mfeat_multinom_top, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(title = "mfeat-zernike with multinom (Top Attribute)",
x = "Instances",
y = "Kappa Loss",
color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1))
# Create plot for popular attribute
plot_popular <- ggplot(mfeat_multinom_popular, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(title = "mfeat-zernike with multinom (Popular Attribute)",
x = "Instances",
y = "Kappa Loss",
color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1))
# Display plots side by side
grid.arrange(plot_top, plot_popular, ncol = 2)
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally) # extensi贸n de ggplot2
library(factoextra) # visualizacion de los clusters
library(NbClust) # determinar el mejor numero de grupos
library(cluster) # medidas de evaluacion como silhouette
library(gridExtra) # For grid.arrange to place plots side by side
library(grid) # For text grobs
# Load files
datasets <- readRDS("../files/datasets.rds")
method_names = readRDS("../files/method_names.rds")
# Remove svmLinear for testing on most popular key attribute
method_names <- method_names[! method_names %in% c("svmLinear")]
noise_level <- readRDS("../files/noise.rds")
noise_names <- readRDS("../files/noise_names.rds")
instances_names = readRDS("../files/instances_names.rds")
# Load results
KLC_res <- readRDS("../results/KLC_plot_deciles.rds")
KLC_p <- readRDS("../results/KLC_plot_deciles_popular.rds")
# Filter data for mfeat-zernike dataset and multinom technique from both datasets
mfeat_multinom_top <- KLC_res %>%
filter(dataset_name == "mfeat-zernike" & technique == "multinom")
mfeat_multinom_popular <- KLC_p %>%
filter(dataset_name == "mfeat-zernike" & technique == "multinom")
# Print the number of rows in each filtered dataset
cat("Top attribute dataset rows:", nrow(mfeat_multinom_top), "\n")
cat("Popular attribute dataset rows:", nrow(mfeat_multinom_popular), "\n")
# Create plot for top attribute
plot_top <- ggplot(mfeat_multinom_top, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(title = "mfeat-zernike with multinom (Top Attribute)",
x = "Instances",
y = "Kappa Loss",
color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1))
# Create plot for popular attribute
plot_popular <- ggplot(mfeat_multinom_popular, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(title = "mfeat-zernike with multinom (Popular Attribute)",
x = "Instances",
y = "Kappa Loss",
color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1))
# Display plots side by side
grid.arrange(plot_top, plot_popular, ncol = 2)
# Extract kappa loss at 100% noise and 100% instances
top_100_100 <- mfeat_multinom_top %>%
filter(noise == 100, percentage == 100) %>%
select(kappa_loss) %>%
pull()
popular_100_100 <- mfeat_multinom_popular %>%
filter(noise == 100, percentage == 100) %>%
select(kappa_loss) %>%
pull()
# Print the results as percentages
cat("\nKappa Loss at 100% Noise and 100% Instances:\n")
cat("Top Important Attribute Loss: ", round(top_100_100 * 100, 2), "%\n", sep = "")
cat("Popular Important Attribute Loss: ", round(popular_100_100 * 100, 2), "%\n", sep = "")
cat("Difference (Top - Popular): ", round((top_100_100 - popular_100_100) * 100, 2), " percentage points\n", sep = "")
cat("Relative Difference: ", round(((top_100_100 - popular_100_100) / popular_100_100) * 100, 2), "%\n", sep = "")
# Load results
mia_df <- readRDS("../results/most_important_attr/mia_df.rds")
View(mia_df)
View(mia_df)
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
library(dplyr)
library(ggplot2)
# Load files
datasets <- readRDS("../files/datasets.rds")
method_names = readRDS("../files/method_names.rds")
# Remove svmLinear for testing on most popular key attribute
method_names <- method_names[! method_names %in% c("svmLinear")]
noise_level <- readRDS("../files/noise.rds")
noise_names <- readRDS("../files/noise_names.rds")
instances_names = readRDS("../files/instances_names.rds")
quartiles_names = c("25", "50", "75", "100")
# Load results
deciles_df <- readRDS("../results/KLC_plot_deciles_popular.rds")
#deciles_df <- deciles_df %>% select(-accuracy, -kappa, -dataset_order, -method_order)
#saveRDS(deciles_df, file = "../results/KLC_plot_deciles.rds")
#saveRDS(deciles_df, file = "../results/KLC_plot_deciles_popular.rds")
#quartiles_df <- readRDS("../results/KLC_plot_quartiles_popular.png")
#quartiles_df <- quartiles_df %>% select(-accuracy, -kappa, -dataset_order, -method_order)
#saveRDS(quartiles_df, file = "../results/KLC_plot_quartiles.rds")
#saveRDS(quartiles_df, file = "../results/KLC_plot_quartiles_popular.png")
df1 <- deciles_df %>%
group_by(technique, noise) %>%
summarize(kappa_loss = round(mean(kappa_loss, na.rm = TRUE), 2)) %>%
ungroup()
df2 <- deciles_df %>%
group_by(technique, noise, percentage) %>%
summarize(kappa_loss = round(mean(kappa_loss, na.rm = TRUE), 2)) %>%
ungroup()
#df2_q <- quartiles_df %>%
#    group_by(technique, noise, percentage) %>%
#    summarize(kappa_loss = round(mean(kappa_loss, na.rm = TRUE), 2)) %>%
#    ungroup()
#saveRDS(df2, file = "../results/meanKLC_d.rds")
saveRDS(df2, file = "../results/meanKLC_d_popular.rds")
#saveRDS(df2_q, file = "../results/meanKLC_q.rds")
for(instance in quartiles_names) {
# Filter data for the current instance percentage
filtered_data <- subset(df2, percentage == instance & noise != 5)
# Create plot
p2 <- ggplot(filtered_data, aes(x = noise, y = kappa_loss, color = factor(technique))) +
geom_point() +
geom_line(aes(noise)) +
labs(x = "Noise", y = "Kappa Loss", color = "Technique") +
ggtitle(paste0("Kappa Loss Curves by technique, noise and ", instance, " % of instances altered")) +
theme_bw() +
scale_y_continuous(limits = c(0.0, 0.5), breaks = seq(0, 1, by = 0.1))
# Print plot
print(p2)
}
#ggsave("../results/plots/KLC_techniques_q.png", p2, width = 40, height = 40, dpi = 600)
ggsave("../results/plots/KLC_techniques_d_popular.png", p2, width = 40, height = 40, dpi = 600)
